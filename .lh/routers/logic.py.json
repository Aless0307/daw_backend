{
    "sourceFile": "routers/logic.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 25,
            "patches": [
                {
                    "date": 1746139863306,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1746140086372,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,111 +1,134 @@\n # routers/logic.py\n-from fastapi import APIRouter, Depends, HTTPException, status\n-from bson import ObjectId # Necesario para trabajar con ObjectIds\n-from typing import Optional, Dict, List # Importar tipos necesarios\n-from datetime import datetime # Necesario para timestamps si no lo generas en el cliente\n+from fastapi import APIRouter, Depends, HTTPException, status, Query # Importa Query para parámetros de consulta\n+from bson import ObjectId\n+from typing import Optional, Dict, List, Union # Importa Union\n+from datetime import datetime\n \n-# Importa tu cliente de MongoDB (asegúrate que la ruta de importación sea correcta)\n+# Importa tu cliente de MongoDB\n from mongodb_client import MongoDBClient\n \n # Importa tu dependencia para obtener el usuario actual\n-from utils.auth_utils import get_current_user # Asegúrate que la ruta es correcta\n+from utils.auth_utils import get_current_user\n \n-# Importa el modelo de respuesta de progreso que acabamos de crear\n-from models.logic import UserProgressResponse, DifficultyProgress # Asegúrate que la ruta es correcta\n+# Importa los modelos de respuesta (ahora incluyendo los nuevos)\n+from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse # Importa los nuevos modelos\n \n-import logging # Para logging\n-logger = logging.getLogger(__name__) # Obtener logger para este módulo\n+import logging\n+logger = logging.getLogger(__name__)\n \n router = APIRouter(\n-    prefix=\"/logic\", # Prefijo para todas las rutas en este router (ej. /api/logic/...)\n-    tags=[\"Logic Problems\"], # Tags para la documentación de Swagger/OpenAPI\n-    # Aquí podrías añadir la dependencia de autenticación a todo el router si quieres que todas sus rutas estén protegidas por defecto\n-    # dependencies=[Depends(get_current_user)]\n+    prefix=\"/logic\", # Prefijo /logic\n+    tags=[\"Logic Problems\"],\n+    # dependencies=[Depends(get_current_user)] # Podrías añadirlo aquí si todas son protegidas\n )\n \n-# Instancia del cliente de MongoDB\n+# Instancia del cliente de MongoDB (ya la tienes)\n mongo_client = MongoDBClient()\n \n-# Endpoint para obtener el progreso del usuario en los ejercicios de lógica\n+# --- Endpoint Existente ---\n @router.get(\"/progress\", response_model=UserProgressResponse)\n async def get_user_progress(\n-    # Usa la dependencia para obtener el usuario autenticado.\n-    # get_current_user debe devolver el documento completo del usuario o al menos su ID y email.\n-    # Según tu código, get_current_user devuelve el diccionario completo del usuario.\n     current_user: dict = Depends(get_current_user)\n ):\n-    \"\"\"\n-    Obtiene el progreso del usuario en los ejercicios de lógica resueltos.\n-    Retorna conteos por dificultad y promedios de calificación.\n-    Esta ruta requiere autenticación (Bearer Token).\n-    \"\"\"\n-    user_id = current_user.get(\"_id\") # Obtiene el ObjectId del usuario del documento retornado por get_current_user\n-    user_email = current_user.get(\"email\") # Obtiene el email para logging\n+    # ... (Tu código para calcular el progreso aquí) ...\n+    user_id = current_user.get(\"_id\")\n+    user_email = current_user.get(\"email\", \"N/A\")\n \n-    if not user_id:\n-         logger.error(f\"Usuario autenticado sin _id en el token/objeto retornado: {user_email}\")\n-         # Esto no debería pasar si get_current_user funciona correctamente, pero es una buena validación\n+    if not user_id or not isinstance(user_id, ObjectId):\n+         logger.error(f\"Usuario autenticado sin _id válido en el objeto retornado: {user_email}\")\n          raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"No se pudo identificar al usuario\")\n \n \n     logger.info(f\"Solicitud de progreso para usuario: {user_email} (ID: {user_id})\")\n \n-    # El array de ejercicios resueltos está directamente en el documento del usuario\n-    # Si por alguna razón el usuario no tiene el campo 'ejercicios', accedemos de forma segura con .get()\n     solved_exercises = current_user.get(\"ejercicios\", [])\n \n-    # Inicializar contadores y sumas para el cálculo del progreso\n     progress_counts: Dict[str, int] = {\"basico\": 0, \"intermedio\": 0, \"avanzado\": 0}\n     progress_sums: Dict[str, float] = {\"basico\": 0.0, \"intermedio\": 0.0, \"avanzado\": 0.0}\n     total_solved_count = 0\n     total_grade_sum = 0.0\n \n-    # Iterar sobre los ejercicios resueltos para calcular las estadísticas\n     for exercise in solved_exercises:\n-        # Verificar que el ejercicio tenga la estructura esperada\n         if isinstance(exercise, dict) and \"problem_difficulty\" in exercise and \"llm_grade\" in exercise:\n             difficulty = exercise[\"problem_difficulty\"]\n             grade = exercise[\"llm_grade\"]\n \n-            # Verificar que la dificultad sea una de las esperadas y el grade sea numérico\n             if difficulty in progress_counts and isinstance(grade, (int, float)):\n                 total_solved_count += 1\n                 total_grade_sum += grade\n-\n                 progress_counts[difficulty] += 1\n                 progress_sums[difficulty] += grade\n             else:\n-                 logger.warning(f\"Ejercicio con formato inesperado encontrado para user_id {user_id}: {exercise}\")\n+                 logger.warning(f\"Ejercicio con formato inesperado encontrado en historial de user_id {user_id}: {exercise}\")\n \n-\n-    # Calcular promedios por dificultad\n     progress_by_difficulty: Dict[str, DifficultyProgress] = {}\n-    for difficulty in progress_counts:\n-        solved_count = progress_counts[difficulty]\n-        grade_sum = progress_sums[difficulty]\n-        # Calcular promedio solo si hay ejercicios resueltos en esa dificultad para evitar división por cero\n+    for difficulty in [\"basico\", \"intermedio\", \"avanzado\"]:\n+        solved_count = progress_counts.get(difficulty, 0)\n+        grade_sum = progress_sums.get(difficulty, 0.0)\n         average_grade = grade_sum / solved_count if solved_count > 0 else 0.0\n\\ No newline at end of file\n-        # Opcional: Redondear el promedio para la respuesta\n         average_grade = round(average_grade, 2)\n \n         progress_by_difficulty[difficulty] = DifficultyProgress(\n             solved_count=solved_count,\n             average_grade=average_grade\n         )\n \n-    # Calcular promedio general\n     overall_average_grade = total_grade_sum / total_solved_count if total_solved_count > 0 else 0.0\n-    overall_average_grade = round(overall_average_grade, 2) # Opcional: Redondear\n+    overall_average_grade = round(overall_average_grade, 2)\n \n     logger.info(f\"Progreso calculado para {user_email}: {total_solved_count} total, {progress_by_difficulty}, {overall_average_grade} avg\")\n \n-    # Crear y retornar la respuesta usando el modelo Pydantic\n     return UserProgressResponse(\n         total_solved=total_solved_count,\n         progress_by_difficulty=progress_by_difficulty,\n         overall_average_grade=overall_average_grade,\n         message=\"Tu progreso ha sido cargado.\"\n     )\n \n-# --- Otros endpoints de lógica (como /problem y /submit_answer) irán aquí ---\n-# Los implementaremos en los siguientes pasos.\n+\n+# --- NUEVO Endpoint para obtener un problema ---\n+@router.get(\"/problem\", response_model=Union[ProblemResponse, NoProblemResponse]) # La respuesta puede ser un problema o un mensaje de no encontrado\n+async def get_logic_problem(\n+    current_user: dict = Depends(get_current_user),\n+    # Permite al cliente especificar opcionalmente la dificultad como parámetro de consulta\n+    difficulty: Optional[str] = Query(None, description=\"Dificultad del problema (ej. 'basico', 'intermedio', 'avanzado')\")\n+):\n+    \"\"\"\n+    Obtiene un problema de lógica aleatorio que el usuario autenticado no haya resuelto.\n+    Opcionalmente filtra por dificultad.\n+    Requiere autenticación (Bearer Token).\n+    \"\"\"\n+    user_id = current_user.get(\"_id\") # Obtiene el ObjectId del usuario\n+\n+    if not user_id or not isinstance(user_id, ObjectId):\n+         logger.error(f\"Usuario autenticado sin _id válido: {current_user.get('email', 'N/A')}\")\n+         raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"No se pudo identificar al usuario\")\n+\n+    # Validar que la dificultad, si se proporciona, sea una de las esperadas\n+    if difficulty is not None and difficulty not in [\"basico\", \"intermedio\", \"avanzado\"]:\n+         logger.warning(f\"Solicitud con dificultad inválida para user_id {user_id}: {difficulty}\")\n+         raise HTTPException(\n+             status_code=status.HTTP_400_BAD_REQUEST,\n+             detail=\"La dificultad especificada es inválida. Usa 'basico', 'intermedio' o 'avanzado'.\"\n+         )\n+\n+    logger.info(f\"Solicitud de problema para user_id: {user_id}, dificultad: {difficulty}\")\n+\n+    # Usar el método de tu MongoDBClient para buscar un problema sin resolver\n+    problem = mongo_client.get_random_unsolved_problem(user_id, difficulty=difficulty)\n+\n+    if problem:\n+        # Si se encontró un problema, FastAPI usará ProblemResponse para serializarlo\n+        logger.info(f\"Problema encontrado: {problem.get('_id')} (Dificultad: {problem.get('difficulty')})\")\n+        return problem # mongo_client retorna un dict, Pydantic lo validará y serializará\n+\n+    else:\n+        # Si no se encontró ningún problema sin resolver con los criterios\n+        logger.info(f\"No se encontraron problemas sin resolver para user_id {user_id} con dificultad: {difficulty}\")\n+        # FastAPI usará NoProblemResponse para serializarlo. Retornamos 200 OK con este mensaje.\n+        return NoProblemResponse(\n+            message=f\"No se encontraron problemas sin resolver para la dificultad '{difficulty}'.\" if difficulty else \"No se encontraron problemas sin resolver.\"\n+        )\n+\n+\n+# --- El endpoint /submit_answer irá aquí en un futuro paso ---\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746141553289,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -85,27 +85,27 @@\n         message=\"Tu progreso ha sido cargado.\"\n     )\n \n \n-# --- NUEVO Endpoint para obtener un problema ---\n+\n+\n+# --- Endpoint para obtener un problema (MODIFICADO) ---\n @router.get(\"/problem\", response_model=Union[ProblemResponse, NoProblemResponse]) # La respuesta puede ser un problema o un mensaje de no encontrado\n async def get_logic_problem(\n     current_user: dict = Depends(get_current_user),\n-    # Permite al cliente especificar opcionalmente la dificultad como parámetro de consulta\n     difficulty: Optional[str] = Query(None, description=\"Dificultad del problema (ej. 'basico', 'intermedio', 'avanzado')\")\n ):\n     \"\"\"\n     Obtiene un problema de lógica aleatorio que el usuario autenticado no haya resuelto.\n     Opcionalmente filtra por dificultad.\n     Requiere autenticación (Bearer Token).\n     \"\"\"\n-    user_id = current_user.get(\"_id\") # Obtiene el ObjectId del usuario\n+    user_id = current_user.get(\"_id\")\n \n     if not user_id or not isinstance(user_id, ObjectId):\n          logger.error(f\"Usuario autenticado sin _id válido: {current_user.get('email', 'N/A')}\")\n          raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"No se pudo identificar al usuario\")\n \n-    # Validar que la dificultad, si se proporciona, sea una de las esperadas\n     if difficulty is not None and difficulty not in [\"basico\", \"intermedio\", \"avanzado\"]:\n          logger.warning(f\"Solicitud con dificultad inválida para user_id {user_id}: {difficulty}\")\n          raise HTTPException(\n              status_code=status.HTTP_400_BAD_REQUEST,\n@@ -113,22 +113,30 @@\n          )\n \n     logger.info(f\"Solicitud de problema para user_id: {user_id}, dificultad: {difficulty}\")\n \n-    # Usar el método de tu MongoDBClient para buscar un problema sin resolver\n     problem = mongo_client.get_random_unsolved_problem(user_id, difficulty=difficulty)\n \n     if problem:\n-        # Si se encontró un problema, FastAPI usará ProblemResponse para serializarlo\n-        logger.info(f\"Problema encontrado: {problem.get('_id')} (Dificultad: {problem.get('difficulty')})\")\n-        return problem # mongo_client retorna un dict, Pydantic lo validará y serializará\n+        # --- MODIFICACIÓN AQUÍ ---\n+        # Creamos explícitamente una instancia de ProblemResponse a partir del diccionario\n+        # devuelto por el cliente de MongoDB. Esto fuerza la validación y serialización en este punto.\n+        try:\n+            problem_response_data = ProblemResponse(**problem)\n+            logger.info(f\"Serialización exitosa del problema {problem.get('_id')}.\")\n+            return problem_response_data # Retornamos la instancia validada\n+        except Exception as e:\n+            # Si la serialización/validación falla aquí, logueamos el error y devolvemos un error interno\n+            logger.error(f\"Error al serializar el problema {problem.get('_id')} con Pydantic: {str(e)}\", exc_info=True)\n+            # Podrías decidir devolver un 500 o el mensaje de no encontrado, dependiendo de cómo quieras manejarlo\n+            # Devolver un 500 es más preciso si el problema *existe* pero no se pudo formatear\n+            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al procesar el problema.\")\n+        # --- FIN MODIFICACIÓN ---\n \n     else:\n         # Si no se encontró ningún problema sin resolver con los criterios\n-        logger.info(f\"No se encontraron problemas sin resolver para user_id {user_id} con dificultad: {difficulty}\")\n-        # FastAPI usará NoProblemResponse para serializarlo. Retornamos 200 OK con este mensaje.\n+        logger.info(f\"No se encontraron problemas sin resolver para user_id {user_id} con dificultad: {difficulty}. Retornando NoProblemResponse.\")\n         return NoProblemResponse(\n             message=f\"No se encontraron problemas sin resolver para la dificultad '{difficulty}'.\" if difficulty else \"No se encontraron problemas sin resolver.\"\n         )\n \n-\n # --- El endpoint /submit_answer irá aquí en un futuro paso ---\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746141671505,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -87,10 +87,10 @@\n \n \n \n \n-# --- Endpoint para obtener un problema (MODIFICADO) ---\n-@router.get(\"/problem\", response_model=Union[ProblemResponse, NoProblemResponse]) # La respuesta puede ser un problema o un mensaje de no encontrado\n+# --- Endpoint para obtener un problema (MODIFICADO DE NUEVO) ---\n+@router.get(\"/problem\", response_model=Union[ProblemResponse, NoProblemResponse])\n async def get_logic_problem(\n     current_user: dict = Depends(get_current_user),\n     difficulty: Optional[str] = Query(None, description=\"Dificultad del problema (ej. 'basico', 'intermedio', 'avanzado')\")\n ):\n@@ -117,20 +117,28 @@\n     problem = mongo_client.get_random_unsolved_problem(user_id, difficulty=difficulty)\n \n     if problem:\n         # --- MODIFICACIÓN AQUÍ ---\n-        # Creamos explícitamente una instancia de ProblemResponse a partir del diccionario\n-        # devuelto por el cliente de MongoDB. Esto fuerza la validación y serialización en este punto.\n+        # El cliente de MongoDB devuelve un diccionario donde _id es un ObjectId.\n+        # Pydantic espera un string para el campo 'id' (alias '_id').\n+        # Convertimos el ObjectId a string ANTES de crear la instancia del modelo Pydantic.\n         try:\n-            problem_response_data = ProblemResponse(**problem)\n-            logger.info(f\"Serialización exitosa del problema {problem.get('_id')}.\")\n-            return problem_response_data # Retornamos la instancia validada\n+            # Crear una copia del diccionario para no modificar el resultado original del cliente DB si se reutiliza\n+            problem_dict_for_pydantic = problem.copy()\n+            # Convertir el ObjectId a string\n+            problem_dict_for_pydantic['_id'] = str(problem_dict_for_pydantic['_id'])\n+\n+            # Ahora creamos la instancia de ProblemResponse con el diccionario modificado\n+            problem_response_data = ProblemResponse(**problem_dict_for_pydantic)\n+\n+            logger.info(f\"Validación y serialización exitosa del problema {problem_dict_for_pydantic['_id']}.\")\n+            return problem_response_data # Retornamos la instancia validada y lista para ser serializada a JSON por FastAPI\n+\n         except Exception as e:\n-            # Si la serialización/validación falla aquí, logueamos el error y devolvemos un error interno\n-            logger.error(f\"Error al serializar el problema {problem.get('_id')} con Pydantic: {str(e)}\", exc_info=True)\n-            # Podrías decidir devolver un 500 o el mensaje de no encontrado, dependiendo de cómo quieras manejarlo\n-            # Devolver un 500 es más preciso si el problema *existe* pero no se pudo formatear\n-            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al procesar el problema.\")\n+            # Si la validación falla a pesar de la conversión (menos probable ahora)\n+            logger.error(f\"Error al validar o serializar el problema {problem.get('_id')} con Pydantic: {str(e)}\", exc_info=True)\n+            # Devolver un 500 para indicar que hubo un error interno procesando el problema encontrado\n+            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al procesar el problema encontrado.\")\n         # --- FIN MODIFICACIÓN ---\n \n     else:\n         # Si no se encontró ningún problema sin resolver con los criterios\n@@ -138,5 +146,6 @@\n         return NoProblemResponse(\n             message=f\"No se encontraron problemas sin resolver para la dificultad '{difficulty}'.\" if difficulty else \"No se encontraron problemas sin resolver.\"\n         )\n \n+\n # --- El endpoint /submit_answer irá aquí en un futuro paso ---\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746238348412,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -10,9 +10,9 @@\n # Importa tu dependencia para obtener el usuario actual\n from utils.auth_utils import get_current_user\n \n # Importa los modelos de respuesta (ahora incluyendo los nuevos)\n-from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse # Importa los nuevos modelos\n+from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse # Importa los nuevos modelos\n \n import logging\n logger = logging.getLogger(__name__)\n \n"
                },
                {
                    "date": 1746238593655,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,151 +1,290 @@\n # routers/logic.py\n-from fastapi import APIRouter, Depends, HTTPException, status, Query # Importa Query para parámetros de consulta\n+from fastapi import APIRouter, Depends, HTTPException, status, Query, Form\n from bson import ObjectId\n-from typing import Optional, Dict, List, Union # Importa Union\n+from typing import Optional, Dict, List, Union, Annotated # Asegúrate de tener Annotated si usas Python 3.9+ con FastAPI reciente\n from datetime import datetime\n \n-# Importa tu cliente de MongoDB\n-from mongodb_client import MongoDBClient\n+# Importa tu cliente de MongoDB (Ajusta la ruta si es necesario)\n+from ..mongodb_client import MongoDBClient # Asumiendo que está un nivel arriba\n \n-# Importa tu dependencia para obtener el usuario actual\n-from utils.auth_utils import get_current_user\n+# Importa tu dependencia para obtener el usuario actual (Ajusta la ruta si es necesario)\n+# Asumiremos que 'get_current_active_user' es la dependencia estándar para rutas protegidas\n+from ..utils.auth_utils import get_current_active_user\n \n-# Importa los modelos de respuesta (ahora incluyendo los nuevos)\n-from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse # Importa los nuevos modelos\n+# Importa los modelos/schemas Pydantic (Ajusta la ruta si es necesario)\n+# Asegúrate de que estos modelos estén definidos correctamente en ese archivo\n+from ..models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse\n \n import logging\n logger = logging.getLogger(__name__)\n \n router = APIRouter(\n-    prefix=\"/logic\", # Prefijo /logic\n-    tags=[\"Logic Problems\"],\n-    # dependencies=[Depends(get_current_user)] # Podrías añadirlo aquí si todas son protegidas\n+    # El prefijo se aplicará cuando incluyas este router en main.py\n+    # prefix=\"/auth/api/logic\", # <- NO pongas el prefijo completo aquí, solo la parte específica de este router\n+    prefix=\"/logic\",             # <- Prefijo relativo a donde se incluye en main.py\n+    tags=[\"Logic Problems\"],      # Etiqueta para la documentación\n )\n \n-# Instancia del cliente de MongoDB (ya la tienes)\n-mongo_client = MongoDBClient()\n+# --- Instancia del Cliente MongoDB ---\n+# Asumiendo que tienes una forma de obtener la instancia, por ejemplo:\n+# mongo_client = MongoDBClient()\n+# O podrías usar una dependencia si la configuración se carga al inicio\n+# Ejemplo simple (asegúrate de que esto funcione en tu estructura):\n+try:\n+    mongo_client = MongoDBClient()\n+    logger.info(\"MongoDBClient instanciado en routers/logic.py\")\n+except Exception as e:\n+    logger.error(f\"Error al instanciar MongoDBClient en routers/logic.py: {e}\")\n+    # Podrías lanzar un error aquí o manejarlo de otra forma si la conexión es crítica\n+    mongo_client = None # Asegúrate de manejar el caso donde mongo_client sea None\n \n-# --- Endpoint Existente ---\n-@router.get(\"/progress\", response_model=UserProgressResponse)\n+# --- Endpoint de Progreso ---\n+@router.get(\n+    \"/progress\",\n+    response_model=UserProgressResponse,\n+    summary=\"Obtiene el progreso del usuario autenticado\"\n+)\n async def get_user_progress(\n-    current_user: dict = Depends(get_current_user)\n+    # Usar la dependencia de autenticación consistente\n+    current_user: Annotated[dict, Depends(get_current_active_user)]\n ):\n-    # ... (Tu código para calcular el progreso aquí) ...\n-    user_id = current_user.get(\"_id\")\n+    \"\"\"\n+    Calcula y devuelve el progreso del usuario en problemas de lógica,\n+    basado en los ejercicios guardados en su perfil.\n+    Requiere autenticación.\n+    \"\"\"\n+    if mongo_client is None:\n+         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n+\n+    # Asumiendo que get_current_active_user devuelve un diccionario con _id y email\n+    user_id_str = current_user.get(\"user_id\") # O el nombre del campo correcto que devuelve tu dependencia\n     user_email = current_user.get(\"email\", \"N/A\")\n \n-    if not user_id or not isinstance(user_id, ObjectId):\n-         logger.error(f\"Usuario autenticado sin _id válido en el objeto retornado: {user_email}\")\n-         raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"No se pudo identificar al usuario\")\n+    if not user_id_str:\n+         logger.error(f\"Usuario autenticado sin ID recuperable: {user_email}\")\n+         raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"No se pudo identificar al usuario (ID ausente).\")\n \n+    # Convertir ID de string (del token quizás) a ObjectId para consultas DB\n+    try:\n+        user_id = ObjectId(user_id_str)\n+    except Exception:\n+         logger.error(f\"ID de usuario inválido en token para {user_email}: {user_id_str}\")\n+         raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Identificador de usuario inválido.\")\n \n     logger.info(f\"Solicitud de progreso para usuario: {user_email} (ID: {user_id})\")\n \n-    solved_exercises = current_user.get(\"ejercicios\", [])\n+    # Obtener datos frescos del usuario desde la DB, incluyendo 'ejercicios'\n+    # Es más seguro que depender de que el token tenga toda la data actualizada.\n+    db_user_data = await mongo_client.get_user_by_id(user_id)\n+    if not db_user_data:\n+         logger.error(f\"No se encontró el usuario con ID {user_id} en la base de datos.\")\n+         # Podría ser 404 o 401 dependiendo de tu lógica (¿token válido para usuario borrado?)\n+         raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Usuario no encontrado.\")\n \n+\n+    solved_exercises = db_user_data.get(\"ejercicios\", [])\n+\n+    # --- Lógica de Cálculo de Progreso (parece correcta) ---\n     progress_counts: Dict[str, int] = {\"basico\": 0, \"intermedio\": 0, \"avanzado\": 0}\n     progress_sums: Dict[str, float] = {\"basico\": 0.0, \"intermedio\": 0.0, \"avanzado\": 0.0}\n     total_solved_count = 0\n     total_grade_sum = 0.0\n \n     for exercise in solved_exercises:\n-        if isinstance(exercise, dict) and \"problem_difficulty\" in exercise and \"llm_grade\" in exercise:\n+        # Validaciones más robustas\n+        if isinstance(exercise, dict) and \\\n+           exercise.get(\"problem_difficulty\") in progress_counts and \\\n+           isinstance(exercise.get(\"llm_grade\"), (int, float)):\n+\n             difficulty = exercise[\"problem_difficulty\"]\n             grade = exercise[\"llm_grade\"]\n \n-            if difficulty in progress_counts and isinstance(grade, (int, float)):\n-                total_solved_count += 1\n-                total_grade_sum += grade\n-                progress_counts[difficulty] += 1\n-                progress_sums[difficulty] += grade\n-            else:\n-                 logger.warning(f\"Ejercicio con formato inesperado encontrado en historial de user_id {user_id}: {exercise}\")\n+            total_solved_count += 1\n+            total_grade_sum += grade\n+            progress_counts[difficulty] += 1\n+            progress_sums[difficulty] += grade\n+        else:\n+             logger.warning(f\"Ejercicio con formato/datos inesperados en historial de user_id {user_id}: {exercise}\")\n \n     progress_by_difficulty: Dict[str, DifficultyProgress] = {}\n-    for difficulty in [\"basico\", \"intermedio\", \"avanzado\"]:\n-        solved_count = progress_counts.get(difficulty, 0)\n-        grade_sum = progress_sums.get(difficulty, 0.0)\n-        average_grade = grade_sum / solved_count if solved_count > 0 else 0.0\n-        average_grade = round(average_grade, 2)\n-\n-        progress_by_difficulty[difficulty] = DifficultyProgress(\n-            solved_count=solved_count,\n-            average_grade=average_grade\n+    for difficulty_level in [\"basico\", \"intermedio\", \"avanzado\"]:\n+        count = progress_counts[difficulty_level]\n+        grade_sum = progress_sums[difficulty_level]\n\\ No newline at end of file\n+        avg_grade = round(grade_sum / count, 2) if count > 0 else 0.0\n+        progress_by_difficulty[difficulty_level] = DifficultyProgress(\n+            solved_count=count,\n+            average_grade=avg_grade\n         )\n \n-    overall_average_grade = total_grade_sum / total_solved_count if total_solved_count > 0 else 0.0\n-    overall_average_grade = round(overall_average_grade, 2)\n+    overall_avg = round(total_grade_sum / total_solved_count, 2) if total_solved_count > 0 else 0.0\n \n-    logger.info(f\"Progreso calculado para {user_email}: {total_solved_count} total, {progress_by_difficulty}, {overall_average_grade} avg\")\n+    logger.info(f\"Progreso calculado para {user_email}: Total={total_solved_count}, Avg={overall_avg}\")\n \n     return UserProgressResponse(\n         total_solved=total_solved_count,\n         progress_by_difficulty=progress_by_difficulty,\n-        overall_average_grade=overall_average_grade,\n+        overall_average_grade=overall_avg,\n         message=\"Tu progreso ha sido cargado.\"\n     )\n \n-\n-\n-\n-# --- Endpoint para obtener un problema (MODIFICADO DE NUEVO) ---\n-@router.get(\"/problem\", response_model=Union[ProblemResponse, NoProblemResponse])\n+# --- Endpoint para Obtener Problema ---\n+@router.get(\n+    \"/problem\",\n+    response_model=Union[ProblemResponse, NoProblemResponse], # Permite ambos tipos de respuesta\n+    summary=\"Obtiene un problema de lógica no resuelto por el usuario\"\n+)\n async def get_logic_problem(\n-    current_user: dict = Depends(get_current_user),\n-    difficulty: Optional[str] = Query(None, description=\"Dificultad del problema (ej. 'basico', 'intermedio', 'avanzado')\")\n+    current_user: Annotated[dict, Depends(get_current_active_user)],\n+    difficulty: Annotated[Optional[str], Query(None, description=\"Filtrar por dificultad (basico, intermedio, avanzado)\")] = None\n ):\n     \"\"\"\n-    Obtiene un problema de lógica aleatorio que el usuario autenticado no haya resuelto.\n-    Opcionalmente filtra por dificultad.\n-    Requiere autenticación (Bearer Token).\n+    Busca en la base de datos un problema de lógica que el usuario\n+    aún no haya resuelto, opcionalmente filtrado por dificultad.\n     \"\"\"\n-    user_id = current_user.get(\"_id\")\n+    if mongo_client is None:\n+         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n \n-    if not user_id or not isinstance(user_id, ObjectId):\n-         logger.error(f\"Usuario autenticado sin _id válido: {current_user.get('email', 'N/A')}\")\n-         raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"No se pudo identificar al usuario\")\n+    user_id_str = current_user.get(\"user_id\")\n+    user_email = current_user.get(\"email\", \"N/A\")\n \n+    if not user_id_str: # Validar ID del usuario\n+         logger.error(f\"Usuario autenticado sin ID recuperable: {user_email}\")\n+         raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"No se pudo identificar al usuario (ID ausente).\")\n+    try:\n+        user_id = ObjectId(user_id_str)\n+    except Exception:\n+         logger.error(f\"ID de usuario inválido en token para {user_email}: {user_id_str}\")\n+         raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Identificador de usuario inválido.\")\n+\n+    # Validar parámetro de dificultad si se proporciona\n     if difficulty is not None and difficulty not in [\"basico\", \"intermedio\", \"avanzado\"]:\n-         logger.warning(f\"Solicitud con dificultad inválida para user_id {user_id}: {difficulty}\")\n+         logger.warning(f\"Solicitud con dificultad inválida ({difficulty}) para user_id {user_id}\")\n          raise HTTPException(\n              status_code=status.HTTP_400_BAD_REQUEST,\n-             detail=\"La dificultad especificada es inválida. Usa 'basico', 'intermedio' o 'avanzado'.\"\n+             detail=\"Dificultad inválida. Usa 'basico', 'intermedio' o 'avanzado'.\"\n          )\n \n-    logger.info(f\"Solicitud de problema para user_id: {user_id}, dificultad: {difficulty}\")\n+    logger.info(f\"Buscando problema para user_id: {user_id}, dificultad: {difficulty or 'cualquiera'}\")\n \n-    problem = mongo_client.get_random_unsolved_problem(user_id, difficulty=difficulty)\n+    # Llamar a la función de la DB (asumiendo que existe)\n+    problem_dict = await mongo_client.get_random_unsolved_problem(user_id, difficulty=difficulty)\n \n-    if problem:\n-        # --- MODIFICACIÓN AQUÍ ---\n-        # El cliente de MongoDB devuelve un diccionario donde _id es un ObjectId.\n-        # Pydantic espera un string para el campo 'id' (alias '_id').\n-        # Convertimos el ObjectId a string ANTES de crear la instancia del modelo Pydantic.\n+    if problem_dict:\n+        logger.info(f\"Problema encontrado para {user_email}: ID={problem_dict.get('_id')}\")\n+        # Convertir _id a string para Pydantic y validar\n         try:\n-            # Crear una copia del diccionario para no modificar el resultado original del cliente DB si se reutiliza\n-            problem_dict_for_pydantic = problem.copy()\n-            # Convertir el ObjectId a string\n-            problem_dict_for_pydantic['_id'] = str(problem_dict_for_pydantic['_id'])\n+            # Importante: FastAPI espera que el campo 'id' del modelo Pydantic\n+            # se llene con el valor de '_id' de MongoDB. Pydantic v1 lo hacía\n+            # con alias, Pydantic v2 puede requerir configuración o manejo manual.\n+            # La forma más segura es asegurar que el modelo Pydantic tenga 'id'\n+            # y pasarle el valor de '_id' convertido a string.\n+            # Asumiendo que ProblemResponse tiene un campo `id: str`\n+             validated_problem = ProblemResponse(\n+                 id=str(problem_dict[\"_id\"]), # Convertir ObjectId a string para el campo 'id'\n+                 text=problem_dict[\"text\"],\n+                 difficulty=problem_dict[\"difficulty\"],\n+                 topics=problem_dict.get(\"topics\", []) # Usar .get para campos opcionales\n+             )\n+             # Pydantic valida los tipos al crear la instancia.\n+             return validated_problem # FastAPI serializará esto a JSON\n \n-            # Ahora creamos la instancia de ProblemResponse con el diccionario modificado\n-            problem_response_data = ProblemResponse(**problem_dict_for_pydantic)\n+        except Exception as e:\n+            logger.error(f\"Error al validar/mapear problema de DB a Pydantic para ID {problem_dict.get('_id')}: {e}\", exc_info=True)\n+            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error procesando datos del problema.\")\n+    else:\n+        # No se encontraron problemas\n+        logger.info(f\"No se encontraron problemas sin resolver para {user_email} con dificultad: {difficulty}\")\n+        message = f\"¡Felicidades! Parece que has resuelto todos los problemas de nivel '{difficulty}'.\" if difficulty else \"¡Felicidades! Parece que has resuelto todos los problemas.\"\n+        return NoProblemResponse(message=message)\n \n-            logger.info(f\"Validación y serialización exitosa del problema {problem_dict_for_pydantic['_id']}.\")\n-            return problem_response_data # Retornamos la instancia validada y lista para ser serializada a JSON por FastAPI\n \n-        except Exception as e:\n-            # Si la validación falla a pesar de la conversión (menos probable ahora)\n-            logger.error(f\"Error al validar o serializar el problema {problem.get('_id')} con Pydantic: {str(e)}\", exc_info=True)\n-            # Devolver un 500 para indicar que hubo un error interno procesando el problema encontrado\n-            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al procesar el problema encontrado.\")\n-        # --- FIN MODIFICACIÓN ---\n+# --- NUEVO Endpoint para Enviar Respuesta ---\n+@router.post(\n+    \"/submit_answer\",\n+    response_model=FeedbackResponse, # El frontend espera este modelo\n+    summary=\"Envía la respuesta de un usuario a un problema de lógica\",\n+    description=\"Recibe el ID del problema y la respuesta del usuario, la procesa (simulado), la guarda y devuelve un análisis y calificación.\"\n+)\n+async def submit_user_answer(\n+    current_user: Annotated[dict, Depends(get_current_active_user)],\n+    problem_id: Annotated[str, Form(...)], # ID del problema al que se responde\n+    user_answer: Annotated[str, Form(...)]  # Respuesta del usuario\n+):\n+    \"\"\"\n+    Endpoint para procesar y guardar la respuesta de un usuario.\n+    \"\"\"\n+    if mongo_client is None:\n+         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n \n+    user_id_str = current_user.get(\"user_id\")\n+    user_email = current_user.get(\"email\", \"N/A\")\n+\n+    # Validar IDs\n+    if not user_id_str:\n+         raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"No se pudo identificar al usuario (ID ausente).\")\n+    try:\n+        user_id_obj = ObjectId(user_id_str)\n+        problem_id_obj = ObjectId(problem_id) # Convertir ID de problema a ObjectId\n+    except Exception:\n+         logger.error(f\"ID de usuario o problema inválido: user='{user_id_str}', problem='{problem_id}'\")\n+         raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"ID de usuario o problema inválido.\")\n+\n+\n+    logger.info(f\"Usuario '{user_email}' (ID: {user_id_obj}) envió respuesta para problema '{problem_id_obj}'.\")\n+    logger.debug(f\"Respuesta recibida: '{user_answer}'\")\n+\n+    # --- Opcional: Verificar que el problema existe ---\n+    problem_data = await mongo_client.get_problem_by_id(problem_id_obj)\n+    if not problem_data:\n+         logger.error(f\"Intento de responder a problema inexistente ID: {problem_id_obj} por usuario {user_email}\")\n+         raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"El problema especificado no fue encontrado.\")\n+\n+    # --- LÓGICA DE PROCESAMIENTO (PLACEHOLDER) ---\n+    # Aquí llamarías al LLM real pasándole problem_data['text'] y user_answer\n+    analysis_text = f\"Análisis simulado para la respuesta: '{user_answer[:50]}...'.\"\n+    dummy_grade = 0\n+    if not user_answer:\n+        analysis_text += \" La respuesta estaba vacía.\"; dummy_grade = 0\n+    elif len(user_answer) < 20:\n+        analysis_text += \" La respuesta es muy corta.\"; dummy_grade = 1\n+    elif \"bucle\" in user_answer.lower() or \"iterar\" in user_answer.lower():\n+        analysis_text += \" Mencionaste bucles/iteración.\"; dummy_grade = 4\n+    elif \"condición\" in user_answer.lower() or \"si\" in user_answer.lower():\n+         analysis_text += \" Hablaste sobre condiciones.\"; dummy_grade = 3\n     else:\n-        # Si no se encontró ningún problema sin resolver con los criterios\n-        logger.info(f\"No se encontraron problemas sin resolver para user_id {user_id} con dificultad: {difficulty}. Retornando NoProblemResponse.\")\n-        return NoProblemResponse(\n-            message=f\"No se encontraron problemas sin resolver para la dificultad '{difficulty}'.\" if difficulty else \"No se encontraron problemas sin resolver.\"\n-        )\n+        analysis_text += \" Respuesta genérica recibida.\"; dummy_grade = 2\n+    final_grade = max(0, min(5, dummy_grade)) # Asegurar rango 0-5\n+    # --- FIN LÓGICA PLACEHOLDER ---\n \n+    # --- GUARDAR EL RESULTADO EN LA BASE DE DATOS ---\n+    submission_data = {\n+        \"problem_id\": problem_id_obj,\n+        \"problem_difficulty\": problem_data.get(\"difficulty\", \"desconocida\"), # Guardar dificultad original\n+        \"user_answer\": user_answer,\n+        \"analysis_received\": analysis_text, # Guardar análisis simulado\n+        \"llm_grade\": final_grade,          # Guardar nota simulada\n+        \"submission_timestamp\": datetime.utcnow()\n+    }\n \n-# --- El endpoint /submit_answer irá aquí en un futuro paso ---\n+    try:\n+        update_result = await mongo_client.add_solved_exercise_to_user(user_id_obj, submission_data)\n+        if update_result.modified_count == 0 and update_result.matched_count == 1:\n+             logger.warning(f\"No se modificó el usuario {user_id_obj} al añadir ejercicio (¿ya existía?), pero se encontró el usuario.\")\n+             # Considerar si esto es un error o no. Podría ser un re-intento.\n+        elif update_result.matched_count == 0:\n+             logger.error(f\"No se encontró el usuario {user_id_obj} para añadir el ejercicio resuelto.\")\n+             # Esto no debería pasar si el token es válido, pero por si acaso.\n+             raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Usuario no encontrado para guardar progreso.\")\n+        else:\n+             logger.info(f\"Ejercicio resuelto añadido correctamente al historial del usuario {user_id_obj}\")\n+\n+    except Exception as e:\n+        logger.error(f\"Error al guardar el ejercicio resuelto para user {user_id_obj}: {e}\", exc_info=True)\n+        # Decidir si fallar la solicitud o solo loguear y continuar\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al guardar el resultado del ejercicio.\")\n+\n+\n+    logger.info(f\"Evaluación simulada para {user_email}: Calificación={final_grade}\")\n+\n+    # Devolver el feedback al frontend\n+    return FeedbackResponse(analysis=analysis_text, grade=final_grade)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746238782752,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,44 +1,42 @@\n # routers/logic.py\n from fastapi import APIRouter, Depends, HTTPException, status, Query, Form\n from bson import ObjectId\n-from typing import Optional, Dict, List, Union, Annotated # Asegúrate de tener Annotated si usas Python 3.9+ con FastAPI reciente\n+from typing import Optional, Dict, List, Union, Annotated\n from datetime import datetime\n+import logging # Añadir import para logging\n \n-# Importa tu cliente de MongoDB (Ajusta la ruta si es necesario)\n-from ..mongodb_client import MongoDBClient # Asumiendo que está un nivel arriba\n+# --- CORREGIR IMPORTACIONES ---\n+# Asumiendo que mongodb_client.py está en daw_backend/\n+from mongodb_client import MongoDBClient # Ya no necesita ..\n \n-# Importa tu dependencia para obtener el usuario actual (Ajusta la ruta si es necesario)\n-# Asumiremos que 'get_current_active_user' es la dependencia estándar para rutas protegidas\n-from ..utils.auth_utils import get_current_active_user\n+# Asumiendo que auth_utils.py está en daw_backend/utils/\n+from utils.auth_utils import get_current_active_user # Ya no necesita ..\n \n-# Importa los modelos/schemas Pydantic (Ajusta la ruta si es necesario)\n-# Asegúrate de que estos modelos estén definidos correctamente en ese archivo\n-from ..models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse\n+# Asumiendo que logic.py está en daw_backend/models/\n+from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse # Ya no necesita ..\n+# --- FIN CORRECCIONES ---\n \n-import logging\n+\n logger = logging.getLogger(__name__)\n \n router = APIRouter(\n-    # El prefijo se aplicará cuando incluyas este router en main.py\n-    # prefix=\"/auth/api/logic\", # <- NO pongas el prefijo completo aquí, solo la parte específica de este router\n-    prefix=\"/logic\",             # <- Prefijo relativo a donde se incluye en main.py\n-    tags=[\"Logic Problems\"],      # Etiqueta para la documentación\n+    prefix=\"/logic\", # Prefijo relativo a donde se incluye en main.py\n+    tags=[\"Logic Problems\"],\n )\n \n # --- Instancia del Cliente MongoDB ---\n-# Asumiendo que tienes una forma de obtener la instancia, por ejemplo:\n-# mongo_client = MongoDBClient()\n-# O podrías usar una dependencia si la configuración se carga al inicio\n-# Ejemplo simple (asegúrate de que esto funcione en tu estructura):\n try:\n     mongo_client = MongoDBClient()\n     logger.info(\"MongoDBClient instanciado en routers/logic.py\")\n except Exception as e:\n     logger.error(f\"Error al instanciar MongoDBClient en routers/logic.py: {e}\")\n-    # Podrías lanzar un error aquí o manejarlo de otra forma si la conexión es crítica\n-    mongo_client = None # Asegúrate de manejar el caso donde mongo_client sea None\n+    mongo_client = None\n \n+# ... (El resto del código del archivo routers/logic.py que te di antes) ...\n+# Asegúrate de que el resto del código (los endpoints @router.get, @router.post)\n+# permanezca igual que en la versión completa anterior.\n+\n # --- Endpoint de Progreso ---\n @router.get(\n     \"/progress\",\n     response_model=UserProgressResponse,\n"
                },
                {
                    "date": 1746239444413,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -2,26 +2,24 @@\n from fastapi import APIRouter, Depends, HTTPException, status, Query, Form\n from bson import ObjectId\n from typing import Optional, Dict, List, Union, Annotated\n from datetime import datetime\n-import logging # Añadir import para logging\n+import logging\n \n-# --- CORREGIR IMPORTACIONES ---\n-# Asumiendo que mongodb_client.py está en daw_backend/\n-from mongodb_client import MongoDBClient # Ya no necesita ..\n+# Importa tu cliente de MongoDB (Ajusta la ruta si es necesario)\n+from mongodb_client import MongoDBClient # Usando import absoluto\n \n-# Asumiendo que auth_utils.py está en daw_backend/utils/\n-from utils.auth_utils import get_current_active_user # Ya no necesita ..\n+# --- CORRECCIÓN IMPORTACIÓN ---\n+# Importa tu dependencia para obtener el usuario actual (con el nombre correcto)\n+from utils.auth_utils import get_current_user # <--- Nombre corregido\n \n-# Asumiendo que logic.py está en daw_backend/models/\n-from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse # Ya no necesita ..\n-# --- FIN CORRECCIONES ---\n+# Importa los modelos/schemas Pydantic (Ajusta la ruta si es necesario)\n+from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse\n \n-\n logger = logging.getLogger(__name__)\n \n router = APIRouter(\n-    prefix=\"/logic\", # Prefijo relativo a donde se incluye en main.py\n+    prefix=\"/logic\",\n     tags=[\"Logic Problems\"],\n )\n \n # --- Instancia del Cliente MongoDB ---\n@@ -31,94 +29,68 @@\n except Exception as e:\n     logger.error(f\"Error al instanciar MongoDBClient en routers/logic.py: {e}\")\n     mongo_client = None\n \n-# ... (El resto del código del archivo routers/logic.py que te di antes) ...\n-# Asegúrate de que el resto del código (los endpoints @router.get, @router.post)\n-# permanezca igual que en la versión completa anterior.\n-\n # --- Endpoint de Progreso ---\n @router.get(\n     \"/progress\",\n     response_model=UserProgressResponse,\n     summary=\"Obtiene el progreso del usuario autenticado\"\n )\n async def get_user_progress(\n-    # Usar la dependencia de autenticación consistente\n-    current_user: Annotated[dict, Depends(get_current_active_user)]\n+    # --- CORRECCIÓN Depends ---\n+    # Usa la función de dependencia correcta. Devuelve el documento del usuario de la DB.\n+    current_db_user: Annotated[dict, Depends(get_current_user)] # <--- Nombre corregido\n ):\n     \"\"\"\n-    Calcula y devuelve el progreso del usuario en problemas de lógica,\n-    basado en los ejercicios guardados en su perfil.\n-    Requiere autenticación.\n+    Calcula y devuelve el progreso del usuario en problemas de lógica.\n     \"\"\"\n     if mongo_client is None:\n          raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n \n-    # Asumiendo que get_current_active_user devuelve un diccionario con _id y email\n-    user_id_str = current_user.get(\"user_id\") # O el nombre del campo correcto que devuelve tu dependencia\n-    user_email = current_user.get(\"email\", \"N/A\")\n+    # --- Acceso a Datos Corregido ---\n+    # get_current_user devuelve el documento de la DB, que ya tiene _id como ObjectId\n+    user_id = current_db_user.get(\"_id\") # Accede directamente a _id\n+    user_email = current_db_user.get(\"email\", \"N/A\")\n \n-    if not user_id_str:\n-         logger.error(f\"Usuario autenticado sin ID recuperable: {user_email}\")\n-         raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"No se pudo identificar al usuario (ID ausente).\")\n+    # Ya no es necesaria la conversión ObjectId(user_id_str), user_id ya es ObjectId\n+    if not user_id or not isinstance(user_id, ObjectId):\n+         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n+         # Esto indicaría un problema en get_current_user o en los datos de la DB\n+         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n \n-    # Convertir ID de string (del token quizás) a ObjectId para consultas DB\n-    try:\n-        user_id = ObjectId(user_id_str)\n-    except Exception:\n-         logger.error(f\"ID de usuario inválido en token para {user_email}: {user_id_str}\")\n-         raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Identificador de usuario inválido.\")\n-\n     logger.info(f\"Solicitud de progreso para usuario: {user_email} (ID: {user_id})\")\n \n-    # Obtener datos frescos del usuario desde la DB, incluyendo 'ejercicios'\n-    # Es más seguro que depender de que el token tenga toda la data actualizada.\n-    db_user_data = await mongo_client.get_user_by_id(user_id)\n-    if not db_user_data:\n-         logger.error(f\"No se encontró el usuario con ID {user_id} en la base de datos.\")\n-         # Podría ser 404 o 401 dependiendo de tu lógica (¿token válido para usuario borrado?)\n-         raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Usuario no encontrado.\")\n+    # La dependencia ya nos dio los datos frescos del usuario\n+    solved_exercises = current_db_user.get(\"ejercicios\", [])\n \n-\n-    solved_exercises = db_user_data.get(\"ejercicios\", [])\n-\n-    # --- Lógica de Cálculo de Progreso (parece correcta) ---\n+    # --- Lógica de Cálculo de Progreso (sin cambios) ---\n     progress_counts: Dict[str, int] = {\"basico\": 0, \"intermedio\": 0, \"avanzado\": 0}\n     progress_sums: Dict[str, float] = {\"basico\": 0.0, \"intermedio\": 0.0, \"avanzado\": 0.0}\n     total_solved_count = 0\n     total_grade_sum = 0.0\n-\n     for exercise in solved_exercises:\n-        # Validaciones más robustas\n         if isinstance(exercise, dict) and \\\n            exercise.get(\"problem_difficulty\") in progress_counts and \\\n            isinstance(exercise.get(\"llm_grade\"), (int, float)):\n-\n             difficulty = exercise[\"problem_difficulty\"]\n             grade = exercise[\"llm_grade\"]\n-\n             total_solved_count += 1\n             total_grade_sum += grade\n             progress_counts[difficulty] += 1\n             progress_sums[difficulty] += grade\n         else:\n              logger.warning(f\"Ejercicio con formato/datos inesperados en historial de user_id {user_id}: {exercise}\")\n-\n     progress_by_difficulty: Dict[str, DifficultyProgress] = {}\n     for difficulty_level in [\"basico\", \"intermedio\", \"avanzado\"]:\n         count = progress_counts[difficulty_level]\n         grade_sum = progress_sums[difficulty_level]\n         avg_grade = round(grade_sum / count, 2) if count > 0 else 0.0\n         progress_by_difficulty[difficulty_level] = DifficultyProgress(\n-            solved_count=count,\n-            average_grade=avg_grade\n+            solved_count=count, average_grade=avg_grade\n         )\n-\n     overall_avg = round(total_grade_sum / total_solved_count, 2) if total_solved_count > 0 else 0.0\n-\n     logger.info(f\"Progreso calculado para {user_email}: Total={total_solved_count}, Avg={overall_avg}\")\n-\n     return UserProgressResponse(\n         total_solved=total_solved_count,\n         progress_by_difficulty=progress_by_difficulty,\n         overall_average_grade=overall_avg,\n@@ -127,13 +99,14 @@\n \n # --- Endpoint para Obtener Problema ---\n @router.get(\n     \"/problem\",\n-    response_model=Union[ProblemResponse, NoProblemResponse], # Permite ambos tipos de respuesta\n+    response_model=Union[ProblemResponse, NoProblemResponse],\n     summary=\"Obtiene un problema de lógica no resuelto por el usuario\"\n )\n async def get_logic_problem(\n-    current_user: Annotated[dict, Depends(get_current_active_user)],\n+    # --- CORRECCIÓN Depends ---\n+    current_db_user: Annotated[dict, Depends(get_current_user)], # <--- Nombre corregido\n     difficulty: Annotated[Optional[str], Query(None, description=\"Filtrar por dificultad (basico, intermedio, avanzado)\")] = None\n ):\n     \"\"\"\n     Busca en la base de datos un problema de lógica que el usuario\n@@ -141,148 +114,117 @@\n     \"\"\"\n     if mongo_client is None:\n          raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n \n-    user_id_str = current_user.get(\"user_id\")\n-    user_email = current_user.get(\"email\", \"N/A\")\n+    # --- Acceso a Datos Corregido ---\n+    user_id = current_db_user.get(\"_id\") # Obtiene ObjectId directamente\n+    user_email = current_db_user.get(\"email\", \"N/A\")\n \n-    if not user_id_str: # Validar ID del usuario\n-         logger.error(f\"Usuario autenticado sin ID recuperable: {user_email}\")\n-         raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"No se pudo identificar al usuario (ID ausente).\")\n-    try:\n-        user_id = ObjectId(user_id_str)\n-    except Exception:\n-         logger.error(f\"ID de usuario inválido en token para {user_email}: {user_id_str}\")\n-         raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Identificador de usuario inválido.\")\n+    if not user_id or not isinstance(user_id, ObjectId): # Verifica que sea ObjectId\n+         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n+         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener ID de usuario.\")\n \n-    # Validar parámetro de dificultad si se proporciona\n     if difficulty is not None and difficulty not in [\"basico\", \"intermedio\", \"avanzado\"]:\n          logger.warning(f\"Solicitud con dificultad inválida ({difficulty}) para user_id {user_id}\")\n-         raise HTTPException(\n-             status_code=status.HTTP_400_BAD_REQUEST,\n-             detail=\"Dificultad inválida. Usa 'basico', 'intermedio' o 'avanzado'.\"\n-         )\n+         raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Dificultad inválida.\")\n \n     logger.info(f\"Buscando problema para user_id: {user_id}, dificultad: {difficulty or 'cualquiera'}\")\n \n-    # Llamar a la función de la DB (asumiendo que existe)\n     problem_dict = await mongo_client.get_random_unsolved_problem(user_id, difficulty=difficulty)\n \n     if problem_dict:\n         logger.info(f\"Problema encontrado para {user_email}: ID={problem_dict.get('_id')}\")\n-        # Convertir _id a string para Pydantic y validar\n         try:\n-            # Importante: FastAPI espera que el campo 'id' del modelo Pydantic\n-            # se llene con el valor de '_id' de MongoDB. Pydantic v1 lo hacía\n-            # con alias, Pydantic v2 puede requerir configuración o manejo manual.\n-            # La forma más segura es asegurar que el modelo Pydantic tenga 'id'\n-            # y pasarle el valor de '_id' convertido a string.\n-            # Asumiendo que ProblemResponse tiene un campo `id: str`\n+             # Asume que ProblemResponse tiene campo 'id: str' y otros campos coinciden\n              validated_problem = ProblemResponse(\n-                 id=str(problem_dict[\"_id\"]), # Convertir ObjectId a string para el campo 'id'\n+                 id=str(problem_dict[\"_id\"]), # Convertir ObjectId a string\n                  text=problem_dict[\"text\"],\n                  difficulty=problem_dict[\"difficulty\"],\n-                 topics=problem_dict.get(\"topics\", []) # Usar .get para campos opcionales\n+                 topics=problem_dict.get(\"topics\", [])\n              )\n-             # Pydantic valida los tipos al crear la instancia.\n-             return validated_problem # FastAPI serializará esto a JSON\n-\n+             return validated_problem\n         except Exception as e:\n-            logger.error(f\"Error al validar/mapear problema de DB a Pydantic para ID {problem_dict.get('_id')}: {e}\", exc_info=True)\n+            logger.error(f\"Error al validar/mapear problema Pydantic ID {problem_dict.get('_id')}: {e}\", exc_info=True)\n             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error procesando datos del problema.\")\n     else:\n-        # No se encontraron problemas\n         logger.info(f\"No se encontraron problemas sin resolver para {user_email} con dificultad: {difficulty}\")\n         message = f\"¡Felicidades! Parece que has resuelto todos los problemas de nivel '{difficulty}'.\" if difficulty else \"¡Felicidades! Parece que has resuelto todos los problemas.\"\n         return NoProblemResponse(message=message)\n \n-\n-# --- NUEVO Endpoint para Enviar Respuesta ---\n+# --- Endpoint para Enviar Respuesta ---\n @router.post(\n     \"/submit_answer\",\n-    response_model=FeedbackResponse, # El frontend espera este modelo\n+    response_model=FeedbackResponse,\n     summary=\"Envía la respuesta de un usuario a un problema de lógica\",\n-    description=\"Recibe el ID del problema y la respuesta del usuario, la procesa (simulado), la guarda y devuelve un análisis y calificación.\"\n )\n async def submit_user_answer(\n-    current_user: Annotated[dict, Depends(get_current_active_user)],\n-    problem_id: Annotated[str, Form(...)], # ID del problema al que se responde\n-    user_answer: Annotated[str, Form(...)]  # Respuesta del usuario\n+    # --- CORRECCIÓN Depends ---\n+    current_db_user: Annotated[dict, Depends(get_current_user)], # <--- Nombre corregido\n+    problem_id: Annotated[str, Form(...)],\n+    user_answer: Annotated[str, Form(...)]\n ):\n     \"\"\"\n     Endpoint para procesar y guardar la respuesta de un usuario.\n     \"\"\"\n     if mongo_client is None:\n          raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n \n-    user_id_str = current_user.get(\"user_id\")\n-    user_email = current_user.get(\"email\", \"N/A\")\n+    # --- Acceso a Datos Corregido ---\n+    user_id = current_db_user.get(\"_id\") # Obtiene ObjectId directamente\n+    user_email = current_db_user.get(\"email\", \"N/A\")\n \n-    # Validar IDs\n-    if not user_id_str:\n-         raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"No se pudo identificar al usuario (ID ausente).\")\n+    if not user_id or not isinstance(user_id, ObjectId): # Verifica que sea ObjectId\n+         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n+         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener ID de usuario.\")\n+\n+    # Validar problem_id\n     try:\n-        user_id_obj = ObjectId(user_id_str)\n-        problem_id_obj = ObjectId(problem_id) # Convertir ID de problema a ObjectId\n+        problem_id_obj = ObjectId(problem_id)\n     except Exception:\n-         logger.error(f\"ID de usuario o problema inválido: user='{user_id_str}', problem='{problem_id}'\")\n-         raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"ID de usuario o problema inválido.\")\n+         logger.error(f\"ID de problema inválido recibido: '{problem_id}' para usuario {user_email}\")\n+         raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"ID de problema inválido.\")\n \n-\n-    logger.info(f\"Usuario '{user_email}' (ID: {user_id_obj}) envió respuesta para problema '{problem_id_obj}'.\")\n+    logger.info(f\"Usuario '{user_email}' (ID: {user_id}) envió respuesta para problema '{problem_id_obj}'.\")\n     logger.debug(f\"Respuesta recibida: '{user_answer}'\")\n \n-    # --- Opcional: Verificar que el problema existe ---\n     problem_data = await mongo_client.get_problem_by_id(problem_id_obj)\n     if not problem_data:\n          logger.error(f\"Intento de responder a problema inexistente ID: {problem_id_obj} por usuario {user_email}\")\n          raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"El problema especificado no fue encontrado.\")\n \n-    # --- LÓGICA DE PROCESAMIENTO (PLACEHOLDER) ---\n-    # Aquí llamarías al LLM real pasándole problem_data['text'] y user_answer\n+    # --- LÓGICA DE PROCESAMIENTO (PLACEHOLDER - sin cambios) ---\n     analysis_text = f\"Análisis simulado para la respuesta: '{user_answer[:50]}...'.\"\n     dummy_grade = 0\n-    if not user_answer:\n-        analysis_text += \" La respuesta estaba vacía.\"; dummy_grade = 0\n-    elif len(user_answer) < 20:\n-        analysis_text += \" La respuesta es muy corta.\"; dummy_grade = 1\n-    elif \"bucle\" in user_answer.lower() or \"iterar\" in user_answer.lower():\n-        analysis_text += \" Mencionaste bucles/iteración.\"; dummy_grade = 4\n-    elif \"condición\" in user_answer.lower() or \"si\" in user_answer.lower():\n-         analysis_text += \" Hablaste sobre condiciones.\"; dummy_grade = 3\n-    else:\n-        analysis_text += \" Respuesta genérica recibida.\"; dummy_grade = 2\n-    final_grade = max(0, min(5, dummy_grade)) # Asegurar rango 0-5\n+    if not user_answer: analysis_text += \" La respuesta estaba vacía.\"; dummy_grade = 0\n+    elif len(user_answer) < 20: analysis_text += \" La respuesta es muy corta.\"; dummy_grade = 1\n+    elif \"bucle\" in user_answer.lower() or \"iterar\" in user_answer.lower(): analysis_text += \" Mencionaste bucles/iteración.\"; dummy_grade = 4\n+    elif \"condición\" in user_answer.lower() or \"si\" in user_answer.lower(): analysis_text += \" Hablaste sobre condiciones.\"; dummy_grade = 3\n+    else: analysis_text += \" Respuesta genérica recibida.\"; dummy_grade = 2\n+    final_grade = max(0, min(5, dummy_grade))\n     # --- FIN LÓGICA PLACEHOLDER ---\n \n-    # --- GUARDAR EL RESULTADO EN LA BASE DE DATOS ---\n+    # --- GUARDAR EL RESULTADO EN LA BASE DE DATOS (sin cambios) ---\n     submission_data = {\n         \"problem_id\": problem_id_obj,\n-        \"problem_difficulty\": problem_data.get(\"difficulty\", \"desconocida\"), # Guardar dificultad original\n+        \"problem_difficulty\": problem_data.get(\"difficulty\", \"desconocida\"),\n         \"user_answer\": user_answer,\n-        \"analysis_received\": analysis_text, # Guardar análisis simulado\n-        \"llm_grade\": final_grade,          # Guardar nota simulada\n+        \"analysis_received\": analysis_text,\n+        \"llm_grade\": final_grade,\n         \"submission_timestamp\": datetime.utcnow()\n     }\n-\n     try:\n-        update_result = await mongo_client.add_solved_exercise_to_user(user_id_obj, submission_data)\n+        update_result = await mongo_client.add_solved_exercise_to_user(user_id, submission_data)\n         if update_result.modified_count == 0 and update_result.matched_count == 1:\n-             logger.warning(f\"No se modificó el usuario {user_id_obj} al añadir ejercicio (¿ya existía?), pero se encontró el usuario.\")\n-             # Considerar si esto es un error o no. Podría ser un re-intento.\n+             logger.warning(f\"No se modificó el usuario {user_id} al añadir ejercicio, pero se encontró.\")\n         elif update_result.matched_count == 0:\n-             logger.error(f\"No se encontró el usuario {user_id_obj} para añadir el ejercicio resuelto.\")\n-             # Esto no debería pasar si el token es válido, pero por si acaso.\n+             logger.error(f\"No se encontró el usuario {user_id} para añadir el ejercicio resuelto.\")\n              raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Usuario no encontrado para guardar progreso.\")\n         else:\n-             logger.info(f\"Ejercicio resuelto añadido correctamente al historial del usuario {user_id_obj}\")\n-\n+             logger.info(f\"Ejercicio resuelto añadido correctamente al historial del usuario {user_id}\")\n     except Exception as e:\n-        logger.error(f\"Error al guardar el ejercicio resuelto para user {user_id_obj}: {e}\", exc_info=True)\n-        # Decidir si fallar la solicitud o solo loguear y continuar\n+        logger.error(f\"Error al guardar el ejercicio resuelto para user {user_id}: {e}\", exc_info=True)\n         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al guardar el resultado del ejercicio.\")\n \n-\n     logger.info(f\"Evaluación simulada para {user_email}: Calificación={final_grade}\")\n \n     # Devolver el feedback al frontend\n     return FeedbackResponse(analysis=analysis_text, grade=final_grade)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746239613624,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,70 +1,68 @@\n # routers/logic.py\n from fastapi import APIRouter, Depends, HTTPException, status, Query, Form\n from bson import ObjectId\n-from typing import Optional, Dict, List, Union, Annotated\n+from typing import Optional, Dict, List, Union, Annotated # Asegúrate de tener Annotated si usas Python 3.9+ con FastAPI reciente\n from datetime import datetime\n import logging\n \n # Importa tu cliente de MongoDB (Ajusta la ruta si es necesario)\n from mongodb_client import MongoDBClient # Usando import absoluto\n \n-# --- CORRECCIÓN IMPORTACIÓN ---\n-# Importa tu dependencia para obtener el usuario actual (con el nombre correcto)\n-from utils.auth_utils import get_current_user # <--- Nombre corregido\n+# Importa tu dependencia para obtener el usuario actual (Ajusta la ruta si es necesario)\n+from utils.auth_utils import get_current_user # Nombre corregido\n \n # Importa los modelos/schemas Pydantic (Ajusta la ruta si es necesario)\n from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse\n \n logger = logging.getLogger(__name__)\n \n router = APIRouter(\n-    prefix=\"/logic\",\n-    tags=[\"Logic Problems\"],\n+    prefix=\"/logic\",             # Prefijo relativo a donde se incluye en main.py\n+    tags=[\"Logic Problems\"],      # Etiqueta para la documentación\n )\n \n # --- Instancia del Cliente MongoDB ---\n try:\n     mongo_client = MongoDBClient()\n     logger.info(\"MongoDBClient instanciado en routers/logic.py\")\n except Exception as e:\n     logger.error(f\"Error al instanciar MongoDBClient en routers/logic.py: {e}\")\n-    mongo_client = None\n+    mongo_client = None # Asegúrate de manejar el caso donde mongo_client sea None\n \n # --- Endpoint de Progreso ---\n @router.get(\n     \"/progress\",\n     response_model=UserProgressResponse,\n     summary=\"Obtiene el progreso del usuario autenticado\"\n )\n async def get_user_progress(\n-    # --- CORRECCIÓN Depends ---\n-    # Usa la función de dependencia correcta. Devuelve el documento del usuario de la DB.\n-    current_db_user: Annotated[dict, Depends(get_current_user)] # <--- Nombre corregido\n+    current_db_user: Annotated[dict, Depends(get_current_user)] # Nombre corregido\n ):\n     \"\"\"\n     Calcula y devuelve el progreso del usuario en problemas de lógica.\n     \"\"\"\n     if mongo_client is None:\n          raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n \n-    # --- Acceso a Datos Corregido ---\n-    # get_current_user devuelve el documento de la DB, que ya tiene _id como ObjectId\n-    user_id = current_db_user.get(\"_id\") # Accede directamente a _id\n+    user_id = current_db_user.get(\"_id\") # Accede directamente a _id (ObjectId)\n     user_email = current_db_user.get(\"email\", \"N/A\")\n \n-    # Ya no es necesaria la conversión ObjectId(user_id_str), user_id ya es ObjectId\n     if not user_id or not isinstance(user_id, ObjectId):\n          logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n-         # Esto indicaría un problema en get_current_user o en los datos de la DB\n          raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n \n     logger.info(f\"Solicitud de progreso para usuario: {user_email} (ID: {user_id})\")\n \n-    # La dependencia ya nos dio los datos frescos del usuario\n-    solved_exercises = current_db_user.get(\"ejercicios\", [])\n+    # Obtener datos frescos incluyendo 'ejercicios'\n+    db_user_data = await mongo_client.get_user_by_id(user_id)\n+    if not db_user_data:\n+         logger.error(f\"No se encontró el usuario con ID {user_id} en la base de datos.\")\n+         raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Usuario no encontrado.\")\n \n-    # --- Lógica de Cálculo de Progreso (sin cambios) ---\n+    solved_exercises = db_user_data.get(\"ejercicios\", [])\n+\n+    # --- Lógica de Cálculo de Progreso ---\n     progress_counts: Dict[str, int] = {\"basico\": 0, \"intermedio\": 0, \"avanzado\": 0}\n     progress_sums: Dict[str, float] = {\"basico\": 0.0, \"intermedio\": 0.0, \"avanzado\": 0.0}\n     total_solved_count = 0\n     total_grade_sum = 0.0\n@@ -103,24 +101,24 @@\n     response_model=Union[ProblemResponse, NoProblemResponse],\n     summary=\"Obtiene un problema de lógica no resuelto por el usuario\"\n )\n async def get_logic_problem(\n-    # --- CORRECCIÓN Depends ---\n-    current_db_user: Annotated[dict, Depends(get_current_user)], # <--- Nombre corregido\n-    difficulty: Annotated[Optional[str], Query(None, description=\"Filtrar por dificultad (basico, intermedio, avanzado)\")] = None\n+    current_db_user: Annotated[dict, Depends(get_current_user)], # Usa nombre corregido\n+    # --- CORRECCIÓN DE Assertion Error ---\n+    difficulty: Annotated[str | None, Query(description=\"Filtrar por dificultad (basico, intermedio, avanzado)\")] = None # Default fuera de Annotated\n+    # --- FIN CORRECCIÓN ---\n ):\n     \"\"\"\n     Busca en la base de datos un problema de lógica que el usuario\n     aún no haya resuelto, opcionalmente filtrado por dificultad.\n     \"\"\"\n     if mongo_client is None:\n          raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n \n-    # --- Acceso a Datos Corregido ---\n-    user_id = current_db_user.get(\"_id\") # Obtiene ObjectId directamente\n+    user_id = current_db_user.get(\"_id\") # Obtiene ObjectId\n     user_email = current_db_user.get(\"email\", \"N/A\")\n \n-    if not user_id or not isinstance(user_id, ObjectId): # Verifica que sea ObjectId\n+    if not user_id or not isinstance(user_id, ObjectId):\n          logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n          raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener ID de usuario.\")\n \n     if difficulty is not None and difficulty not in [\"basico\", \"intermedio\", \"avanzado\"]:\n@@ -133,9 +131,9 @@\n \n     if problem_dict:\n         logger.info(f\"Problema encontrado para {user_email}: ID={problem_dict.get('_id')}\")\n         try:\n-             # Asume que ProblemResponse tiene campo 'id: str' y otros campos coinciden\n+             # Asume que ProblemResponse tiene campo 'id: str'\n              validated_problem = ProblemResponse(\n                  id=str(problem_dict[\"_id\"]), # Convertir ObjectId a string\n                  text=problem_dict[\"text\"],\n                  difficulty=problem_dict[\"difficulty\"],\n@@ -149,17 +147,17 @@\n         logger.info(f\"No se encontraron problemas sin resolver para {user_email} con dificultad: {difficulty}\")\n         message = f\"¡Felicidades! Parece que has resuelto todos los problemas de nivel '{difficulty}'.\" if difficulty else \"¡Felicidades! Parece que has resuelto todos los problemas.\"\n         return NoProblemResponse(message=message)\n \n+\n # --- Endpoint para Enviar Respuesta ---\n @router.post(\n     \"/submit_answer\",\n-    response_model=FeedbackResponse,\n+    response_model=FeedbackResponse, # El frontend espera este modelo\n     summary=\"Envía la respuesta de un usuario a un problema de lógica\",\n )\n async def submit_user_answer(\n-    # --- CORRECCIÓN Depends ---\n-    current_db_user: Annotated[dict, Depends(get_current_user)], # <--- Nombre corregido\n+    current_db_user: Annotated[dict, Depends(get_current_user)], # Usa nombre corregido\n     problem_id: Annotated[str, Form(...)],\n     user_answer: Annotated[str, Form(...)]\n ):\n     \"\"\"\n@@ -167,17 +165,15 @@\n     \"\"\"\n     if mongo_client is None:\n          raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n \n-    # --- Acceso a Datos Corregido ---\n-    user_id = current_db_user.get(\"_id\") # Obtiene ObjectId directamente\n+    user_id = current_db_user.get(\"_id\") # Obtiene ObjectId\n     user_email = current_db_user.get(\"email\", \"N/A\")\n \n-    if not user_id or not isinstance(user_id, ObjectId): # Verifica que sea ObjectId\n+    if not user_id or not isinstance(user_id, ObjectId):\n          logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n          raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener ID de usuario.\")\n \n-    # Validar problem_id\n     try:\n         problem_id_obj = ObjectId(problem_id)\n     except Exception:\n          logger.error(f\"ID de problema inválido recibido: '{problem_id}' para usuario {user_email}\")\n@@ -190,9 +186,9 @@\n     if not problem_data:\n          logger.error(f\"Intento de responder a problema inexistente ID: {problem_id_obj} por usuario {user_email}\")\n          raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"El problema especificado no fue encontrado.\")\n \n-    # --- LÓGICA DE PROCESAMIENTO (PLACEHOLDER - sin cambios) ---\n+    # --- LÓGICA DE PROCESAMIENTO (PLACEHOLDER) ---\n     analysis_text = f\"Análisis simulado para la respuesta: '{user_answer[:50]}...'.\"\n     dummy_grade = 0\n     if not user_answer: analysis_text += \" La respuesta estaba vacía.\"; dummy_grade = 0\n     elif len(user_answer) < 20: analysis_text += \" La respuesta es muy corta.\"; dummy_grade = 1\n@@ -201,18 +197,19 @@\n     else: analysis_text += \" Respuesta genérica recibida.\"; dummy_grade = 2\n     final_grade = max(0, min(5, dummy_grade))\n     # --- FIN LÓGICA PLACEHOLDER ---\n \n-    # --- GUARDAR EL RESULTADO EN LA BASE DE DATOS (sin cambios) ---\n+    # --- GUARDAR EL RESULTADO EN LA BASE DE DATOS ---\n     submission_data = {\n         \"problem_id\": problem_id_obj,\n         \"problem_difficulty\": problem_data.get(\"difficulty\", \"desconocida\"),\n         \"user_answer\": user_answer,\n-        \"analysis_received\": analysis_text,\n-        \"llm_grade\": final_grade,\n+        \"analysis_received\": analysis_text, # Guardar análisis simulado\n+        \"llm_grade\": final_grade,          # Guardar nota simulada\n         \"submission_timestamp\": datetime.utcnow()\n     }\n     try:\n+        # Asume que esta función existe en tu cliente mongo\n         update_result = await mongo_client.add_solved_exercise_to_user(user_id, submission_data)\n         if update_result.modified_count == 0 and update_result.matched_count == 1:\n              logger.warning(f\"No se modificó el usuario {user_id} al añadir ejercicio, pero se encontró.\")\n         elif update_result.matched_count == 0:\n"
                },
                {
                    "date": 1746240175694,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,68 +1,72 @@\n # routers/logic.py\n from fastapi import APIRouter, Depends, HTTPException, status, Query, Form\n from bson import ObjectId\n-from typing import Optional, Dict, List, Union, Annotated # Asegúrate de tener Annotated si usas Python 3.9+ con FastAPI reciente\n+from typing import Optional, Dict, List, Union, Annotated\n from datetime import datetime\n import logging\n+import asyncio # <--- AÑADIR IMPORT\n \n-# Importa tu cliente de MongoDB (Ajusta la ruta si es necesario)\n-from mongodb_client import MongoDBClient # Usando import absoluto\n+# Importa tu cliente de MongoDB\n+from mongodb_client import MongoDBClient\n \n-# Importa tu dependencia para obtener el usuario actual (Ajusta la ruta si es necesario)\n-from utils.auth_utils import get_current_user # Nombre corregido\n+# Importa tu dependencia de autenticación\n+from utils.auth_utils import get_current_user\n \n-# Importa los modelos/schemas Pydantic (Ajusta la ruta si es necesario)\n+# Importa los modelos/schemas Pydantic\n from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse\n \n logger = logging.getLogger(__name__)\n \n router = APIRouter(\n-    prefix=\"/logic\",             # Prefijo relativo a donde se incluye en main.py\n-    tags=[\"Logic Problems\"],      # Etiqueta para la documentación\n+    prefix=\"/logic\",\n+    tags=[\"Logic Problems\"],\n )\n \n-# --- Instancia del Cliente MongoDB ---\n+# Instancia del Cliente MongoDB\n try:\n     mongo_client = MongoDBClient()\n     logger.info(\"MongoDBClient instanciado en routers/logic.py\")\n except Exception as e:\n     logger.error(f\"Error al instanciar MongoDBClient en routers/logic.py: {e}\")\n-    mongo_client = None # Asegúrate de manejar el caso donde mongo_client sea None\n+    mongo_client = None\n \n # --- Endpoint de Progreso ---\n @router.get(\n     \"/progress\",\n     response_model=UserProgressResponse,\n     summary=\"Obtiene el progreso del usuario autenticado\"\n )\n async def get_user_progress(\n-    current_db_user: Annotated[dict, Depends(get_current_user)] # Nombre corregido\n+    current_db_user: Annotated[dict, Depends(get_current_user)]\n ):\n-    \"\"\"\n-    Calcula y devuelve el progreso del usuario en problemas de lógica.\n-    \"\"\"\n     if mongo_client is None:\n          raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n \n-    user_id = current_db_user.get(\"_id\") # Accede directamente a _id (ObjectId)\n+    user_id = current_db_user.get(\"_id\")\n     user_email = current_db_user.get(\"email\", \"N/A\")\n \n     if not user_id or not isinstance(user_id, ObjectId):\n          logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n          raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n \n     logger.info(f\"Solicitud de progreso para usuario: {user_email} (ID: {user_id})\")\n \n-    # Obtener datos frescos incluyendo 'ejercicios'\n-    db_user_data = await mongo_client.get_user_by_id(user_id)\n+    # --- Ejecutar llamada síncrona en thread ---\n+    try:\n+        db_user_data = await asyncio.to_thread(mongo_client.get_user_by_id, user_id) # <--- CAMBIO\n+    except Exception as db_error:\n+        logger.error(f\"Error de base de datos al obtener usuario {user_id} para progreso: {db_error}\", exc_info=True)\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al consultar datos del usuario.\")\n+    # --- Fin cambio ---\n+\n     if not db_user_data:\n          logger.error(f\"No se encontró el usuario con ID {user_id} en la base de datos.\")\n          raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Usuario no encontrado.\")\n \n     solved_exercises = db_user_data.get(\"ejercicios\", [])\n \n-    # --- Lógica de Cálculo de Progreso ---\n+    # Lógica de Cálculo (sin cambios)...\n     progress_counts: Dict[str, int] = {\"basico\": 0, \"intermedio\": 0, \"avanzado\": 0}\n     progress_sums: Dict[str, float] = {\"basico\": 0.0, \"intermedio\": 0.0, \"avanzado\": 0.0}\n     total_solved_count = 0\n     total_grade_sum = 0.0\n@@ -101,21 +105,15 @@\n     response_model=Union[ProblemResponse, NoProblemResponse],\n     summary=\"Obtiene un problema de lógica no resuelto por el usuario\"\n )\n async def get_logic_problem(\n-    current_db_user: Annotated[dict, Depends(get_current_user)], # Usa nombre corregido\n-    # --- CORRECCIÓN DE Assertion Error ---\n-    difficulty: Annotated[str | None, Query(description=\"Filtrar por dificultad (basico, intermedio, avanzado)\")] = None # Default fuera de Annotated\n-    # --- FIN CORRECCIÓN ---\n+    current_db_user: Annotated[dict, Depends(get_current_user)],\n+    difficulty: Annotated[str | None, Query(description=\"Filtrar por dificultad (basico, intermedio, avanzado)\")] = None\n ):\n-    \"\"\"\n-    Busca en la base de datos un problema de lógica que el usuario\n-    aún no haya resuelto, opcionalmente filtrado por dificultad.\n-    \"\"\"\n     if mongo_client is None:\n          raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n \n-    user_id = current_db_user.get(\"_id\") # Obtiene ObjectId\n+    user_id = current_db_user.get(\"_id\")\n     user_email = current_db_user.get(\"email\", \"N/A\")\n \n     if not user_id or not isinstance(user_id, ObjectId):\n          logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n@@ -126,19 +124,22 @@\n          raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Dificultad inválida.\")\n \n     logger.info(f\"Buscando problema para user_id: {user_id}, dificultad: {difficulty or 'cualquiera'}\")\n \n-    problem_dict = await mongo_client.get_random_unsolved_problem(user_id, difficulty=difficulty)\n+    # --- Ejecutar llamada síncrona en thread ---\n+    try:\n+        problem_dict = await asyncio.to_thread(mongo_client.get_random_unsolved_problem, user_id, difficulty=difficulty) # <--- CAMBIO\n+    except Exception as db_error:\n+        logger.error(f\"Error de base de datos al obtener problema para usuario {user_id}: {db_error}\", exc_info=True)\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al consultar problemas.\")\n+    # --- Fin cambio ---\n \n     if problem_dict:\n         logger.info(f\"Problema encontrado para {user_email}: ID={problem_dict.get('_id')}\")\n         try:\n-             # Asume que ProblemResponse tiene campo 'id: str'\n              validated_problem = ProblemResponse(\n-                 id=str(problem_dict[\"_id\"]), # Convertir ObjectId a string\n-                 text=problem_dict[\"text\"],\n-                 difficulty=problem_dict[\"difficulty\"],\n-                 topics=problem_dict.get(\"topics\", [])\n+                 id=str(problem_dict[\"_id\"]), text=problem_dict[\"text\"],\n+                 difficulty=problem_dict[\"difficulty\"], topics=problem_dict.get(\"topics\", [])\n              )\n              return validated_problem\n         except Exception as e:\n             logger.error(f\"Error al validar/mapear problema Pydantic ID {problem_dict.get('_id')}: {e}\", exc_info=True)\n@@ -151,23 +152,20 @@\n \n # --- Endpoint para Enviar Respuesta ---\n @router.post(\n     \"/submit_answer\",\n-    response_model=FeedbackResponse, # El frontend espera este modelo\n+    response_model=FeedbackResponse,\n     summary=\"Envía la respuesta de un usuario a un problema de lógica\",\n )\n async def submit_user_answer(\n-    current_db_user: Annotated[dict, Depends(get_current_user)], # Usa nombre corregido\n+    current_db_user: Annotated[dict, Depends(get_current_user)],\n     problem_id: Annotated[str, Form(...)],\n     user_answer: Annotated[str, Form(...)]\n ):\n-    \"\"\"\n-    Endpoint para procesar y guardar la respuesta de un usuario.\n-    \"\"\"\n     if mongo_client is None:\n          raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n \n-    user_id = current_db_user.get(\"_id\") # Obtiene ObjectId\n+    user_id = current_db_user.get(\"_id\")\n     user_email = current_db_user.get(\"email\", \"N/A\")\n \n     if not user_id or not isinstance(user_id, ObjectId):\n          logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n@@ -181,16 +179,24 @@\n \n     logger.info(f\"Usuario '{user_email}' (ID: {user_id}) envió respuesta para problema '{problem_id_obj}'.\")\n     logger.debug(f\"Respuesta recibida: '{user_answer}'\")\n \n-    problem_data = await mongo_client.get_problem_by_id(problem_id_obj)\n+    # --- Ejecutar llamada síncrona en thread ---\n+    try:\n+        problem_data = await asyncio.to_thread(mongo_client.get_problem_by_id, problem_id_obj) # <--- CAMBIO\n+    except Exception as db_error:\n+         logger.error(f\"Error de base de datos al obtener problema {problem_id_obj} para validación: {db_error}\", exc_info=True)\n+         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al validar el problema.\")\n+    # --- Fin cambio ---\n+\n     if not problem_data:\n          logger.error(f\"Intento de responder a problema inexistente ID: {problem_id_obj} por usuario {user_email}\")\n          raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"El problema especificado no fue encontrado.\")\n \n     # --- LÓGICA DE PROCESAMIENTO (PLACEHOLDER) ---\n     analysis_text = f\"Análisis simulado para la respuesta: '{user_answer[:50]}...'.\"\n     dummy_grade = 0\n+    # ... (lógica de calificación simulada sin cambios) ...\n     if not user_answer: analysis_text += \" La respuesta estaba vacía.\"; dummy_grade = 0\n     elif len(user_answer) < 20: analysis_text += \" La respuesta es muy corta.\"; dummy_grade = 1\n     elif \"bucle\" in user_answer.lower() or \"iterar\" in user_answer.lower(): analysis_text += \" Mencionaste bucles/iteración.\"; dummy_grade = 4\n     elif \"condición\" in user_answer.lower() or \"si\" in user_answer.lower(): analysis_text += \" Hablaste sobre condiciones.\"; dummy_grade = 3\n@@ -202,25 +208,33 @@\n     submission_data = {\n         \"problem_id\": problem_id_obj,\n         \"problem_difficulty\": problem_data.get(\"difficulty\", \"desconocida\"),\n         \"user_answer\": user_answer,\n-        \"analysis_received\": analysis_text, # Guardar análisis simulado\n-        \"llm_grade\": final_grade,          # Guardar nota simulada\n+        \"analysis_received\": analysis_text,\n+        \"llm_grade\": final_grade,\n         \"submission_timestamp\": datetime.utcnow()\n     }\n     try:\n-        # Asume que esta función existe en tu cliente mongo\n-        update_result = await mongo_client.add_solved_exercise_to_user(user_id, submission_data)\n+        # --- Ejecutar llamada síncrona en thread ---\n+        update_result = await asyncio.to_thread(mongo_client.add_solved_exercise_to_user, user_id, submission_data) # <--- CAMBIO\n+        # --- Fin cambio ---\n+\n+        # Chequeos del resultado (sin cambios)\n         if update_result.modified_count == 0 and update_result.matched_count == 1:\n              logger.warning(f\"No se modificó el usuario {user_id} al añadir ejercicio, pero se encontró.\")\n         elif update_result.matched_count == 0:\n              logger.error(f\"No se encontró el usuario {user_id} para añadir el ejercicio resuelto.\")\n              raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Usuario no encontrado para guardar progreso.\")\n         else:\n              logger.info(f\"Ejercicio resuelto añadido correctamente al historial del usuario {user_id}\")\n     except Exception as e:\n+        # Manejo de error genérico al guardar en DB\n         logger.error(f\"Error al guardar el ejercicio resuelto para user {user_id}: {e}\", exc_info=True)\n-        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al guardar el resultado del ejercicio.\")\n+        # Devolvemos error 500 pero CON el feedback que ya calculamos (o podríamos devolver error directo)\n+        # Depende de si prefieres que el usuario vea el feedback aunque no se guarde.\n+        # Aquí optamos por devolver el feedback de todas formas, pero logueamos el error de guardado.\n+        # raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al guardar el resultado del ejercicio.\")\n+        pass # Continuar para devolver el feedback al usuario\n \n     logger.info(f\"Evaluación simulada para {user_email}: Calificación={final_grade}\")\n \n     # Devolver el feedback al frontend\n"
                },
                {
                    "date": 1746282534376,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -29,8 +29,22 @@\n except Exception as e:\n     logger.error(f\"Error al instanciar MongoDBClient en routers/logic.py: {e}\")\n     mongo_client = None\n \n+\n+# --- AÑADIR IMPORTACIÓN PARA GEMINI ---\n+try:\n+    # Asumiendo que gemini_utils está en el directorio 'utils' relativo a 'daw_backend'\n+    from utils.gemini_utils import get_gemini_feedback\n+    GEMINI_AVAILABLE = True\n+    logging.info(\"Módulo gemini_utils importado correctamente.\")\n+except ImportError:\n+    logging.warning(\"Módulo gemini_utils no encontrado o get_gemini_feedback no definido. La evaluación usará placeholders.\")\n+    GEMINI_AVAILABLE = False\n+    # Definir una función placeholder si no existe para evitar errores más adelante\n+    async def get_gemini_feedback(problem_text: str, user_answer: str): return None\n+# --- FIN IMPORTACIÓN ---\n+\n # --- Endpoint de Progreso ---\n @router.get(\n     \"/progress\",\n     response_model=UserProgressResponse,\n@@ -148,94 +162,102 @@\n         logger.info(f\"No se encontraron problemas sin resolver para {user_email} con dificultad: {difficulty}\")\n         message = f\"¡Felicidades! Parece que has resuelto todos los problemas de nivel '{difficulty}'.\" if difficulty else \"¡Felicidades! Parece que has resuelto todos los problemas.\"\n         return NoProblemResponse(message=message)\n \n-\n-# --- Endpoint para Enviar Respuesta ---\n+# --- Endpoint para Enviar Respuesta (MODIFICADO CON LLM y nombre correcto de guardado) ---\n @router.post(\n     \"/submit_answer\",\n     response_model=FeedbackResponse,\n-    summary=\"Envía la respuesta de un usuario a un problema de lógica\",\n+    summary=\"Envía la respuesta, la evalúa con IA y la guarda\",\n )\n async def submit_user_answer(\n     current_db_user: Annotated[dict, Depends(get_current_user)],\n     problem_id: Annotated[str, Form(...)],\n     user_answer: Annotated[str, Form(...)]\n ):\n     if mongo_client is None:\n-         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n+         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio DB no disponible.\")\n \n     user_id = current_db_user.get(\"_id\")\n     user_email = current_db_user.get(\"email\", \"N/A\")\n-\n     if not user_id or not isinstance(user_id, ObjectId):\n-         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n-         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener ID de usuario.\")\n+         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"ID usuario inválido.\")\n \n     try:\n         problem_id_obj = ObjectId(problem_id)\n     except Exception:\n-         logger.error(f\"ID de problema inválido recibido: '{problem_id}' para usuario {user_email}\")\n          raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"ID de problema inválido.\")\n \n     logger.info(f\"Usuario '{user_email}' (ID: {user_id}) envió respuesta para problema '{problem_id_obj}'.\")\n     logger.debug(f\"Respuesta recibida: '{user_answer}'\")\n \n-    # --- Ejecutar llamada síncrona en thread ---\n+    # 1. Validar que el problema existe\n     try:\n-        problem_data = await asyncio.to_thread(mongo_client.get_problem_by_id, problem_id_obj) # <--- CAMBIO\n+        problem_data = await asyncio.to_thread(mongo_client.get_problem_by_id, problem_id_obj)\n     except Exception as db_error:\n-         logger.error(f\"Error de base de datos al obtener problema {problem_id_obj} para validación: {db_error}\", exc_info=True)\n+         logger.error(f\"Error DB al obtener problema {problem_id_obj}: {db_error}\", exc_info=True)\n          raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al validar el problema.\")\n-    # --- Fin cambio ---\n-\n     if not problem_data:\n-         logger.error(f\"Intento de responder a problema inexistente ID: {problem_id_obj} por usuario {user_email}\")\n          raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"El problema especificado no fue encontrado.\")\n \n-    # --- LÓGICA DE PROCESAMIENTO (PLACEHOLDER) ---\n-    analysis_text = f\"Análisis simulado para la respuesta: '{user_answer[:50]}...'.\"\n-    dummy_grade = 0\n-    # ... (lógica de calificación simulada sin cambios) ...\n-    if not user_answer: analysis_text += \" La respuesta estaba vacía.\"; dummy_grade = 0\n-    elif len(user_answer) < 20: analysis_text += \" La respuesta es muy corta.\"; dummy_grade = 1\n-    elif \"bucle\" in user_answer.lower() or \"iterar\" in user_answer.lower(): analysis_text += \" Mencionaste bucles/iteración.\"; dummy_grade = 4\n-    elif \"condición\" in user_answer.lower() or \"si\" in user_answer.lower(): analysis_text += \" Hablaste sobre condiciones.\"; dummy_grade = 3\n-    else: analysis_text += \" Respuesta genérica recibida.\"; dummy_grade = 2\n-    final_grade = max(0, min(5, dummy_grade))\n-    # --- FIN LÓGICA PLACEHOLDER ---\n+    # 2. --- LLAMADA AL LLM (Reemplaza Placeholder) ---\n+    llm_analysis = \"Análisis no disponible (LLM no configurado o error).\"\n+    llm_grade = 0 # Nota por defecto\n \n-    # --- GUARDAR EL RESULTADO EN LA BASE DE DATOS ---\n+    if GEMINI_AVAILABLE:\n+        logger.info(f\"Llamando a Gemini para evaluar respuesta del problema {problem_id_obj}...\")\n+        try:\n+            # Asumiendo que get_gemini_feedback es SÍNCRONA (verifica tu implementación)\n+            feedback_result = await asyncio.to_thread(get_gemini_feedback, problem_data['text'], user_answer)\n+\n+            if feedback_result:\n+                llm_analysis = feedback_result.get(\"analysis\", \"Error al extraer análisis.\")\n+                try:\n+                     llm_grade = int(feedback_result.get(\"grade\", 0))\n+                     llm_grade = max(0, min(10, llm_grade)) # Asegurar rango 0-10\n+                except (ValueError, TypeError):\n+                     logger.error(f\"Nota inválida de Gemini: {feedback_result.get('grade')}. Usando 0.\")\n+                     llm_grade = 0\n+                logger.info(f\"Evaluación de Gemini recibida: Calificación={llm_grade}\")\n+            else:\n+                logger.error(\"La llamada a Gemini no devolvió resultado o falló.\")\n+                # Mantener feedback por defecto\n+\n+        except Exception as llm_error:\n+            logger.error(f\"Error durante la llamada o procesamiento de Gemini: {llm_error}\", exc_info=True)\n+            # Mantener feedback por defecto\n+    else:\n+        # Lógica placeholder si Gemini no está disponible\n\\ No newline at end of file\n+        llm_analysis = f\"Análisis simulado: '{user_answer[:50]}...'.\"\n+        dummy_grade = len(user_answer) // 20 # Ajustar simulación para 0-10\n+        llm_analysis += \" (Evaluación Simulada)\"\n+        llm_grade = max(0, min(10, dummy_grade))\n+        logger.warning(\"Usando evaluación placeholder porque Gemini no está disponible.\")\n+    # --- FIN LLAMADA LLM ---\n+\n+\n+    # 3. --- GUARDAR RESULTADO EN DB ---\n     submission_data = {\n         \"problem_id\": problem_id_obj,\n         \"problem_difficulty\": problem_data.get(\"difficulty\", \"desconocida\"),\n         \"user_answer\": user_answer,\n-        \"analysis_received\": analysis_text,\n-        \"llm_grade\": final_grade,\n+        \"analysis_received\": llm_analysis, # Análisis real o placeholder\n+        \"llm_grade\": llm_grade,            # Nota real o placeholder (0-10)\n         \"submission_timestamp\": datetime.utcnow()\n     }\n     try:\n-        # --- Ejecutar llamada síncrona en thread ---\n-        update_result = await asyncio.to_thread(mongo_client.add_solved_exercise_to_user, user_id, submission_data) # <--- CAMBIO\n-        # --- Fin cambio ---\n+        # --- Usar nombre correcto de la función ---\n+        update_result = await asyncio.to_thread(mongo_client.add_solved_exercise, user_id, submission_data) # <--- NOMBRE CORREGIDO\n+        # --- Fin corrección ---\n \n-        # Chequeos del resultado (sin cambios)\n-        if update_result.modified_count == 0 and update_result.matched_count == 1:\n-             logger.warning(f\"No se modificó el usuario {user_id} al añadir ejercicio, pero se encontró.\")\n-        elif update_result.matched_count == 0:\n-             logger.error(f\"No se encontró el usuario {user_id} para añadir el ejercicio resuelto.\")\n-             raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Usuario no encontrado para guardar progreso.\")\n-        else:\n-             logger.info(f\"Ejercicio resuelto añadido correctamente al historial del usuario {user_id}\")\n+        if update_result.modified_count == 0 and update_result.matched_count == 1: logger.warning(f\"No se modificó usuario {user_id} al añadir ejercicio.\")\n+        elif update_result.matched_count == 0: raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Usuario no encontrado para guardar.\")\n+        else: logger.info(f\"Ejercicio resuelto añadido para usuario {user_id}\")\n     except Exception as e:\n-        # Manejo de error genérico al guardar en DB\n-        logger.error(f\"Error al guardar el ejercicio resuelto para user {user_id}: {e}\", exc_info=True)\n-        # Devolvemos error 500 pero CON el feedback que ya calculamos (o podríamos devolver error directo)\n-        # Depende de si prefieres que el usuario vea el feedback aunque no se guarde.\n-        # Aquí optamos por devolver el feedback de todas formas, pero logueamos el error de guardado.\n-        # raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al guardar el resultado del ejercicio.\")\n-        pass # Continuar para devolver el feedback al usuario\n+        logger.error(f\"Error al guardar ejercicio resuelto para user {user_id}: {e}\", exc_info=True)\n+        # Continuamos para devolver el feedback aunque no se guarde\n+        pass\n \n-    logger.info(f\"Evaluación simulada para {user_email}: Calificación={final_grade}\")\n+    logger.info(f\"Evaluación final para {user_email} (problema {problem_id_obj}): Calificación={llm_grade}\")\n \n-    # Devolver el feedback al frontend\n-    return FeedbackResponse(analysis=analysis_text, grade=final_grade)\n+    # 4. Devolver el feedback real/placeholder al frontend\n+    return FeedbackResponse(analysis=llm_analysis, grade=llm_grade)\n"
                },
                {
                    "date": 1746283251584,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,11 +1,12 @@\n-# routers/logic.py\n+# /home/alessandro_hp/Documentos/Cursor/DAW_PROYECTO/daw_backend/routers/logic.py\n+\n from fastapi import APIRouter, Depends, HTTPException, status, Query, Form\n from bson import ObjectId\n from typing import Optional, Dict, List, Union, Annotated\n from datetime import datetime\n import logging\n-import asyncio # <--- AÑADIR IMPORT\n+import asyncio # Necesario para asyncio.to_thread para llamadas síncronas a DB\n \n # Importa tu cliente de MongoDB\n from mongodb_client import MongoDBClient\n \n@@ -14,8 +15,19 @@\n \n # Importa los modelos/schemas Pydantic\n from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse\n \n+# Importa la función de Gemini (ajusta la ruta si es necesario)\n+try:\n+    from utils.gemini_utils import get_gemini_feedback\n+    GEMINI_AVAILABLE = True\n+    logging.info(\"Módulo gemini_utils importado correctamente.\")\n+except ImportError:\n+    logging.warning(\"Módulo gemini_utils no encontrado o get_gemini_feedback no definido. La evaluación usará placeholders.\")\n+    GEMINI_AVAILABLE = False\n+    # Definir una función placeholder async si no existe para evitar errores\n+    async def get_gemini_feedback(problem_text: str, user_answer: str): return None\n+\n logger = logging.getLogger(__name__)\n \n router = APIRouter(\n     prefix=\"/logic\",\n@@ -29,22 +41,8 @@\n except Exception as e:\n     logger.error(f\"Error al instanciar MongoDBClient en routers/logic.py: {e}\")\n     mongo_client = None\n \n-\n-# --- AÑADIR IMPORTACIÓN PARA GEMINI ---\n-try:\n-    # Asumiendo que gemini_utils está en el directorio 'utils' relativo a 'daw_backend'\n-    from utils.gemini_utils import get_gemini_feedback\n-    GEMINI_AVAILABLE = True\n-    logging.info(\"Módulo gemini_utils importado correctamente.\")\n-except ImportError:\n-    logging.warning(\"Módulo gemini_utils no encontrado o get_gemini_feedback no definido. La evaluación usará placeholders.\")\n-    GEMINI_AVAILABLE = False\n-    # Definir una función placeholder si no existe para evitar errores más adelante\n-    async def get_gemini_feedback(problem_text: str, user_answer: str): return None\n-# --- FIN IMPORTACIÓN ---\n-\n # --- Endpoint de Progreso ---\n @router.get(\n     \"/progress\",\n     response_model=UserProgressResponse,\n@@ -64,15 +62,13 @@\n          raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n \n     logger.info(f\"Solicitud de progreso para usuario: {user_email} (ID: {user_id})\")\n \n-    # --- Ejecutar llamada síncrona en thread ---\n     try:\n-        db_user_data = await asyncio.to_thread(mongo_client.get_user_by_id, user_id) # <--- CAMBIO\n+        db_user_data = await asyncio.to_thread(mongo_client.get_user_by_id, user_id)\n     except Exception as db_error:\n-        logger.error(f\"Error de base de datos al obtener usuario {user_id} para progreso: {db_error}\", exc_info=True)\n+        logger.error(f\"Error DB al obtener usuario {user_id}: {db_error}\", exc_info=True)\n         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al consultar datos del usuario.\")\n-    # --- Fin cambio ---\n \n     if not db_user_data:\n          logger.error(f\"No se encontró el usuario con ID {user_id} en la base de datos.\")\n          raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Usuario no encontrado.\")\n@@ -81,90 +77,55 @@\n \n     # Lógica de Cálculo (sin cambios)...\n     progress_counts: Dict[str, int] = {\"basico\": 0, \"intermedio\": 0, \"avanzado\": 0}\n     progress_sums: Dict[str, float] = {\"basico\": 0.0, \"intermedio\": 0.0, \"avanzado\": 0.0}\n-    total_solved_count = 0\n-    total_grade_sum = 0.0\n+    total_solved_count = 0; total_grade_sum = 0.0\n     for exercise in solved_exercises:\n-        if isinstance(exercise, dict) and \\\n-           exercise.get(\"problem_difficulty\") in progress_counts and \\\n-           isinstance(exercise.get(\"llm_grade\"), (int, float)):\n-            difficulty = exercise[\"problem_difficulty\"]\n-            grade = exercise[\"llm_grade\"]\n-            total_solved_count += 1\n-            total_grade_sum += grade\n-            progress_counts[difficulty] += 1\n-            progress_sums[difficulty] += grade\n-        else:\n-             logger.warning(f\"Ejercicio con formato/datos inesperados en historial de user_id {user_id}: {exercise}\")\n+        if isinstance(exercise, dict) and exercise.get(\"problem_difficulty\") in progress_counts and isinstance(exercise.get(\"llm_grade\"), (int, float)):\n+            difficulty = exercise[\"problem_difficulty\"]; grade = exercise[\"llm_grade\"]\n+            total_solved_count += 1; total_grade_sum += grade\n+            progress_counts[difficulty] += 1; progress_sums[difficulty] += grade\n+        else: logger.warning(f\"Ejercicio formato inválido user_id {user_id}: {exercise}\")\n     progress_by_difficulty: Dict[str, DifficultyProgress] = {}\n-    for difficulty_level in [\"basico\", \"intermedio\", \"avanzado\"]:\n-        count = progress_counts[difficulty_level]\n-        grade_sum = progress_sums[difficulty_level]\n+    for dl in [\"basico\", \"intermedio\", \"avanzado\"]:\n+        count = progress_counts[dl]; grade_sum = progress_sums[dl]\n         avg_grade = round(grade_sum / count, 2) if count > 0 else 0.0\n-        progress_by_difficulty[difficulty_level] = DifficultyProgress(\n-            solved_count=count, average_grade=avg_grade\n-        )\n+        progress_by_difficulty[dl] = DifficultyProgress(solved_count=count, average_grade=avg_grade)\n     overall_avg = round(total_grade_sum / total_solved_count, 2) if total_solved_count > 0 else 0.0\n     logger.info(f\"Progreso calculado para {user_email}: Total={total_solved_count}, Avg={overall_avg}\")\n-    return UserProgressResponse(\n-        total_solved=total_solved_count,\n-        progress_by_difficulty=progress_by_difficulty,\n-        overall_average_grade=overall_avg,\n-        message=\"Tu progreso ha sido cargado.\"\n-    )\n+    return UserProgressResponse(total_solved=total_solved_count, progress_by_difficulty=progress_by_difficulty, overall_average_grade=overall_avg, message=\"Tu progreso ha sido cargado.\")\n \n+\n # --- Endpoint para Obtener Problema ---\n @router.get(\n     \"/problem\",\n     response_model=Union[ProblemResponse, NoProblemResponse],\n-    summary=\"Obtiene un problema de lógica no resuelto por el usuario\"\n+    summary=\"Obtiene un problema de lógica no resuelto\"\n )\n async def get_logic_problem(\n     current_db_user: Annotated[dict, Depends(get_current_user)],\n-    difficulty: Annotated[str | None, Query(description=\"Filtrar por dificultad (basico, intermedio, avanzado)\")] = None\n+    difficulty: Annotated[str | None, Query(description=\"Filtrar por dificultad\")] = None\n ):\n-    if mongo_client is None:\n-         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n-\n-    user_id = current_db_user.get(\"_id\")\n-    user_email = current_db_user.get(\"email\", \"N/A\")\n-\n-    if not user_id or not isinstance(user_id, ObjectId):\n-         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n-         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener ID de usuario.\")\n-\n-    if difficulty is not None and difficulty not in [\"basico\", \"intermedio\", \"avanzado\"]:\n-         logger.warning(f\"Solicitud con dificultad inválida ({difficulty}) para user_id {user_id}\")\n-         raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Dificultad inválida.\")\n-\n-    logger.info(f\"Buscando problema para user_id: {user_id}, dificultad: {difficulty or 'cualquiera'}\")\n-\n-    # --- Ejecutar llamada síncrona en thread ---\n-    try:\n-        problem_dict = await asyncio.to_thread(mongo_client.get_random_unsolved_problem, user_id, difficulty=difficulty) # <--- CAMBIO\n-    except Exception as db_error:\n-        logger.error(f\"Error de base de datos al obtener problema para usuario {user_id}: {db_error}\", exc_info=True)\n-        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al consultar problemas.\")\n-    # --- Fin cambio ---\n-\n+    if mongo_client is None: raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio DB no disponible.\")\n+    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n+    if not user_id or not isinstance(user_id, ObjectId): raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"ID usuario inválido.\")\n+    if difficulty is not None and difficulty not in [\"basico\", \"intermedio\", \"avanzado\"]: raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Dificultad inválida.\")\n+    logger.info(f\"Buscando problema user_id: {user_id}, dificultad: {difficulty or 'cualquiera'}\")\n+    try: problem_dict = await asyncio.to_thread(mongo_client.get_random_unsolved_problem, user_id, difficulty=difficulty)\n+    except Exception as db_error: raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error DB consulta problemas.\")\n     if problem_dict:\n-        logger.info(f\"Problema encontrado para {user_email}: ID={problem_dict.get('_id')}\")\n+        logger.info(f\"Problema encontrado {user_email}: ID={problem_dict.get('_id')}\")\n         try:\n-             validated_problem = ProblemResponse(\n-                 id=str(problem_dict[\"_id\"]), text=problem_dict[\"text\"],\n-                 difficulty=problem_dict[\"difficulty\"], topics=problem_dict.get(\"topics\", [])\n-             )\n+             validated_problem = ProblemResponse(id=str(problem_dict[\"_id\"]), text=problem_dict[\"text\"], difficulty=problem_dict[\"difficulty\"], topics=problem_dict.get(\"topics\", []))\n              return validated_problem\n-        except Exception as e:\n-            logger.error(f\"Error al validar/mapear problema Pydantic ID {problem_dict.get('_id')}: {e}\", exc_info=True)\n-            raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error procesando datos del problema.\")\n+        except Exception as e: raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error procesando datos problema.\")\n     else:\n-        logger.info(f\"No se encontraron problemas sin resolver para {user_email} con dificultad: {difficulty}\")\n-        message = f\"¡Felicidades! Parece que has resuelto todos los problemas de nivel '{difficulty}'.\" if difficulty else \"¡Felicidades! Parece que has resuelto todos los problemas.\"\n+        logger.info(f\"No se encontraron problemas {user_email}, dificultad: {difficulty}\")\n+        message = f\"¡Felicidades! Has resuelto todos los problemas de nivel '{difficulty}'.\" if difficulty else \"¡Felicidades! Has resuelto todos los problemas.\"\n         return NoProblemResponse(message=message)\n \n-# --- Endpoint para Enviar Respuesta (MODIFICADO CON LLM y nombre correcto de guardado) ---\n+\n+# --- Endpoint para Enviar Respuesta (CORREGIDO LLAMADA LLM Y MANEJO SAVE RESULT) ---\n @router.post(\n     \"/submit_answer\",\n     response_model=FeedbackResponse,\n     summary=\"Envía la respuesta, la evalúa con IA y la guarda\",\n@@ -173,42 +134,33 @@\n     current_db_user: Annotated[dict, Depends(get_current_user)],\n     problem_id: Annotated[str, Form(...)],\n     user_answer: Annotated[str, Form(...)]\n ):\n-    if mongo_client is None:\n-         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio DB no disponible.\")\n+    if mongo_client is None: raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio DB no disponible.\")\n+    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n+    if not user_id or not isinstance(user_id, ObjectId): raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"ID usuario inválido.\")\n+    try: problem_id_obj = ObjectId(problem_id)\n+    except Exception: raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"ID de problema inválido.\")\n \n-    user_id = current_db_user.get(\"_id\")\n-    user_email = current_db_user.get(\"email\", \"N/A\")\n-    if not user_id or not isinstance(user_id, ObjectId):\n-         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"ID usuario inválido.\")\n-\n-    try:\n-        problem_id_obj = ObjectId(problem_id)\n-    except Exception:\n-         raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"ID de problema inválido.\")\n-\n     logger.info(f\"Usuario '{user_email}' (ID: {user_id}) envió respuesta para problema '{problem_id_obj}'.\")\n     logger.debug(f\"Respuesta recibida: '{user_answer}'\")\n \n     # 1. Validar que el problema existe\n-    try:\n-        problem_data = await asyncio.to_thread(mongo_client.get_problem_by_id, problem_id_obj)\n-    except Exception as db_error:\n-         logger.error(f\"Error DB al obtener problema {problem_id_obj}: {db_error}\", exc_info=True)\n-         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al validar el problema.\")\n-    if not problem_data:\n-         raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"El problema especificado no fue encontrado.\")\n+    try: problem_data = await asyncio.to_thread(mongo_client.get_problem_by_id, problem_id_obj)\n+    except Exception as db_error: raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al validar el problema.\")\n+    if not problem_data: raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"El problema especificado no fue encontrado.\")\n \n-    # 2. --- LLAMADA AL LLM (Reemplaza Placeholder) ---\n+    # 2. --- LLAMADA AL LLM ---\n     llm_analysis = \"Análisis no disponible (LLM no configurado o error).\"\n-    llm_grade = 0 # Nota por defecto\n+    llm_grade = 0\n \n     if GEMINI_AVAILABLE:\n         logger.info(f\"Llamando a Gemini para evaluar respuesta del problema {problem_id_obj}...\")\n         try:\n-            # Asumiendo que get_gemini_feedback es SÍNCRONA (verifica tu implementación)\n-            feedback_result = await asyncio.to_thread(get_gemini_feedback, problem_data['text'], user_answer)\n+            # --- CORRECCIÓN: Llamar directamente con await si get_gemini_feedback es async def ---\n+            feedback_result = await get_gemini_feedback(problem_data['text'], user_answer)\n+            # --- SI get_gemini_feedback FUERA SÍNCRONA, USARÍAS: ---\n+            # feedback_result = await asyncio.to_thread(get_gemini_feedback, problem_data['text'], user_answer)\n \n             if feedback_result:\n                 llm_analysis = feedback_result.get(\"analysis\", \"Error al extraer análisis.\")\n                 try:\n@@ -219,45 +171,58 @@\n                      llm_grade = 0\n                 logger.info(f\"Evaluación de Gemini recibida: Calificación={llm_grade}\")\n             else:\n                 logger.error(\"La llamada a Gemini no devolvió resultado o falló.\")\n-                # Mantener feedback por defecto\n-\n         except Exception as llm_error:\n             logger.error(f\"Error durante la llamada o procesamiento de Gemini: {llm_error}\", exc_info=True)\n-            # Mantener feedback por defecto\n     else:\n         # Lógica placeholder si Gemini no está disponible\n         llm_analysis = f\"Análisis simulado: '{user_answer[:50]}...'.\"\n-        dummy_grade = len(user_answer) // 20 # Ajustar simulación para 0-10\n+        dummy_grade = len(user_answer) // 10 # Simulación simple para 0-10\n         llm_analysis += \" (Evaluación Simulada)\"\n         llm_grade = max(0, min(10, dummy_grade))\n         logger.warning(\"Usando evaluación placeholder porque Gemini no está disponible.\")\n     # --- FIN LLAMADA LLM ---\n \n-\n     # 3. --- GUARDAR RESULTADO EN DB ---\n     submission_data = {\n         \"problem_id\": problem_id_obj,\n         \"problem_difficulty\": problem_data.get(\"difficulty\", \"desconocida\"),\n         \"user_answer\": user_answer,\n-        \"analysis_received\": llm_analysis, # Análisis real o placeholder\n-        \"llm_grade\": llm_grade,            # Nota real o placeholder (0-10)\n+        \"analysis_received\": llm_analysis,\n+        \"llm_grade\": llm_grade, # Nota 0-10\n         \"submission_timestamp\": datetime.utcnow()\n     }\n+    save_error = False\n     try:\n-        # --- Usar nombre correcto de la función ---\n-        update_result = await asyncio.to_thread(mongo_client.add_solved_exercise, user_id, submission_data) # <--- NOMBRE CORREGIDO\n-        # --- Fin corrección ---\n+        # --- CORRECCIÓN MANEJO RETORNO ---\n+        # Ejecutar llamada (asumiendo que add_solved_exercise devuelve UpdateResult o None)\n+        update_result = await asyncio.to_thread(mongo_client.add_solved_exercise, user_id, submission_data)\n \n-        if update_result.modified_count == 0 and update_result.matched_count == 1: logger.warning(f\"No se modificó usuario {user_id} al añadir ejercicio.\")\n-        elif update_result.matched_count == 0: raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Usuario no encontrado para guardar.\")\n-        else: logger.info(f\"Ejercicio resuelto añadido para usuario {user_id}\")\n+        # Verificar el resultado devuelto por add_solved_exercise\n+        if update_result is None:\n+            save_error = True\n+            logger.error(f\"La función add_solved_exercise devolvió None para user {user_id}. No se pudo guardar.\")\n+        # Si devuelve UpdateResult, verificar counts\n+        elif hasattr(update_result, 'matched_count') and hasattr(update_result, 'modified_count'):\n+            if update_result.matched_count == 0:\n+                 save_error = True\n+                 logger.error(f\"No se encontró el usuario {user_id} para añadir el ejercicio resuelto (update_one).\")\n+            elif update_result.modified_count == 0:\n+                 logger.warning(f\"No se modificó el usuario {user_id} al añadir ejercicio (modified_count=0).\")\n+            else:\n+                 logger.info(f\"Ejercicio resuelto añadido correctamente al historial del usuario {user_id}\")\n+        else:\n+             # Si devolvió algo inesperado (ni None ni UpdateResult)\n+             save_error = True\n+             logger.error(f\"Valor de retorno inesperado de add_solved_exercise para user {user_id}: {type(update_result)}\")\n+        # --- FIN CORRECCIÓN MANEJO ---\n+\n     except Exception as e:\n-        logger.error(f\"Error al guardar ejercicio resuelto para user {user_id}: {e}\", exc_info=True)\n+        logger.error(f\"Error al intentar guardar el ejercicio resuelto para user {user_id}: {e}\", exc_info=True)\n+        save_error = True\n         # Continuamos para devolver el feedback aunque no se guarde\n-        pass\n \n-    logger.info(f\"Evaluación final para {user_email} (problema {problem_id_obj}): Calificación={llm_grade}\")\n+    logger.info(f\"Evaluación final para {user_email} (problema {problem_id_obj}): Calificación={llm_grade} (Guardado: {'No' if save_error else 'Sí'})\")\n \n     # 4. Devolver el feedback real/placeholder al frontend\n     return FeedbackResponse(analysis=llm_analysis, grade=llm_grade)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746307910854,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,81 +1,106 @@\n-# /home/alessandro_hp/Documentos/Cursor/DAW_PROYECTO/daw_backend/routers/logic.py\n+# routers/logic.py\n \n-from fastapi import APIRouter, Depends, HTTPException, status, Query, Form\n+from fastapi import APIRouter, Depends, HTTPException, status, Query, Form # Importa Form si esperas datos de formulario\n+from fastapi.responses import Response\n from bson import ObjectId\n-from typing import Optional, Dict, List, Union, Annotated\n-from datetime import datetime\n+from typing import Optional, Dict, List, Union, Annotated # Importa Annotated\n+from datetime import datetime # Para el timestamp\n import logging\n import asyncio # Necesario para asyncio.to_thread para llamadas síncronas a DB\n \n+# Importa cliente Google Cloud Text-to-Speech si lo usas (ya debe estar)\n+# from google.cloud import texttospeech\n+\n # Importa tu cliente de MongoDB\n from mongodb_client import MongoDBClient\n \n # Importa tu dependencia de autenticación\n from utils.auth_utils import get_current_user\n \n # Importa los modelos/schemas Pydantic\n-from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse\n+# Necesitas el modelo FeedbackResponse para la respuesta\n+from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse # Asegúrate de que FeedbackResponse esté en models.logic\n+# Si no tienes FeedbackResponse, defínelo en models/logic.py:\n+# class FeedbackResponse(BaseModel):\n+#    analysis: str\n+#    grade: int # O float, según lo que devuelva tu LLM\n \n-# Importa la función de Gemini (ajusta la ruta si es necesario)\n+\n+# --- Configuración para el LLM (Gemini) ---\n+# Necesitas una función que llame a la API de Gemini.\n+# Supondremos que tienes un archivo como utils/gemini_utils.py\n+# con una función get_gemini_feedback(problem_text: str, user_answer: str) -> Dict[str, Any] (o None si falla).\n+# Esta función debería llamar a la API de Gemini con un prompt adecuado.\n try:\n+    # ASEGÚRATE de que la ruta de importación sea correcta para tu proyecto\n+    # y que el archivo utils/gemini_utils.py exista y tenga la función get_gemini_feedback\n     from utils.gemini_utils import get_gemini_feedback\n     GEMINI_AVAILABLE = True\n-    logging.info(\"Módulo gemini_utils importado correctamente.\")\n+    logger.info(\"Módulo gemini_utils importado correctamente.\")\n except ImportError:\n-    logging.warning(\"Módulo gemini_utils no encontrado o get_gemini_feedback no definido. La evaluación usará placeholders.\")\n+    logger.warning(\"Módulo gemini_utils no encontrado o get_gemini_feedback no definido. La evaluación usará placeholders.\")\n     GEMINI_AVAILABLE = False\n-    # Definir una función placeholder async si no existe para evitar errores\n-    async def get_gemini_feedback(problem_text: str, user_answer: str): return None\n+    # Definir una función placeholder async si no existe la real, para evitar errores\n+    async def get_gemini_feedback(problem_text: str, user_answer: str):\n+        logger.warning(\"Usando placeholder get_gemini_feedback.\")\n+        # Simulación de respuesta de Gemini (debe coincidir con el formato esperado)\n+        simulated_analysis = f\"Análisis simulado para '{user_answer[:50]}...'. Parece una respuesta con longitud {len(user_answer)}. (Evaluación Simulada)\"\n+        simulated_grade = max(0, min(10, len(user_answer) // 5)) # Simulación simple de nota 0-10\n+        # Simular algo de latencia\n+        await asyncio.sleep(1)\n+        return {\"analysis\": simulated_analysis, \"grade\": simulated_grade}\n \n+\n logger = logging.getLogger(__name__)\n \n router = APIRouter(\n-    prefix=\"/logic\",\n+    prefix=\"/logic\", # Prefijo /logic para este router\n     tags=[\"Logic Problems\"],\n+    # dependencies=[Depends(get_current_user)] # Opcional: Proteger todo el router\n )\n \n-# Instancia del Cliente MongoDB\n+# Instancia del Cliente MongoDB (asumiendo que ya la tienes)\n try:\n     mongo_client = MongoDBClient()\n     logger.info(\"MongoDBClient instanciado en routers/logic.py\")\n except Exception as e:\n     logger.error(f\"Error al instanciar MongoDBClient en routers/logic.py: {e}\")\n-    mongo_client = None\n+    mongo_client = None # Set a None si falla para verificar en endpoints\n \n+# Instancia del cliente Google Cloud Text-to-Speech (asumiendo que ya la tienes e inicializaste)\n+# Debe estar definida globalmente en este archivo si la usas en /tts\n+# try: tts_client = texttospeech.TextToSpeechClient() except Exception: tts_client = None\n+# Asegúrate de que el endpoint /tts está definido si lo usas.\n+\n+\n # --- Endpoint de Progreso ---\n @router.get(\n     \"/progress\",\n     response_model=UserProgressResponse,\n     summary=\"Obtiene el progreso del usuario autenticado\"\n )\n async def get_user_progress(\n+    # current_user ya es el diccionario del usuario de la DB\n     current_db_user: Annotated[dict, Depends(get_current_user)]\n ):\n     if mongo_client is None:\n          raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n \n-    user_id = current_db_user.get(\"_id\")\n-    user_email = current_db_user.get(\"email\", \"N/A\")\n+    # Ya tenemos el documento del usuario gracias a Depends(get_current_user)\n+    # No necesitamos obtenerlo de nuevo por ID a menos que necesitemos una versión más reciente (poco probable aquí)\n+    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n \n     if not user_id or not isinstance(user_id, ObjectId):\n+         # Esto no debería pasar si get_current_user funciona bien, pero es una seguridad.\n          logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n          raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n \n     logger.info(f\"Solicitud de progreso para usuario: {user_email} (ID: {user_id})\")\n \n-    try:\n-        db_user_data = await asyncio.to_thread(mongo_client.get_user_by_id, user_id)\n-    except Exception as db_error:\n-        logger.error(f\"Error DB al obtener usuario {user_id}: {db_error}\", exc_info=True)\n-        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al consultar datos del usuario.\")\n+    # El array de ejercicios resueltos está directamente en el documento del usuario\n+    solved_exercises = current_db_user.get(\"ejercicios\", []) # Acceder directamente al array del documento proporcionado por el Depends\n \n-    if not db_user_data:\n-         logger.error(f\"No se encontró el usuario con ID {user_id} en la base de datos.\")\n-         raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"Usuario no encontrado.\")\n-\n-    solved_exercises = db_user_data.get(\"ejercicios\", [])\n-\n     # Lógica de Cálculo (sin cambios)...\n     progress_counts: Dict[str, int] = {\"basico\": 0, \"intermedio\": 0, \"avanzado\": 0}\n     progress_sums: Dict[str, float] = {\"basico\": 0.0, \"intermedio\": 0.0, \"avanzado\": 0.0}\n     total_solved_count = 0; total_grade_sum = 0.0\n@@ -109,120 +134,265 @@\n     user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n     if not user_id or not isinstance(user_id, ObjectId): raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"ID usuario inválido.\")\n     if difficulty is not None and difficulty not in [\"basico\", \"intermedio\", \"avanzado\"]: raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Dificultad inválida.\")\n     logger.info(f\"Buscando problema user_id: {user_id}, dificultad: {difficulty or 'cualquiera'}\")\n-    try: problem_dict = await asyncio.to_thread(mongo_client.get_random_unsolved_problem, user_id, difficulty=difficulty)\n-    except Exception as db_error: raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error DB consulta problemas.\")\n+\n+    try:\n+        # Asegúrate de que get_random_unsolved_problem es síncrono o usa async db driver (Motor)\n+        # Si es síncrono (PyMongo), usa asyncio.to_thread\n+        problem_dict = await asyncio.to_thread(mongo_client.get_random_unsolved_problem, user_id, difficulty=difficulty)\n+\n+    except Exception as db_error:\n+        logger.error(f\"Error DB consulta problemas user {user_id}: {db_error}\", exc_info=True)\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error DB consulta problemas.\")\n+\n     if problem_dict:\n         logger.info(f\"Problema encontrado {user_email}: ID={problem_dict.get('_id')}\")\n         try:\n+             # Crear instancia Pydantic explícitamente para validación y serialización\n              validated_problem = ProblemResponse(id=str(problem_dict[\"_id\"]), text=problem_dict[\"text\"], difficulty=problem_dict[\"difficulty\"], topics=problem_dict.get(\"topics\", []))\n              return validated_problem\n-        except Exception as e: raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error procesando datos problema.\")\n+        except Exception as e:\n+             logger.error(f\"Error procesando datos problema {problem_dict.get('_id')} para {user_email}: {e}\", exc_info=True)\n+             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error procesando datos problema.\")\n     else:\n-        logger.info(f\"No se encontraron problemas {user_email}, dificultad: {difficulty}\")\n+        logger.info(f\"No se encontraron problemas {user_email}, dificultad: {difficulty or 'cualquiera'}\")\n         message = f\"¡Felicidades! Has resuelto todos los problemas de nivel '{difficulty}'.\" if difficulty else \"¡Felicidades! Has resuelto todos los problemas.\"\n         return NoProblemResponse(message=message)\n \n \n-# --- Endpoint para Enviar Respuesta (CORREGIDO LLAMADA LLM Y MANEJO SAVE RESULT) ---\n+# --- Endpoint POST /tts (si usas Google Cloud TTS) ---\n+# ASEGÚRATE de que el cliente tts_client esté inicializado globalmente arriba\n+# ASEGÚRATE de tener instalada la librería google-cloud-texttospeech\n+@router.post(\"/tts\")\n+async def text_to_speech(\n+    text: str, # Espera texto en cuerpo JSON {\"text\": \"...\"}\n+    current_user: Annotated[dict, Depends(get_current_user)] # Proteger el endpoint\n+):\n+    if not tts_client:\n+        logger.error(\"Intento de usar TTS, pero cliente no inicializado.\")\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Servicio de voz no disponible en el servidor.\")\n+\n+    if not text:\n+        logger.warning(f\"Solicitud /tts vacía de usuario {current_user.get('email', 'N/A')}\")\n+        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"No se proporcionó texto para convertir a voz.\")\n+\n+    user_email = current_user.get(\"email\", \"N/A\")\n+    logger.info(f\"Generando voz para usuario {user_email}: '{text[:50]}...'\")\n+\n+    try:\n+        synthesis_input = texttospeech.SynthesisInput(text=text)\n+        voice = texttospeech.VoiceSelectionParams(language_code=\"es-MX\", ssml_gender=texttospeech.SsmlVoiceGender.FEMALE)\n+        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n+\n+        response = tts_client.synthesize_speech(\n+            input=synthesis_input,\n+            voice=voice,\n+            audio_config=audio_config\n+        )\n+\n+        logger.info(f\"Voz generada exitosamente para {user_email} ({len(response.audio_content)} bytes).\")\n+        return Response(content=response.audio_content, media_type=\"audio/mpeg\")\n+\n+    except Exception as e:\n+        logger.error(f\"Error durante la síntesis de voz con Google Cloud TTS para {user_email}: {str(e)}\", exc_info=True)\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Error al generar voz en el servidor: {str(e)}\")\n+\n+\n+# --- Endpoint para Enviar Respuesta (CONEXIÓN CON LLM Y SAVE RESULT) ---\n+# Este endpoint recibe el texto de la respuesta, la evalúa y la guarda.\n+# REQUIERE que tengas implementada la función get_gemini_feedback en utils/gemini_utils.py\n+# REQUIERE que add_solved_exercise en mongodb_client.py funcione correctamente.\n @router.post(\n     \"/submit_answer\",\n+    # Asumiendo que models/logic.py tiene un modelo FeedbackResponse\n+    # con al menos 'analysis' (str) y 'grade' (int o float).\n+    # Ejemplo: class FeedbackResponse(BaseModel): analysis: str; grade: int\n     response_model=FeedbackResponse,\n-    summary=\"Envía la respuesta, la evalúa con IA y la guarda\",\n+    summary=\"Recibe respuesta, evalúa con IA y guarda el resultado\",\n )\n async def submit_user_answer(\n+    # current_user es el documento del usuario logeado, ya obtenido por Depends\n     current_db_user: Annotated[dict, Depends(get_current_user)],\n-    problem_id: Annotated[str, Form(...)],\n-    user_answer: Annotated[str, Form(...)]\n+    problem_id: Annotated[str, Form(...)], # Recibe el ID del problema (como string) del frontend (Form data)\n+    user_answer: Annotated[str, Form(...)] # Recibe el texto de la respuesta (como string) del frontend (Form data)\n ):\n-    if mongo_client is None: raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio DB no disponible.\")\n+    if mongo_client is None:\n+         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n+\n     user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n-    if not user_id or not isinstance(user_id, ObjectId): raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"ID usuario inválido.\")\n-    try: problem_id_obj = ObjectId(problem_id)\n-    except Exception: raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"ID de problema inválido.\")\n+    if not user_id or not isinstance(user_id, ObjectId):\n+         # Esto no debería pasar con un Depends válido, pero es una seguridad\n+         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n+         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n \n+    # 1. Validar y convertir el ID del problema recibido\n+    try:\n+        # problem_id llega como string del frontend (Form data)\n+        problem_id_obj = ObjectId(problem_id) # Convertir el string ID a ObjectId\n+    except Exception:\n+        # Si la conversión falla, el ID recibido no es válido\n+        logger.warning(f\"ID de problema inválido recibido de {user_email}: '{problem_id}'\")\n+        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"ID de problema inválido.\")\n+\n     logger.info(f\"Usuario '{user_email}' (ID: {user_id}) envió respuesta para problema '{problem_id_obj}'.\")\n     logger.debug(f\"Respuesta recibida: '{user_answer}'\")\n \n-    # 1. Validar que el problema existe\n-    try: problem_data = await asyncio.to_thread(mongo_client.get_problem_by_id, problem_id_obj)\n\\ No newline at end of file\n-    except Exception as db_error: raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al validar el problema.\")\n-    if not problem_data: raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"El problema especificado no fue encontrado.\")\n+    # 2. Obtener el problema original de la DB (necesario para el prompt del LLM)\n+    # Asumiendo que tienes un método get_problem_by_id(problem_id_obj) en mongo_client\n+    try:\n+        # Si get_problem_by_id es síncrono (PyMongo), usa asyncio.to_thread\n+        # Si es async (Motor), quita await asyncio.to_thread\n+        problem_data = await asyncio.to_thread(mongo_client.get_problem_by_id, problem_id_obj)\n+        # Si no tienes get_problem_by_id, puedes intentar obtenerlo de la misma agregación que en get_random_unsolved_problem,\n+        # pero get_problem_by_id es más limpio. Implementa get_problem_by_id en mongo_client si no existe.\n+    except Exception as db_error:\n+        logger.error(f\"Error DB al obtener problema {problem_id_obj} para {user_email}: {db_error}\", exc_info=True)\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al validar el problema.\")\n \n-    # 2. --- LLAMADA AL LLM ---\n-    llm_analysis = \"Análisis no disponible (LLM no configurado o error).\"\n-    llm_grade = 0\n+    if not problem_data:\n+        logger.warning(f\"Problema {problem_id_obj} no encontrado en DB para respuesta de {user_email}.\")\n+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"El problema especificado no fue encontrado.\")\n \n+    # 3. --- PREPARAR PROMPT PARA LLM ---\n+    # Aquí es donde construirías el prompt para el LLM, incluyendo:\n+    # - Contexto general del proyecto (aplicación educativa, para usuarios ciegos, etc.)\n+    # - Progreso del usuario (opcional, pero útil para contexto del LLM)\n+    # - El problema original (problem_data['text'])\n+    # - La respuesta del usuario (user_answer)\n+    # - Instrucciones claras para el LLM (analizar lógica, no código, calificar 1-5, formato JSON).\n+\n+    # Para obtener el progreso del usuario *actualizado* para el prompt,\n+    # podrías volver a calcularlo o obtener el documento completo de usuario.\n+    # El current_db_user ya trae el array 'ejercicios'.\n+    # Puedes reutilizar la lógica de cálculo de progreso de get_user_progress aquí.\n+\n+    user_solved_exercises = current_db_user.get(\"ejercicios\", []) # Array de ejercicios resueltos\n+    # Calcula el progreso actual (total, por dificultad, promedios) a partir de user_solved_exercises\n+\n+    # --- Simulación de cálculo de progreso para el prompt ---\n+    # NOTA: Reemplaza esto con la lógica real de cálculo de progreso si la necesitas en el prompt.\n+    total_solved_count = len(user_solved_exercises)\n+    # Aquí iría la lógica para calcular promedios y conteos por dificultad si los incluyes en el prompt.\n+    # --- Fin Simulación ---\n+\n+\n+    # --- Construir el prompt ---\n+    # Este prompt es CRUCIAL para guiar al LLM. Adapta el texto según el modelo LLM que uses.\n+    llm_prompt_parts = [\n+        \"SYSTEM: You are a programming logic tutor, friendly and helpful, specialized in assisting blind users learning to program. Your feedback should focus on the logical steps, problem-solving approach, correctness, and efficiency, not specific code syntax. Provide a clear analysis and assign a grade.\",\n+        \"CONTEXT: This is an educational web application for blind individuals. Interaction is primarily through voice. Your response will be read aloud by a screen reader.\",\n+        f\"USER_PROGRESS_SUMMARY: This user has solved {total_solved_count} exercises so far.\", # Puedes añadir más detalles aquí si los calculaste\n+        f\"PROGRAMMING_LOGIC_PROBLEM: {problem_data['text']}\", # El enunciado original del problema\n+        f\"USER_SUBMITTED_SOLUTION_LOGIC: {user_answer}\", # La respuesta transcrita del usuario\n+        \"INSTRUCTIONS: Based on the PROGRAMMING_LOGIC_PROBLEM and the USER_SUBMITTED_SOLUTION_LOGIC:\",\n+        \"- Analyze the user's proposed logic and thought process. Is it a valid approach to solve the problem?\",\n+        \"- Comment on its correctness, clarity, and potential efficiency. Discuss edge cases if relevant to the problem.\",\n+        \"- Do NOT provide code snippets or specific code syntax in your analysis.\",\n+        \"- Provide detailed feedback (aim for 50-200 words, keep it concise but informative for voice).\",\n+        \"- Assign a grade for the solution's logic on a scale of 0 to 10, where 0 is completely incorrect/no attempt, and 10 is excellent.\",\n+        \"- Respond ONLY in JSON format with the keys 'analysis' (string) and 'grade' (integer 0-10). Ensure the JSON is valid.\",\n+        \"EXAMPLE_JSON_RESPONSE: {\\\"analysis\\\": \\\"Your approach is logical and correct...\\\", \\\"grade\\\": 8}\"\n+    ]\n+    llm_prompt = \"\\n\".join(llm_prompt_parts)\n+\n+    # 4. --- LLAMADA AL LLM ---\n+    llm_analysis = \"Análisis no disponible (servicio de IA no configurado o falló).\"\n+    llm_grade = 0 # Grado por defecto si falla el LLM\n+\n     if GEMINI_AVAILABLE:\n-        logger.info(f\"Llamando a Gemini para evaluar respuesta del problema {problem_id_obj}...\")\n+        logger.info(f\"Llamando a Gemini para evaluar respuesta del problema {problem_id_obj} para user {user_email}...\")\n         try:\n-            # --- CORRECCIÓN: Llamar directamente con await si get_gemini_feedback es async def ---\n-            feedback_result = await get_gemini_feedback(problem_data['text'], user_answer)\n-            # --- SI get_gemini_feedback FUERA SÍNCRONA, USARÍAS: ---\n-            # feedback_result = await asyncio.to_thread(get_gemini_feedback, problem_data['text'], user_answer)\n+            # La función get_gemini_feedback debe estar implementada en utils/gemini_utils.py\n+            # y ser ASYNC (def async) para usar await aquí.\n+            # Si es SÍNCRONA, usa: feedback_result = await asyncio.to_thread(get_gemini_feedback, ...)\n+            feedback_result = await get_gemini_feedback(problem_data['text'], user_answer, user_progress_summary=llm_prompt_parts[2]) # Pasar el prompt completo o solo la parte del progreso si la función lo acepta\n \n-            if feedback_result:\n-                llm_analysis = feedback_result.get(\"analysis\", \"Error al extraer análisis.\")\n+\n+            if feedback_result and isinstance(feedback_result, dict): # Verificar que sea un diccionario\n+                llm_analysis = feedback_result.get(\"analysis\", \"Error al extraer análisis del resultado de IA.\")\n                 try:\n+                     # Intentar convertir la calificación a entero, manejando posibles errores\n                      llm_grade = int(feedback_result.get(\"grade\", 0))\n-                     llm_grade = max(0, min(10, llm_grade)) # Asegurar rango 0-10\n+                     # Asegurar que la calificación esté en el rango esperado (ej. 0-10)\n+                     llm_grade = max(0, min(10, llm_grade))\n                 except (ValueError, TypeError):\n-                     logger.error(f\"Nota inválida de Gemini: {feedback_result.get('grade')}. Usando 0.\")\n+                     logger.error(f\"Nota inválida recibida de Gemini para {user_email} ({problem_id_obj}): '{feedback_result.get('grade')}'. Usando 0.\")\n                      llm_grade = 0\n-                logger.info(f\"Evaluación de Gemini recibida: Calificación={llm_grade}\")\n+                logger.info(f\"Evaluación de Gemini recibida para {user_email}: Calificación={llm_grade}\")\n             else:\n-                logger.error(\"La llamada a Gemini no devolvió resultado o falló.\")\n+                logger.error(f\"La llamada a Gemini no devolvió un diccionario o falló para {user_email} ({problem_id_obj}). Resultado: {feedback_result}\")\n+                llm_analysis = \"La evaluación automática falló. Intenta de nuevo más tarde.\" # Mensaje amigable si el LLM falla\n+                llm_grade = 0 # Calificación por defecto si falla el LLM\n         except Exception as llm_error:\n-            logger.error(f\"Error durante la llamada o procesamiento de Gemini: {llm_error}\", exc_info=True)\n+            # Capturar errores durante la llamada o procesamiento de la respuesta de Gemini\n+            logger.error(f\"Error inesperado durante la llamada o procesamiento de Gemini para {user_email} ({problem_id_obj}): {llm_error}\", exc_info=True)\n+            llm_analysis = \"Error interno al procesar la evaluación automática. Intenta de nuevo.\" # Mensaje amigable si el LLM falla\n+            llm_grade = 0 # Calificación por defecto si falla el LLM\n     else:\n-        # Lógica placeholder si Gemini no está disponible\n-        llm_analysis = f\"Análisis simulado: '{user_answer[:50]}...'.\"\n-        dummy_grade = len(user_answer) // 10 # Simulación simple para 0-10\n-        llm_analysis += \" (Evaluación Simulada)\"\n-        llm_grade = max(0, min(10, dummy_grade))\n+        # Lógica placeholder si Gemini no está disponible (definida arriba en el try/except de importación)\n+        # get_gemini_feedback ya es la función placeholder si la importación falla\n         logger.warning(\"Usando evaluación placeholder porque Gemini no está disponible.\")\n-    # --- FIN LLAMADA LLM ---\n+        # Llamamos al placeholder para generar un resultado simulado\n+        simulated_feedback = await get_gemini_feedback(problem_data['text'], user_answer)\n+        llm_analysis = simulated_feedback[\"analysis\"]\n+        llm_grade = simulated_feedback[\"grade\"]\n \n-    # 3. --- GUARDAR RESULTADO EN DB ---\n+\n+    # 5. --- GUARDAR RESULTADO EN DB ---\n+    # Preparamos los datos para guardar en el array 'ejercicios' del usuario\n     submission_data = {\n-        \"problem_id\": problem_id_obj,\n-        \"problem_difficulty\": problem_data.get(\"difficulty\", \"desconocida\"),\n-        \"user_answer\": user_answer,\n-        \"analysis_received\": llm_analysis,\n-        \"llm_grade\": llm_grade, # Nota 0-10\n-        \"submission_timestamp\": datetime.utcnow()\n+        \"problem_id\": problem_id_obj, # ID del problema (ObjectId)\n+        \"problem_difficulty\": problem_data.get(\"difficulty\", \"desconocida\"), # Dificultad del problema original\n+        \"user_answer\": user_answer, # La respuesta del usuario (texto)\n+        \"analysis_received\": llm_analysis, # El análisis del LLM\n+        \"llm_grade\": llm_grade, # La calificación del LLM (0-10)\n+        \"submission_timestamp\": datetime.utcnow() # Timestamp de la sumisión\n     }\n+\n     save_error = False\n     try:\n-        # --- CORRECCIÓN MANEJO RETORNO ---\n-        # Ejecutar llamada (asumiendo que add_solved_exercise devuelve UpdateResult o None)\n+        # Llamar al método add_solved_exercise de MongoDBClient para guardar\n+        # Asumiendo que add_solved_exercise es síncrono (PyMongo), usar asyncio.to_thread\n+        # Si es async (Motor), quitar await asyncio.to_thread\n         update_result = await asyncio.to_thread(mongo_client.add_solved_exercise, user_id, submission_data)\n \n-        # Verificar el resultado devuelto por add_solved_exercise\n+        # Verificar el resultado de la operación de guardado (opcional pero recomendado)\n+        # add_solved_exercise debería devolver UpdateResult si usa update_one\n         if update_result is None:\n             save_error = True\n             logger.error(f\"La función add_solved_exercise devolvió None para user {user_id}. No se pudo guardar.\")\n-        # Si devuelve UpdateResult, verificar counts\n         elif hasattr(update_result, 'matched_count') and hasattr(update_result, 'modified_count'):\n-            if update_result.matched_count == 0:\n-                 save_error = True\n-                 logger.error(f\"No se encontró el usuario {user_id} para añadir el ejercicio resuelto (update_one).\")\n-            elif update_result.modified_count == 0:\n-                 logger.warning(f\"No se modificó el usuario {user_id} al añadir ejercicio (modified_count=0).\")\n-            else:\n-                 logger.info(f\"Ejercicio resuelto añadido correctamente al historial del usuario {user_id}\")\n+             if update_result.matched_count == 0:\n+                  save_error = True\n+                  logger.error(f\"No se encontró el usuario {user_id} para añadir el ejercicio resuelto (update_one matched_count=0).\")\n+             elif update_result.modified_count == 0:\n+                  # Esto puede pasar si el documento ya estaba en el array por alguna razón\n+                  logger.warning(f\"No se modificó el usuario {user_id} al añadir ejercicio (modified_count=0).\")\n+             else:\n+                  logger.info(f\"Ejercicio resuelto añadido correctamente al historial del usuario {user_id}\")\n         else:\n-             # Si devolvió algo inesperado (ni None ni UpdateResult)\n+             # Si devolvió algo inesperado\n              save_error = True\n              logger.error(f\"Valor de retorno inesperado de add_solved_exercise para user {user_id}: {type(update_result)}\")\n-        # --- FIN CORRECCIÓN MANEJO ---\n \n+\n     except Exception as e:\n-        logger.error(f\"Error al intentar guardar el ejercicio resuelto para user {user_id}: {e}\", exc_info=True)\n+        # Capturar errores durante la operación de guardado\n+        logger.error(f\"Error al intentar guardar el ejercicio resuelto para user {user_id} ({problem_id_obj}): {e}\", exc_info=True)\n         save_error = True\n-        # Continuamos para devolver el feedback aunque no se guarde\n+        # No lanzamos excepción aquí para que el frontend reciba el feedback del LLM aunque no se haya guardado.\n+        # Puedes decidir lanzar una excepción si el guardado es crítico.\n \n+\n     logger.info(f\"Evaluación final para {user_email} (problema {problem_id_obj}): Calificación={llm_grade} (Guardado: {'No' if save_error else 'Sí'})\")\n \n-    # 4. Devolver el feedback real/placeholder al frontend\n-    return FeedbackResponse(analysis=llm_analysis, grade=llm_grade)\n+    # 6. Devolver el feedback al frontend\n+    # Retornar FeedbackResponse(analysis=..., grade=...)\n+    return FeedbackResponse(analysis=llm_analysis, grade=llm_grade)\n+\n+# Asegúrate de que tu modelo FeedbackResponse esté definido en models/logic.py\n+# Ejemplo:\n+# from pydantic import BaseModel\n+# class FeedbackResponse(BaseModel):\n+#     analysis: str\n+#     grade: int # O float si tu LLM devuelve float\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746308006989,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -24,9 +24,13 @@\n # class FeedbackResponse(BaseModel):\n #    analysis: str\n #    grade: int # O float, según lo que devuelva tu LLM\n \n+import logging\n \n+logger = logging.getLogger(__name__)\n+logging.basicConfig(level=logging.INFO)\n+\n # --- Configuración para el LLM (Gemini) ---\n # Necesitas una función que llame a la API de Gemini.\n # Supondremos que tienes un archivo como utils/gemini_utils.py\n # con una función get_gemini_feedback(problem_text: str, user_answer: str) -> Dict[str, Any] (o None si falla).\n"
                },
                {
                    "date": 1746308026488,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,9 +18,9 @@\n from utils.auth_utils import get_current_user\n \n # Importa los modelos/schemas Pydantic\n # Necesitas el modelo FeedbackResponse para la respuesta\n-from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse # Asegúrate de que FeedbackResponse esté en models.logic\n+from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse # Asegúrate de que FeedbackResponse esté en models.logic\n # Si no tienes FeedbackResponse, defínelo en models/logic.py:\n # class FeedbackResponse(BaseModel):\n #    analysis: str\n #    grade: int # O float, según lo que devuelva tu LLM\n"
                },
                {
                    "date": 1746308175828,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,9 +8,9 @@\n import logging\n import asyncio # Necesario para asyncio.to_thread para llamadas síncronas a DB\n \n # Importa cliente Google Cloud Text-to-Speech si lo usas (ya debe estar)\n-# from google.cloud import texttospeech\n+from google.cloud import texttospeech\n \n # Importa tu cliente de MongoDB\n from mongodb_client import MongoDBClient\n \n"
                },
                {
                    "date": 1746308242795,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,10 @@\n     mongo_client = None # Set a None si falla para verificar en endpoints\n \n # Instancia del cliente Google Cloud Text-to-Speech (asumiendo que ya la tienes e inicializaste)\n # Debe estar definida globalmente en este archivo si la usas en /tts\n-# try: tts_client = texttospeech.TextToSpeechClient() except Exception: tts_client = None\n+try: tts_client = texttospeech.TextToSpeechClient() \n+except Exception: tts_client = None\n # Asegúrate de que el endpoint /tts está definido si lo usas.\n \n \n # --- Endpoint de Progreso ---\n"
                },
                {
                    "date": 1746308369828,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -185,11 +185,23 @@\n     logger.info(f\"Generando voz para usuario {user_email}: '{text[:50]}...'\")\n \n     try:\n         synthesis_input = texttospeech.SynthesisInput(text=text)\n-        voice = texttospeech.VoiceSelectionParams(language_code=\"es-MX\", ssml_gender=texttospeech.SsmlVoiceGender.FEMALE)\n-        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)\n+        voice = texttospeech.VoiceSelectionParams(\n+            language_code=\"es-MX\", # <-- Elige el código de idioma (\"es-MX\", \"es-ES\", etc.)\n+            ssml_gender=texttospeech.SsmlVoiceGender.FEMALE # <-- Elige el género (FEMALE, MALE)\n+            # OMITIR o comentar la línea 'name' si quieres que Google Cloud elija una voz estándar\n+            # name=\"es-MX-Wavenet-A\" # <-- COMENTA O ELIMINA esta línea para NO usar una voz Natural específica\n+        )\n \n+        # Configurar el formato de audio (esto ya estaba bien para MP3)\n+        audio_config = texttospeech.AudioConfig(\n+            audio_encoding=texttospeech.AudioEncoding.MP3,\n+            # Puedes ajustar la velocidad y el tono aquí si quieres\n+            speaking_rate=1.0, # 1.0 es velocidad normal\n+            pitch=0.0 # 0.0 es tono normal\n+        )\n+\n         response = tts_client.synthesize_speech(\n             input=synthesis_input,\n             voice=voice,\n             audio_config=audio_config\n"
                },
                {
                    "date": 1746309193381,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,411 @@\n+# routers/logic.py\n+\n+from fastapi import APIRouter, Depends, HTTPException, status, Query, Form # Importa Form si esperas datos de formulario\n+from fastapi.responses import Response\n+from bson import ObjectId\n+from typing import Optional, Dict, List, Union, Annotated # Importa Annotated\n+from datetime import datetime # Para el timestamp\n+import logging\n+import asyncio # Necesario para asyncio.to_thread para llamadas síncronas a DB\n+\n+# Importa cliente Google Cloud Text-to-Speech si lo usas (ya debe estar)\n+from google.cloud import texttospeech\n+\n+# Importa tu cliente de MongoDB\n+from mongodb_client import MongoDBClient\n+\n+# Importa tu dependencia de autenticación\n+from utils.auth_utils import get_current_user\n+\n+# Importa los modelos/schemas Pydantic\n+# Necesitas el modelo FeedbackResponse para la respuesta\n+from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse # Asegúrate de que FeedbackResponse esté en models.logic\n+# Si no tienes FeedbackResponse, defínelo en models/logic.py:\n+# class FeedbackResponse(BaseModel):\n+#    analysis: str\n+#    grade: int # O float, según lo que devuelva tu LLM\n+\n+import logging\n+\n+logger = logging.getLogger(__name__)\n+logging.basicConfig(level=logging.INFO)\n+\n+# --- Configuración para el LLM (Gemini) ---\n+# Necesitas una función que llame a la API de Gemini.\n+# Supondremos que tienes un archivo como utils/gemini_utils.py\n+# con una función get_gemini_feedback(problem_text: str, user_answer: str) -> Dict[str, Any] (o None si falla).\n+# Esta función debería llamar a la API de Gemini con un prompt adecuado.\n+try:\n+    # ASEGÚRATE de que la ruta de importación sea correcta para tu proyecto\n+    # y que el archivo utils/gemini_utils.py exista y tenga la función get_gemini_feedback\n+    from utils.gemini_utils import get_gemini_feedback\n+    GEMINI_AVAILABLE = True\n+    logger.info(\"Módulo gemini_utils importado correctamente.\")\n+except ImportError:\n+    logger.warning(\"Módulo gemini_utils no encontrado o get_gemini_feedback no definido. La evaluación usará placeholders.\")\n+    GEMINI_AVAILABLE = False\n+    # Definir una función placeholder async si no existe la real, para evitar errores\n+    async def get_gemini_feedback(problem_text: str, user_answer: str):\n+        logger.warning(\"Usando placeholder get_gemini_feedback.\")\n+        # Simulación de respuesta de Gemini (debe coincidir con el formato esperado)\n+        simulated_analysis = f\"Análisis simulado para '{user_answer[:50]}...'. Parece una respuesta con longitud {len(user_answer)}. (Evaluación Simulada)\"\n+        simulated_grade = max(0, min(10, len(user_answer) // 5)) # Simulación simple de nota 0-10\n+        # Simular algo de latencia\n+        await asyncio.sleep(1)\n+        return {\"analysis\": simulated_analysis, \"grade\": simulated_grade}\n+\n+\n+logger = logging.getLogger(__name__)\n+\n+router = APIRouter(\n+    prefix=\"/logic\", # Prefijo /logic para este router\n+    tags=[\"Logic Problems\"],\n+    # dependencies=[Depends(get_current_user)] # Opcional: Proteger todo el router\n+)\n+\n+# Instancia del Cliente MongoDB (asumiendo que ya la tienes)\n+try:\n+    mongo_client = MongoDBClient()\n+    logger.info(\"MongoDBClient instanciado en routers/logic.py\")\n+except Exception as e:\n+    logger.error(f\"Error al instanciar MongoDBClient en routers/logic.py: {e}\")\n+    mongo_client = None # Set a None si falla para verificar en endpoints\n+\n+# Instancia del cliente Google Cloud Text-to-Speech (asumiendo que ya la tienes e inicializaste)\n+# Debe estar definida globalmente en este archivo si la usas en /tts\n+try: tts_client = texttospeech.TextToSpeechClient() \n+except Exception: tts_client = None\n+# Asegúrate de que el endpoint /tts está definido si lo usas.\n+\n+\n+# --- Endpoint de Progreso ---\n+@router.get(\n+    \"/progress\",\n+    response_model=UserProgressResponse,\n+    summary=\"Obtiene el progreso del usuario autenticado\"\n+)\n+async def get_user_progress(\n+    # current_user ya es el diccionario del usuario de la DB\n+    current_db_user: Annotated[dict, Depends(get_current_user)]\n+):\n+    if mongo_client is None:\n+         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n+\n+    # Ya tenemos el documento del usuario gracias a Depends(get_current_user)\n+    # No necesitamos obtenerlo de nuevo por ID a menos que necesitemos una versión más reciente (poco probable aquí)\n+    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n+\n+    if not user_id or not isinstance(user_id, ObjectId):\n+         # Esto no debería pasar si get_current_user funciona bien, pero es una seguridad.\n+         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n+         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n+\n+    logger.info(f\"Solicitud de progreso para usuario: {user_email} (ID: {user_id})\")\n+\n+    # El array de ejercicios resueltos está directamente en el documento del usuario\n+    solved_exercises = current_db_user.get(\"ejercicios\", []) # Acceder directamente al array del documento proporcionado por el Depends\n+\n+    # Lógica de Cálculo (sin cambios)...\n+    progress_counts: Dict[str, int] = {\"basico\": 0, \"intermedio\": 0, \"avanzado\": 0}\n+    progress_sums: Dict[str, float] = {\"basico\": 0.0, \"intermedio\": 0.0, \"avanzado\": 0.0}\n+    total_solved_count = 0; total_grade_sum = 0.0\n+    for exercise in solved_exercises:\n+        if isinstance(exercise, dict) and exercise.get(\"problem_difficulty\") in progress_counts and isinstance(exercise.get(\"llm_grade\"), (int, float)):\n+            difficulty = exercise[\"problem_difficulty\"]; grade = exercise[\"llm_grade\"]\n+            total_solved_count += 1; total_grade_sum += grade\n+            progress_counts[difficulty] += 1; progress_sums[difficulty] += grade\n+        else: logger.warning(f\"Ejercicio formato inválido user_id {user_id}: {exercise}\")\n+    progress_by_difficulty: Dict[str, DifficultyProgress] = {}\n+    for dl in [\"basico\", \"intermedio\", \"avanzado\"]:\n+        count = progress_counts[dl]; grade_sum = progress_sums[dl]\n+        avg_grade = round(grade_sum / count, 2) if count > 0 else 0.0\n+        progress_by_difficulty[dl] = DifficultyProgress(solved_count=count, average_grade=avg_grade)\n+    overall_avg = round(total_grade_sum / total_solved_count, 2) if total_solved_count > 0 else 0.0\n+    logger.info(f\"Progreso calculado para {user_email}: Total={total_solved_count}, Avg={overall_avg}\")\n+    return UserProgressResponse(total_solved=total_solved_count, progress_by_difficulty=progress_by_difficulty, overall_average_grade=overall_avg, message=\"Tu progreso ha sido cargado.\")\n+\n+\n+# --- Endpoint para Obtener Problema ---\n+@router.get(\n+    \"/problem\",\n+    response_model=Union[ProblemResponse, NoProblemResponse],\n+    summary=\"Obtiene un problema de lógica no resuelto\"\n+)\n+async def get_logic_problem(\n+    current_db_user: Annotated[dict, Depends(get_current_user)],\n+    difficulty: Annotated[str | None, Query(description=\"Filtrar por dificultad\")] = None\n+):\n+    if mongo_client is None: raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio DB no disponible.\")\n+    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n+    if not user_id or not isinstance(user_id, ObjectId): raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"ID usuario inválido.\")\n+    if difficulty is not None and difficulty not in [\"basico\", \"intermedio\", \"avanzado\"]: raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Dificultad inválida.\")\n+    logger.info(f\"Buscando problema user_id: {user_id}, dificultad: {difficulty or 'cualquiera'}\")\n+\n+    try:\n+        # Asegúrate de que get_random_unsolved_problem es síncrono o usa async db driver (Motor)\n+        # Si es síncrono (PyMongo), usa asyncio.to_thread\n+        problem_dict = await asyncio.to_thread(mongo_client.get_random_unsolved_problem, user_id, difficulty=difficulty)\n+\n+    except Exception as db_error:\n+        logger.error(f\"Error DB consulta problemas user {user_id}: {db_error}\", exc_info=True)\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error DB consulta problemas.\")\n+\n+    if problem_dict:\n+        logger.info(f\"Problema encontrado {user_email}: ID={problem_dict.get('_id')}\")\n+        try:\n+             # Crear instancia Pydantic explícitamente para validación y serialización\n+             validated_problem = ProblemResponse(id=str(problem_dict[\"_id\"]), text=problem_dict[\"text\"], difficulty=problem_dict[\"difficulty\"], topics=problem_dict.get(\"topics\", []))\n+             return validated_problem\n+        except Exception as e:\n+             logger.error(f\"Error procesando datos problema {problem_dict.get('_id')} para {user_email}: {e}\", exc_info=True)\n+             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error procesando datos problema.\")\n+    else:\n+        logger.info(f\"No se encontraron problemas {user_email}, dificultad: {difficulty or 'cualquiera'}\")\n+        message = f\"¡Felicidades! Has resuelto todos los problemas de nivel '{difficulty}'.\" if difficulty else \"¡Felicidades! Has resuelto todos los problemas.\"\n+        return NoProblemResponse(message=message)\n+\n+\n+# --- Endpoint POST /tts (si usas Google Cloud TTS) ---\n+# ASEGÚRATE de que el cliente tts_client esté inicializado globalmente arriba\n+# ASEGÚRATE de tener instalada la librería google-cloud-texttospeech\n+@router.post(\"/tts\")\n+async def text_to_speech(\n+    # --- CAMBIO AQUÍ ---\n+    # Ahora FastAPI espera un cuerpo JSON que coincida con el modelo TTSTextRequest\n+    request_data: TTSTextRequest, # <-- Usamos el modelo Pydantic para el cuerpo\n+    # --- FIN CAMBIO ---\n+    current_user: Annotated[dict, Depends(get_current_user)] # Proteger el endpoint\n+):\n+    if not tts_client:\n+        logger.error(\"Intento de usar TTS, pero cliente no inicializado.\")\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Servicio de voz no disponible en el servidor.\")\n+\n+    # Obtener el texto del objeto recibido del frontend\n+    text = request_data.text # <-- Acceder al texto desde el objeto request_data\n+\n+    if not text: # Esta verificación aún es útil si el modelo permitiera texto vacío, pero el modelo BaseModel no lo permite por defecto\n+        logger.warning(f\"Solicitud /tts con texto vacío de usuario {current_user.get('email', 'N/A')}\")\n+        # FastAPI ya manejaría esto con 422 si el modelo requiriera texto no vacío, pero la dejamos por claridad.\n+        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"No se proporcionó texto para convertir a voz.\")\n+\n+    user_email = current_user.get(\"email\", \"N/A\")\n+    logger.info(f\"Generando voz para usuario {user_email}: '{text[:50]}...'\")\n+\n+    try:\n+        # ... (resto del código para llamar a synthesize_speech con el 'text' obtenido) ...\n+        synthesis_input = texttospeech.SynthesisInput(text=text)\n+        voice = texttospeech.VoiceSelectionParams(language_code=\"es-MX\", ssml_gender=texttospeech.SsmlVoiceGender.FEMALE) # Configurar voz estándar\n+        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3) # Configurar audio MP3\n+\n+        response = tts_client.synthesize_speech(\n+            input=synthesis_input,\n+            voice=voice,\n+            audio_config=audio_config\n+        )\n+\n+        logger.info(f\"Voz generada exitosamente para {user_email} ({len(response.audio_content)} bytes).\")\n+        return Response(content=response.audio_content, media_type=\"audio/mpeg\")\n+\n+    except Exception as e:\n+        logger.error(f\"Error durante la síntesis de voz con Google Cloud TTS para {user_email}: {str(e)}\", exc_info=True)\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Error al generar voz en el servidor: {str(e)}\")\n+\n+\n+# --- Endpoint para Enviar Respuesta (CONEXIÓN CON LLM Y SAVE RESULT) ---\n+# Este endpoint recibe el texto de la respuesta, la evalúa y la guarda.\n+# REQUIERE que tengas implementada la función get_gemini_feedback en utils/gemini_utils.py\n+# REQUIERE que add_solved_exercise en mongodb_client.py funcione correctamente.\n+@router.post(\n+    \"/submit_answer\",\n+    # Asumiendo que models/logic.py tiene un modelo FeedbackResponse\n+    # con al menos 'analysis' (str) y 'grade' (int o float).\n+    # Ejemplo: class FeedbackResponse(BaseModel): analysis: str; grade: int\n+    response_model=FeedbackResponse,\n+    summary=\"Recibe respuesta, evalúa con IA y guarda el resultado\",\n+)\n+async def submit_user_answer(\n+    # current_user es el documento del usuario logeado, ya obtenido por Depends\n+    current_db_user: Annotated[dict, Depends(get_current_user)],\n+    problem_id: Annotated[str, Form(...)], # Recibe el ID del problema (como string) del frontend (Form data)\n+    user_answer: Annotated[str, Form(...)] # Recibe el texto de la respuesta (como string) del frontend (Form data)\n+):\n+    if mongo_client is None:\n+         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n+\n+    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n+    if not user_id or not isinstance(user_id, ObjectId):\n+         # Esto no debería pasar con un Depends válido, pero es una seguridad\n+         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n+         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n+\n+    # 1. Validar y convertir el ID del problema recibido\n+    try:\n+        # problem_id llega como string del frontend (Form data)\n+        problem_id_obj = ObjectId(problem_id) # Convertir el string ID a ObjectId\n+    except Exception:\n+        # Si la conversión falla, el ID recibido no es válido\n+        logger.warning(f\"ID de problema inválido recibido de {user_email}: '{problem_id}'\")\n+        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"ID de problema inválido.\")\n+\n+    logger.info(f\"Usuario '{user_email}' (ID: {user_id}) envió respuesta para problema '{problem_id_obj}'.\")\n+    logger.debug(f\"Respuesta recibida: '{user_answer}'\")\n+\n+    # 2. Obtener el problema original de la DB (necesario para el prompt del LLM)\n+    # Asumiendo que tienes un método get_problem_by_id(problem_id_obj) en mongo_client\n+    try:\n+        # Si get_problem_by_id es síncrono (PyMongo), usa asyncio.to_thread\n+        # Si es async (Motor), quita await asyncio.to_thread\n+        problem_data = await asyncio.to_thread(mongo_client.get_problem_by_id, problem_id_obj)\n+        # Si no tienes get_problem_by_id, puedes intentar obtenerlo de la misma agregación que en get_random_unsolved_problem,\n+        # pero get_problem_by_id es más limpio. Implementa get_problem_by_id en mongo_client si no existe.\n+    except Exception as db_error:\n+        logger.error(f\"Error DB al obtener problema {problem_id_obj} para {user_email}: {db_error}\", exc_info=True)\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al validar el problema.\")\n+\n+    if not problem_data:\n+        logger.warning(f\"Problema {problem_id_obj} no encontrado en DB para respuesta de {user_email}.\")\n+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"El problema especificado no fue encontrado.\")\n+\n+    # 3. --- PREPARAR PROMPT PARA LLM ---\n+    # Aquí es donde construirías el prompt para el LLM, incluyendo:\n+    # - Contexto general del proyecto (aplicación educativa, para usuarios ciegos, etc.)\n+    # - Progreso del usuario (opcional, pero útil para contexto del LLM)\n+    # - El problema original (problem_data['text'])\n+    # - La respuesta del usuario (user_answer)\n+    # - Instrucciones claras para el LLM (analizar lógica, no código, calificar 1-5, formato JSON).\n+\n+    # Para obtener el progreso del usuario *actualizado* para el prompt,\n+    # podrías volver a calcularlo o obtener el documento completo de usuario.\n+    # El current_db_user ya trae el array 'ejercicios'.\n+    # Puedes reutilizar la lógica de cálculo de progreso de get_user_progress aquí.\n+\n+    user_solved_exercises = current_db_user.get(\"ejercicios\", []) # Array de ejercicios resueltos\n+    # Calcula el progreso actual (total, por dificultad, promedios) a partir de user_solved_exercises\n+\n+    # --- Simulación de cálculo de progreso para el prompt ---\n+    # NOTA: Reemplaza esto con la lógica real de cálculo de progreso si la necesitas en el prompt.\n+    total_solved_count = len(user_solved_exercises)\n+    # Aquí iría la lógica para calcular promedios y conteos por dificultad si los incluyes en el prompt.\n+    # --- Fin Simulación ---\n+\n+\n+    # --- Construir el prompt ---\n+    # Este prompt es CRUCIAL para guiar al LLM. Adapta el texto según el modelo LLM que uses.\n+    llm_prompt_parts = [\n+        \"SYSTEM: You are a programming logic tutor, friendly and helpful, specialized in assisting blind users learning to program. Your feedback should focus on the logical steps, problem-solving approach, correctness, and efficiency, not specific code syntax. Provide a clear analysis and assign a grade.\",\n+        \"CONTEXT: This is an educational web application for blind individuals. Interaction is primarily through voice. Your response will be read aloud by a screen reader.\",\n+        f\"USER_PROGRESS_SUMMARY: This user has solved {total_solved_count} exercises so far.\", # Puedes añadir más detalles aquí si los calculaste\n+        f\"PROGRAMMING_LOGIC_PROBLEM: {problem_data['text']}\", # El enunciado original del problema\n+        f\"USER_SUBMITTED_SOLUTION_LOGIC: {user_answer}\", # La respuesta transcrita del usuario\n+        \"INSTRUCTIONS: Based on the PROGRAMMING_LOGIC_PROBLEM and the USER_SUBMITTED_SOLUTION_LOGIC:\",\n+        \"- Analyze the user's proposed logic and thought process. Is it a valid approach to solve the problem?\",\n+        \"- Comment on its correctness, clarity, and potential efficiency. Discuss edge cases if relevant to the problem.\",\n+        \"- Do NOT provide code snippets or specific code syntax in your analysis.\",\n+        \"- Provide detailed feedback (aim for 50-200 words, keep it concise but informative for voice).\",\n+        \"- Assign a grade for the solution's logic on a scale of 0 to 10, where 0 is completely incorrect/no attempt, and 10 is excellent.\",\n+        \"- Respond ONLY in JSON format with the keys 'analysis' (string) and 'grade' (integer 0-10). Ensure the JSON is valid.\",\n+        \"EXAMPLE_JSON_RESPONSE: {\\\"analysis\\\": \\\"Your approach is logical and correct...\\\", \\\"grade\\\": 8}\"\n+    ]\n+    llm_prompt = \"\\n\".join(llm_prompt_parts)\n+\n+    # 4. --- LLAMADA AL LLM ---\n+    llm_analysis = \"Análisis no disponible (servicio de IA no configurado o falló).\"\n+    llm_grade = 0 # Grado por defecto si falla el LLM\n+\n+    if GEMINI_AVAILABLE:\n+        logger.info(f\"Llamando a Gemini para evaluar respuesta del problema {problem_id_obj} para user {user_email}...\")\n+        try:\n+            # La función get_gemini_feedback debe estar implementada en utils/gemini_utils.py\n+            # y ser ASYNC (def async) para usar await aquí.\n+            # Si es SÍNCRONA, usa: feedback_result = await asyncio.to_thread(get_gemini_feedback, ...)\n+            feedback_result = await get_gemini_feedback(problem_data['text'], user_answer, user_progress_summary=llm_prompt_parts[2]) # Pasar el prompt completo o solo la parte del progreso si la función lo acepta\n+\n+\n+            if feedback_result and isinstance(feedback_result, dict): # Verificar que sea un diccionario\n+                llm_analysis = feedback_result.get(\"analysis\", \"Error al extraer análisis del resultado de IA.\")\n+                try:\n+                     # Intentar convertir la calificación a entero, manejando posibles errores\n+                     llm_grade = int(feedback_result.get(\"grade\", 0))\n+                     # Asegurar que la calificación esté en el rango esperado (ej. 0-10)\n+                     llm_grade = max(0, min(10, llm_grade))\n+                except (ValueError, TypeError):\n+                     logger.error(f\"Nota inválida recibida de Gemini para {user_email} ({problem_id_obj}): '{feedback_result.get('grade')}'. Usando 0.\")\n+                     llm_grade = 0\n+                logger.info(f\"Evaluación de Gemini recibida para {user_email}: Calificación={llm_grade}\")\n+            else:\n+                logger.error(f\"La llamada a Gemini no devolvió un diccionario o falló para {user_email} ({problem_id_obj}). Resultado: {feedback_result}\")\n+                llm_analysis = \"La evaluación automática falló. Intenta de nuevo más tarde.\" # Mensaje amigable si el LLM falla\n+                llm_grade = 0 # Calificación por defecto si falla el LLM\n+        except Exception as llm_error:\n+            # Capturar errores durante la llamada o procesamiento de la respuesta de Gemini\n+            logger.error(f\"Error inesperado durante la llamada o procesamiento de Gemini para {user_email} ({problem_id_obj}): {llm_error}\", exc_info=True)\n+            llm_analysis = \"Error interno al procesar la evaluación automática. Intenta de nuevo.\" # Mensaje amigable si el LLM falla\n+            llm_grade = 0 # Calificación por defecto si falla el LLM\n+    else:\n+        # Lógica placeholder si Gemini no está disponible (definida arriba en el try/except de importación)\n+        # get_gemini_feedback ya es la función placeholder si la importación falla\n+        logger.warning(\"Usando evaluación placeholder porque Gemini no está disponible.\")\n+        # Llamamos al placeholder para generar un resultado simulado\n+        simulated_feedback = await get_gemini_feedback(problem_data['text'], user_answer)\n+        llm_analysis = simulated_feedback[\"analysis\"]\n+        llm_grade = simulated_feedback[\"grade\"]\n+\n+\n+    # 5. --- GUARDAR RESULTADO EN DB ---\n+    # Preparamos los datos para guardar en el array 'ejercicios' del usuario\n+    submission_data = {\n+        \"problem_id\": problem_id_obj, # ID del problema (ObjectId)\n+        \"problem_difficulty\": problem_data.get(\"difficulty\", \"desconocida\"), # Dificultad del problema original\n+        \"user_answer\": user_answer, # La respuesta del usuario (texto)\n+        \"analysis_received\": llm_analysis, # El análisis del LLM\n+        \"llm_grade\": llm_grade, # La calificación del LLM (0-10)\n+        \"submission_timestamp\": datetime.utcnow() # Timestamp de la sumisión\n+    }\n+\n+    save_error = False\n+    try:\n+        # Llamar al método add_solved_exercise de MongoDBClient para guardar\n+        # Asumiendo que add_solved_exercise es síncrono (PyMongo), usar asyncio.to_thread\n+        # Si es async (Motor), quitar await asyncio.to_thread\n+        update_result = await asyncio.to_thread(mongo_client.add_solved_exercise, user_id, submission_data)\n+\n+        # Verificar el resultado de la operación de guardado (opcional pero recomendado)\n+        # add_solved_exercise debería devolver UpdateResult si usa update_one\n+        if update_result is None:\n+            save_error = True\n+            logger.error(f\"La función add_solved_exercise devolvió None para user {user_id}. No se pudo guardar.\")\n+        elif hasattr(update_result, 'matched_count') and hasattr(update_result, 'modified_count'):\n+             if update_result.matched_count == 0:\n+                  save_error = True\n+                  logger.error(f\"No se encontró el usuario {user_id} para añadir el ejercicio resuelto (update_one matched_count=0).\")\n+             elif update_result.modified_count == 0:\n+                  # Esto puede pasar si el documento ya estaba en el array por alguna razón\n+                  logger.warning(f\"No se modificó el usuario {user_id} al añadir ejercicio (modified_count=0).\")\n+             else:\n+                  logger.info(f\"Ejercicio resuelto añadido correctamente al historial del usuario {user_id}\")\n+        else:\n+             # Si devolvió algo inesperado\n+             save_error = True\n+             logger.error(f\"Valor de retorno inesperado de add_solved_exercise para user {user_id}: {type(update_result)}\")\n+\n+\n+    except Exception as e:\n+        # Capturar errores durante la operación de guardado\n+        logger.error(f\"Error al intentar guardar el ejercicio resuelto para user {user_id} ({problem_id_obj}): {e}\", exc_info=True)\n+        save_error = True\n+        # No lanzamos excepción aquí para que el frontend reciba el feedback del LLM aunque no se haya guardado.\n+        # Puedes decidir lanzar una excepción si el guardado es crítico.\n+\n+\n+    logger.info(f\"Evaluación final para {user_email} (problema {problem_id_obj}): Calificación={llm_grade} (Guardado: {'No' if save_error else 'Sí'})\")\n+\n+    # 6. Devolver el feedback al frontend\n+    # Retornar FeedbackResponse(analysis=..., grade=...)\n+    return FeedbackResponse(analysis=llm_analysis, grade=llm_grade)\n+\n+# Asegúrate de que tu modelo FeedbackResponse esté definido en models/logic.py\n+# Ejemplo:\n+# from pydantic import BaseModel\n+# class FeedbackResponse(BaseModel):\n+#     analysis: str\n+#     grade: int # O float si tu LLM devuelve float\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746309215011,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,9 +18,9 @@\n from utils.auth_utils import get_current_user\n \n # Importa los modelos/schemas Pydantic\n # Necesitas el modelo FeedbackResponse para la respuesta\n-from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse # Asegúrate de que FeedbackResponse esté en models.logic\n+from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse, TTSTextRequest # Asegúrate de que FeedbackResponse esté en models.logic\n # Si no tienes FeedbackResponse, defínelo en models/logic.py:\n # class FeedbackResponse(BaseModel):\n #    analysis: str\n #    grade: int # O float, según lo que devuelva tu LLM\n@@ -407,420 +407,5 @@\n # Ejemplo:\n # from pydantic import BaseModel\n # class FeedbackResponse(BaseModel):\n #     analysis: str\n-#     grade: int # O float si tu LLM devuelve float\n-# routers/logic.py\n-\n-from fastapi import APIRouter, Depends, HTTPException, status, Query, Form # Importa Form si esperas datos de formulario\n-from fastapi.responses import Response\n-from bson import ObjectId\n-from typing import Optional, Dict, List, Union, Annotated # Importa Annotated\n-from datetime import datetime # Para el timestamp\n-import logging\n-import asyncio # Necesario para asyncio.to_thread para llamadas síncronas a DB\n-\n-# Importa cliente Google Cloud Text-to-Speech si lo usas (ya debe estar)\n-from google.cloud import texttospeech\n-\n-# Importa tu cliente de MongoDB\n-from mongodb_client import MongoDBClient\n-\n-# Importa tu dependencia de autenticación\n-from utils.auth_utils import get_current_user\n-\n-# Importa los modelos/schemas Pydantic\n-# Necesitas el modelo FeedbackResponse para la respuesta\n-from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse # Asegúrate de que FeedbackResponse esté en models.logic\n-# Si no tienes FeedbackResponse, defínelo en models/logic.py:\n-# class FeedbackResponse(BaseModel):\n-#    analysis: str\n-#    grade: int # O float, según lo que devuelva tu LLM\n-\n-import logging\n-\n-logger = logging.getLogger(__name__)\n-logging.basicConfig(level=logging.INFO)\n-\n-# --- Configuración para el LLM (Gemini) ---\n-# Necesitas una función que llame a la API de Gemini.\n-# Supondremos que tienes un archivo como utils/gemini_utils.py\n-# con una función get_gemini_feedback(problem_text: str, user_answer: str) -> Dict[str, Any] (o None si falla).\n-# Esta función debería llamar a la API de Gemini con un prompt adecuado.\n-try:\n-    # ASEGÚRATE de que la ruta de importación sea correcta para tu proyecto\n-    # y que el archivo utils/gemini_utils.py exista y tenga la función get_gemini_feedback\n-    from utils.gemini_utils import get_gemini_feedback\n-    GEMINI_AVAILABLE = True\n-    logger.info(\"Módulo gemini_utils importado correctamente.\")\n-except ImportError:\n-    logger.warning(\"Módulo gemini_utils no encontrado o get_gemini_feedback no definido. La evaluación usará placeholders.\")\n-    GEMINI_AVAILABLE = False\n-    # Definir una función placeholder async si no existe la real, para evitar errores\n-    async def get_gemini_feedback(problem_text: str, user_answer: str):\n-        logger.warning(\"Usando placeholder get_gemini_feedback.\")\n-        # Simulación de respuesta de Gemini (debe coincidir con el formato esperado)\n-        simulated_analysis = f\"Análisis simulado para '{user_answer[:50]}...'. Parece una respuesta con longitud {len(user_answer)}. (Evaluación Simulada)\"\n-        simulated_grade = max(0, min(10, len(user_answer) // 5)) # Simulación simple de nota 0-10\n-        # Simular algo de latencia\n-        await asyncio.sleep(1)\n-        return {\"analysis\": simulated_analysis, \"grade\": simulated_grade}\n-\n-\n-logger = logging.getLogger(__name__)\n-\n-router = APIRouter(\n-    prefix=\"/logic\", # Prefijo /logic para este router\n-    tags=[\"Logic Problems\"],\n-    # dependencies=[Depends(get_current_user)] # Opcional: Proteger todo el router\n-)\n-\n-# Instancia del Cliente MongoDB (asumiendo que ya la tienes)\n-try:\n-    mongo_client = MongoDBClient()\n-    logger.info(\"MongoDBClient instanciado en routers/logic.py\")\n-except Exception as e:\n-    logger.error(f\"Error al instanciar MongoDBClient en routers/logic.py: {e}\")\n-    mongo_client = None # Set a None si falla para verificar en endpoints\n-\n-# Instancia del cliente Google Cloud Text-to-Speech (asumiendo que ya la tienes e inicializaste)\n-# Debe estar definida globalmente en este archivo si la usas en /tts\n-try: tts_client = texttospeech.TextToSpeechClient() \n-except Exception: tts_client = None\n-# Asegúrate de que el endpoint /tts está definido si lo usas.\n-\n-\n-# --- Endpoint de Progreso ---\n-@router.get(\n-    \"/progress\",\n-    response_model=UserProgressResponse,\n-    summary=\"Obtiene el progreso del usuario autenticado\"\n-)\n-async def get_user_progress(\n-    # current_user ya es el diccionario del usuario de la DB\n-    current_db_user: Annotated[dict, Depends(get_current_user)]\n-):\n-    if mongo_client is None:\n-         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n-\n-    # Ya tenemos el documento del usuario gracias a Depends(get_current_user)\n-    # No necesitamos obtenerlo de nuevo por ID a menos que necesitemos una versión más reciente (poco probable aquí)\n-    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n-\n-    if not user_id or not isinstance(user_id, ObjectId):\n-         # Esto no debería pasar si get_current_user funciona bien, pero es una seguridad.\n-         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n-         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n-\n-    logger.info(f\"Solicitud de progreso para usuario: {user_email} (ID: {user_id})\")\n-\n-    # El array de ejercicios resueltos está directamente en el documento del usuario\n-    solved_exercises = current_db_user.get(\"ejercicios\", []) # Acceder directamente al array del documento proporcionado por el Depends\n-\n-    # Lógica de Cálculo (sin cambios)...\n-    progress_counts: Dict[str, int] = {\"basico\": 0, \"intermedio\": 0, \"avanzado\": 0}\n-    progress_sums: Dict[str, float] = {\"basico\": 0.0, \"intermedio\": 0.0, \"avanzado\": 0.0}\n-    total_solved_count = 0; total_grade_sum = 0.0\n-    for exercise in solved_exercises:\n-        if isinstance(exercise, dict) and exercise.get(\"problem_difficulty\") in progress_counts and isinstance(exercise.get(\"llm_grade\"), (int, float)):\n-            difficulty = exercise[\"problem_difficulty\"]; grade = exercise[\"llm_grade\"]\n-            total_solved_count += 1; total_grade_sum += grade\n-            progress_counts[difficulty] += 1; progress_sums[difficulty] += grade\n-        else: logger.warning(f\"Ejercicio formato inválido user_id {user_id}: {exercise}\")\n-    progress_by_difficulty: Dict[str, DifficultyProgress] = {}\n-    for dl in [\"basico\", \"intermedio\", \"avanzado\"]:\n-        count = progress_counts[dl]; grade_sum = progress_sums[dl]\n-        avg_grade = round(grade_sum / count, 2) if count > 0 else 0.0\n-        progress_by_difficulty[dl] = DifficultyProgress(solved_count=count, average_grade=avg_grade)\n-    overall_avg = round(total_grade_sum / total_solved_count, 2) if total_solved_count > 0 else 0.0\n-    logger.info(f\"Progreso calculado para {user_email}: Total={total_solved_count}, Avg={overall_avg}\")\n-    return UserProgressResponse(total_solved=total_solved_count, progress_by_difficulty=progress_by_difficulty, overall_average_grade=overall_avg, message=\"Tu progreso ha sido cargado.\")\n-\n-\n-# --- Endpoint para Obtener Problema ---\n-@router.get(\n-    \"/problem\",\n-    response_model=Union[ProblemResponse, NoProblemResponse],\n-    summary=\"Obtiene un problema de lógica no resuelto\"\n-)\n-async def get_logic_problem(\n-    current_db_user: Annotated[dict, Depends(get_current_user)],\n-    difficulty: Annotated[str | None, Query(description=\"Filtrar por dificultad\")] = None\n-):\n-    if mongo_client is None: raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio DB no disponible.\")\n-    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n-    if not user_id or not isinstance(user_id, ObjectId): raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"ID usuario inválido.\")\n-    if difficulty is not None and difficulty not in [\"basico\", \"intermedio\", \"avanzado\"]: raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Dificultad inválida.\")\n-    logger.info(f\"Buscando problema user_id: {user_id}, dificultad: {difficulty or 'cualquiera'}\")\n-\n-    try:\n-        # Asegúrate de que get_random_unsolved_problem es síncrono o usa async db driver (Motor)\n-        # Si es síncrono (PyMongo), usa asyncio.to_thread\n-        problem_dict = await asyncio.to_thread(mongo_client.get_random_unsolved_problem, user_id, difficulty=difficulty)\n-\n-    except Exception as db_error:\n-        logger.error(f\"Error DB consulta problemas user {user_id}: {db_error}\", exc_info=True)\n-        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error DB consulta problemas.\")\n-\n-    if problem_dict:\n-        logger.info(f\"Problema encontrado {user_email}: ID={problem_dict.get('_id')}\")\n-        try:\n-             # Crear instancia Pydantic explícitamente para validación y serialización\n-             validated_problem = ProblemResponse(id=str(problem_dict[\"_id\"]), text=problem_dict[\"text\"], difficulty=problem_dict[\"difficulty\"], topics=problem_dict.get(\"topics\", []))\n-             return validated_problem\n-        except Exception as e:\n-             logger.error(f\"Error procesando datos problema {problem_dict.get('_id')} para {user_email}: {e}\", exc_info=True)\n-             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error procesando datos problema.\")\n-    else:\n-        logger.info(f\"No se encontraron problemas {user_email}, dificultad: {difficulty or 'cualquiera'}\")\n-        message = f\"¡Felicidades! Has resuelto todos los problemas de nivel '{difficulty}'.\" if difficulty else \"¡Felicidades! Has resuelto todos los problemas.\"\n-        return NoProblemResponse(message=message)\n-\n-\n-# --- Endpoint POST /tts (si usas Google Cloud TTS) ---\n-# ASEGÚRATE de que el cliente tts_client esté inicializado globalmente arriba\n-# ASEGÚRATE de tener instalada la librería google-cloud-texttospeech\n-@router.post(\"/tts\")\n-async def text_to_speech(\n-    text: str, # Espera texto en cuerpo JSON {\"text\": \"...\"}\n-    current_user: Annotated[dict, Depends(get_current_user)] # Proteger el endpoint\n-):\n-    if not tts_client:\n-        logger.error(\"Intento de usar TTS, pero cliente no inicializado.\")\n-        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Servicio de voz no disponible en el servidor.\")\n-\n-    if not text:\n-        logger.warning(f\"Solicitud /tts vacía de usuario {current_user.get('email', 'N/A')}\")\n-        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"No se proporcionó texto para convertir a voz.\")\n-\n-    user_email = current_user.get(\"email\", \"N/A\")\n-    logger.info(f\"Generando voz para usuario {user_email}: '{text[:50]}...'\")\n-\n-    try:\n-        synthesis_input = texttospeech.SynthesisInput(text=text)\n-        voice = texttospeech.VoiceSelectionParams(\n-            language_code=\"es-MX\", # <-- Elige el código de idioma (\"es-MX\", \"es-ES\", etc.)\n-            ssml_gender=texttospeech.SsmlVoiceGender.FEMALE # <-- Elige el género (FEMALE, MALE)\n-            # OMITIR o comentar la línea 'name' si quieres que Google Cloud elija una voz estándar\n-            # name=\"es-MX-Wavenet-A\" # <-- COMENTA O ELIMINA esta línea para NO usar una voz Natural específica\n-        )\n-\n-        # Configurar el formato de audio (esto ya estaba bien para MP3)\n-        audio_config = texttospeech.AudioConfig(\n-            audio_encoding=texttospeech.AudioEncoding.MP3,\n-            # Puedes ajustar la velocidad y el tono aquí si quieres\n-            speaking_rate=1.0, # 1.0 es velocidad normal\n-            pitch=0.0 # 0.0 es tono normal\n-        )\n-\n-        response = tts_client.synthesize_speech(\n-            input=synthesis_input,\n-            voice=voice,\n-            audio_config=audio_config\n-        )\n-\n-        logger.info(f\"Voz generada exitosamente para {user_email} ({len(response.audio_content)} bytes).\")\n-        return Response(content=response.audio_content, media_type=\"audio/mpeg\")\n-\n-    except Exception as e:\n-        logger.error(f\"Error durante la síntesis de voz con Google Cloud TTS para {user_email}: {str(e)}\", exc_info=True)\n-        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Error al generar voz en el servidor: {str(e)}\")\n-\n-\n-# --- Endpoint para Enviar Respuesta (CONEXIÓN CON LLM Y SAVE RESULT) ---\n-# Este endpoint recibe el texto de la respuesta, la evalúa y la guarda.\n-# REQUIERE que tengas implementada la función get_gemini_feedback en utils/gemini_utils.py\n-# REQUIERE que add_solved_exercise en mongodb_client.py funcione correctamente.\n-@router.post(\n-    \"/submit_answer\",\n-    # Asumiendo que models/logic.py tiene un modelo FeedbackResponse\n-    # con al menos 'analysis' (str) y 'grade' (int o float).\n-    # Ejemplo: class FeedbackResponse(BaseModel): analysis: str; grade: int\n-    response_model=FeedbackResponse,\n-    summary=\"Recibe respuesta, evalúa con IA y guarda el resultado\",\n-)\n-async def submit_user_answer(\n-    # current_user es el documento del usuario logeado, ya obtenido por Depends\n-    current_db_user: Annotated[dict, Depends(get_current_user)],\n-    problem_id: Annotated[str, Form(...)], # Recibe el ID del problema (como string) del frontend (Form data)\n-    user_answer: Annotated[str, Form(...)] # Recibe el texto de la respuesta (como string) del frontend (Form data)\n-):\n-    if mongo_client is None:\n-         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n-\n-    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n-    if not user_id or not isinstance(user_id, ObjectId):\n-         # Esto no debería pasar con un Depends válido, pero es una seguridad\n-         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n-         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n-\n-    # 1. Validar y convertir el ID del problema recibido\n-    try:\n-        # problem_id llega como string del frontend (Form data)\n-        problem_id_obj = ObjectId(problem_id) # Convertir el string ID a ObjectId\n-    except Exception:\n-        # Si la conversión falla, el ID recibido no es válido\n-        logger.warning(f\"ID de problema inválido recibido de {user_email}: '{problem_id}'\")\n-        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"ID de problema inválido.\")\n-\n-    logger.info(f\"Usuario '{user_email}' (ID: {user_id}) envió respuesta para problema '{problem_id_obj}'.\")\n-    logger.debug(f\"Respuesta recibida: '{user_answer}'\")\n-\n-    # 2. Obtener el problema original de la DB (necesario para el prompt del LLM)\n-    # Asumiendo que tienes un método get_problem_by_id(problem_id_obj) en mongo_client\n-    try:\n-        # Si get_problem_by_id es síncrono (PyMongo), usa asyncio.to_thread\n-        # Si es async (Motor), quita await asyncio.to_thread\n-        problem_data = await asyncio.to_thread(mongo_client.get_problem_by_id, problem_id_obj)\n-        # Si no tienes get_problem_by_id, puedes intentar obtenerlo de la misma agregación que en get_random_unsolved_problem,\n-        # pero get_problem_by_id es más limpio. Implementa get_problem_by_id en mongo_client si no existe.\n-    except Exception as db_error:\n-        logger.error(f\"Error DB al obtener problema {problem_id_obj} para {user_email}: {db_error}\", exc_info=True)\n-        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al validar el problema.\")\n-\n-    if not problem_data:\n-        logger.warning(f\"Problema {problem_id_obj} no encontrado en DB para respuesta de {user_email}.\")\n-        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"El problema especificado no fue encontrado.\")\n-\n-    # 3. --- PREPARAR PROMPT PARA LLM ---\n-    # Aquí es donde construirías el prompt para el LLM, incluyendo:\n-    # - Contexto general del proyecto (aplicación educativa, para usuarios ciegos, etc.)\n-    # - Progreso del usuario (opcional, pero útil para contexto del LLM)\n-    # - El problema original (problem_data['text'])\n-    # - La respuesta del usuario (user_answer)\n-    # - Instrucciones claras para el LLM (analizar lógica, no código, calificar 1-5, formato JSON).\n-\n-    # Para obtener el progreso del usuario *actualizado* para el prompt,\n-    # podrías volver a calcularlo o obtener el documento completo de usuario.\n-    # El current_db_user ya trae el array 'ejercicios'.\n-    # Puedes reutilizar la lógica de cálculo de progreso de get_user_progress aquí.\n-\n-    user_solved_exercises = current_db_user.get(\"ejercicios\", []) # Array de ejercicios resueltos\n-    # Calcula el progreso actual (total, por dificultad, promedios) a partir de user_solved_exercises\n-\n-    # --- Simulación de cálculo de progreso para el prompt ---\n-    # NOTA: Reemplaza esto con la lógica real de cálculo de progreso si la necesitas en el prompt.\n-    total_solved_count = len(user_solved_exercises)\n-    # Aquí iría la lógica para calcular promedios y conteos por dificultad si los incluyes en el prompt.\n-    # --- Fin Simulación ---\n-\n-\n-    # --- Construir el prompt ---\n-    # Este prompt es CRUCIAL para guiar al LLM. Adapta el texto según el modelo LLM que uses.\n-    llm_prompt_parts = [\n-        \"SYSTEM: You are a programming logic tutor, friendly and helpful, specialized in assisting blind users learning to program. Your feedback should focus on the logical steps, problem-solving approach, correctness, and efficiency, not specific code syntax. Provide a clear analysis and assign a grade.\",\n-        \"CONTEXT: This is an educational web application for blind individuals. Interaction is primarily through voice. Your response will be read aloud by a screen reader.\",\n-        f\"USER_PROGRESS_SUMMARY: This user has solved {total_solved_count} exercises so far.\", # Puedes añadir más detalles aquí si los calculaste\n-        f\"PROGRAMMING_LOGIC_PROBLEM: {problem_data['text']}\", # El enunciado original del problema\n-        f\"USER_SUBMITTED_SOLUTION_LOGIC: {user_answer}\", # La respuesta transcrita del usuario\n-        \"INSTRUCTIONS: Based on the PROGRAMMING_LOGIC_PROBLEM and the USER_SUBMITTED_SOLUTION_LOGIC:\",\n-        \"- Analyze the user's proposed logic and thought process. Is it a valid approach to solve the problem?\",\n-        \"- Comment on its correctness, clarity, and potential efficiency. Discuss edge cases if relevant to the problem.\",\n-        \"- Do NOT provide code snippets or specific code syntax in your analysis.\",\n-        \"- Provide detailed feedback (aim for 50-200 words, keep it concise but informative for voice).\",\n-        \"- Assign a grade for the solution's logic on a scale of 0 to 10, where 0 is completely incorrect/no attempt, and 10 is excellent.\",\n-        \"- Respond ONLY in JSON format with the keys 'analysis' (string) and 'grade' (integer 0-10). Ensure the JSON is valid.\",\n-        \"EXAMPLE_JSON_RESPONSE: {\\\"analysis\\\": \\\"Your approach is logical and correct...\\\", \\\"grade\\\": 8}\"\n-    ]\n-    llm_prompt = \"\\n\".join(llm_prompt_parts)\n-\n-    # 4. --- LLAMADA AL LLM ---\n-    llm_analysis = \"Análisis no disponible (servicio de IA no configurado o falló).\"\n-    llm_grade = 0 # Grado por defecto si falla el LLM\n-\n-    if GEMINI_AVAILABLE:\n-        logger.info(f\"Llamando a Gemini para evaluar respuesta del problema {problem_id_obj} para user {user_email}...\")\n-        try:\n-            # La función get_gemini_feedback debe estar implementada en utils/gemini_utils.py\n-            # y ser ASYNC (def async) para usar await aquí.\n-            # Si es SÍNCRONA, usa: feedback_result = await asyncio.to_thread(get_gemini_feedback, ...)\n-            feedback_result = await get_gemini_feedback(problem_data['text'], user_answer, user_progress_summary=llm_prompt_parts[2]) # Pasar el prompt completo o solo la parte del progreso si la función lo acepta\n-\n-\n-            if feedback_result and isinstance(feedback_result, dict): # Verificar que sea un diccionario\n-                llm_analysis = feedback_result.get(\"analysis\", \"Error al extraer análisis del resultado de IA.\")\n-                try:\n-                     # Intentar convertir la calificación a entero, manejando posibles errores\n-                     llm_grade = int(feedback_result.get(\"grade\", 0))\n-                     # Asegurar que la calificación esté en el rango esperado (ej. 0-10)\n-                     llm_grade = max(0, min(10, llm_grade))\n-                except (ValueError, TypeError):\n-                     logger.error(f\"Nota inválida recibida de Gemini para {user_email} ({problem_id_obj}): '{feedback_result.get('grade')}'. Usando 0.\")\n-                     llm_grade = 0\n-                logger.info(f\"Evaluación de Gemini recibida para {user_email}: Calificación={llm_grade}\")\n-            else:\n-                logger.error(f\"La llamada a Gemini no devolvió un diccionario o falló para {user_email} ({problem_id_obj}). Resultado: {feedback_result}\")\n-                llm_analysis = \"La evaluación automática falló. Intenta de nuevo más tarde.\" # Mensaje amigable si el LLM falla\n-                llm_grade = 0 # Calificación por defecto si falla el LLM\n-        except Exception as llm_error:\n-            # Capturar errores durante la llamada o procesamiento de la respuesta de Gemini\n-            logger.error(f\"Error inesperado durante la llamada o procesamiento de Gemini para {user_email} ({problem_id_obj}): {llm_error}\", exc_info=True)\n-            llm_analysis = \"Error interno al procesar la evaluación automática. Intenta de nuevo.\" # Mensaje amigable si el LLM falla\n-            llm_grade = 0 # Calificación por defecto si falla el LLM\n-    else:\n-        # Lógica placeholder si Gemini no está disponible (definida arriba en el try/except de importación)\n-        # get_gemini_feedback ya es la función placeholder si la importación falla\n-        logger.warning(\"Usando evaluación placeholder porque Gemini no está disponible.\")\n-        # Llamamos al placeholder para generar un resultado simulado\n-        simulated_feedback = await get_gemini_feedback(problem_data['text'], user_answer)\n-        llm_analysis = simulated_feedback[\"analysis\"]\n-        llm_grade = simulated_feedback[\"grade\"]\n-\n-\n-    # 5. --- GUARDAR RESULTADO EN DB ---\n-    # Preparamos los datos para guardar en el array 'ejercicios' del usuario\n-    submission_data = {\n-        \"problem_id\": problem_id_obj, # ID del problema (ObjectId)\n-        \"problem_difficulty\": problem_data.get(\"difficulty\", \"desconocida\"), # Dificultad del problema original\n-        \"user_answer\": user_answer, # La respuesta del usuario (texto)\n-        \"analysis_received\": llm_analysis, # El análisis del LLM\n-        \"llm_grade\": llm_grade, # La calificación del LLM (0-10)\n-        \"submission_timestamp\": datetime.utcnow() # Timestamp de la sumisión\n-    }\n-\n-    save_error = False\n-    try:\n-        # Llamar al método add_solved_exercise de MongoDBClient para guardar\n-        # Asumiendo que add_solved_exercise es síncrono (PyMongo), usar asyncio.to_thread\n-        # Si es async (Motor), quitar await asyncio.to_thread\n-        update_result = await asyncio.to_thread(mongo_client.add_solved_exercise, user_id, submission_data)\n-\n-        # Verificar el resultado de la operación de guardado (opcional pero recomendado)\n-        # add_solved_exercise debería devolver UpdateResult si usa update_one\n-        if update_result is None:\n-            save_error = True\n-            logger.error(f\"La función add_solved_exercise devolvió None para user {user_id}. No se pudo guardar.\")\n-        elif hasattr(update_result, 'matched_count') and hasattr(update_result, 'modified_count'):\n-             if update_result.matched_count == 0:\n-                  save_error = True\n-                  logger.error(f\"No se encontró el usuario {user_id} para añadir el ejercicio resuelto (update_one matched_count=0).\")\n-             elif update_result.modified_count == 0:\n-                  # Esto puede pasar si el documento ya estaba en el array por alguna razón\n-                  logger.warning(f\"No se modificó el usuario {user_id} al añadir ejercicio (modified_count=0).\")\n-             else:\n-                  logger.info(f\"Ejercicio resuelto añadido correctamente al historial del usuario {user_id}\")\n-        else:\n-             # Si devolvió algo inesperado\n-             save_error = True\n-             logger.error(f\"Valor de retorno inesperado de add_solved_exercise para user {user_id}: {type(update_result)}\")\n-\n-\n-    except Exception as e:\n-        # Capturar errores durante la operación de guardado\n-        logger.error(f\"Error al intentar guardar el ejercicio resuelto para user {user_id} ({problem_id_obj}): {e}\", exc_info=True)\n-        save_error = True\n-        # No lanzamos excepción aquí para que el frontend reciba el feedback del LLM aunque no se haya guardado.\n-        # Puedes decidir lanzar una excepción si el guardado es crítico.\n-\n-\n-    logger.info(f\"Evaluación final para {user_email} (problema {problem_id_obj}): Calificación={llm_grade} (Guardado: {'No' if save_error else 'Sí'})\")\n-\n-    # 6. Devolver el feedback al frontend\n-    # Retornar FeedbackResponse(analysis=..., grade=...)\n-    return FeedbackResponse(analysis=llm_analysis, grade=llm_grade)\n-\n-# Asegúrate de que tu modelo FeedbackResponse esté definido en models/logic.py\n-# Ejemplo:\n-# from pydantic import BaseModel\n-# class FeedbackResponse(BaseModel):\n-#     analysis: str\n #     grade: int # O float si tu LLM devuelve float\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746309227495,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,409 @@\n+# routers/logic.py\n+\n+from fastapi import APIRouter, Depends, HTTPException, status, Query, Form # Importa Form si esperas datos de formulario\n+from fastapi.responses import Response\n+from bson import ObjectId\n+from typing import Optional, Dict, List, Union, Annotated # Importa Annotated\n+from datetime import datetime # Para el timestamp\n+import logging\n+import asyncio # Necesario para asyncio.to_thread para llamadas síncronas a DB\n+\n+# Importa cliente Google Cloud Text-to-Speech si lo usas (ya debe estar)\n+from google.cloud import texttospeech\n+\n+# Importa tu cliente de MongoDB\n+from mongodb_client import MongoDBClient\n+\n+# Importa tu dependencia de autenticación\n+from utils.auth_utils import get_current_user\n+\n+# Importa los modelos/schemas Pydantic\n+# Necesitas el modelo FeedbackResponse para la respuesta\n+from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse, TTSTextRequest # Asegúrate de que FeedbackResponse esté en models.logic\n+# Si no tienes FeedbackResponse, defínelo en models/logic.py:\n+# class FeedbackResponse(BaseModel):\n+#    analysis: str\n+#    grade: int # O float, según lo que devuelva tu LLM\n+\n+import logging\n+\n+logger = logging.getLogger(__name__)\n+logging.basicConfig(level=logging.INFO)\n+\n+# --- Configuración para el LLM (Gemini) ---\n+# Necesitas una función que llame a la API de Gemini.\n+# Supondremos que tienes un archivo como utils/gemini_utils.py\n+# con una función get_gemini_feedback(problem_text: str, user_answer: str) -> Dict[str, Any] (o None si falla).\n+# Esta función debería llamar a la API de Gemini con un prompt adecuado.\n+try:\n+    # ASEGÚRATE de que la ruta de importación sea correcta para tu proyecto\n+    # y que el archivo utils/gemini_utils.py exista y tenga la función get_gemini_feedback\n+    from utils.gemini_utils import get_gemini_feedback\n+    GEMINI_AVAILABLE = True\n+    logger.info(\"Módulo gemini_utils importado correctamente.\")\n+except ImportError:\n+    logger.warning(\"Módulo gemini_utils no encontrado o get_gemini_feedback no definido. La evaluación usará placeholders.\")\n+    GEMINI_AVAILABLE = False\n+    # Definir una función placeholder async si no existe la real, para evitar errores\n+    async def get_gemini_feedback(problem_text: str, user_answer: str):\n+        logger.warning(\"Usando placeholder get_gemini_feedback.\")\n+        # Simulación de respuesta de Gemini (debe coincidir con el formato esperado)\n+        simulated_analysis = f\"Análisis simulado para '{user_answer[:50]}...'. Parece una respuesta con longitud {len(user_answer)}. (Evaluación Simulada)\"\n+        simulated_grade = max(0, min(10, len(user_answer) // 5)) # Simulación simple de nota 0-10\n+        # Simular algo de latencia\n+        await asyncio.sleep(1)\n+        return {\"analysis\": simulated_analysis, \"grade\": simulated_grade}\n+\n+\n+logger = logging.getLogger(__name__)\n+\n+router = APIRouter(\n+    prefix=\"/logic\", # Prefijo /logic para este router\n+    tags=[\"Logic Problems\"],\n+    # dependencies=[Depends(get_current_user)] # Opcional: Proteger todo el router\n+)\n+\n+# Instancia del Cliente MongoDB (asumiendo que ya la tienes)\n+try:\n+    mongo_client = MongoDBClient()\n+    logger.info(\"MongoDBClient instanciado en routers/logic.py\")\n+except Exception as e:\n+    logger.error(f\"Error al instanciar MongoDBClient en routers/logic.py: {e}\")\n+    mongo_client = None # Set a None si falla para verificar en endpoints\n+\n+# Instancia del cliente Google Cloud Text-to-Speech (asumiendo que ya la tienes e inicializaste)\n+# Debe estar definida globalmente en este archivo si la usas en /tts\n+try: tts_client = texttospeech.TextToSpeechClient() \n+except Exception: tts_client = None\n+# Asegúrate de que el endpoint /tts está definido si lo usas.\n+\n+\n+# --- Endpoint de Progreso ---\n+@router.get(\n+    \"/progress\",\n+    response_model=UserProgressResponse,\n+    summary=\"Obtiene el progreso del usuario autenticado\"\n+)\n+async def get_user_progress(\n+    # current_user ya es el diccionario del usuario de la DB\n+    current_db_user: Annotated[dict, Depends(get_current_user)]\n+):\n+    if mongo_client is None:\n+         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n+\n+    # Ya tenemos el documento del usuario gracias a Depends(get_current_user)\n+    # No necesitamos obtenerlo de nuevo por ID a menos que necesitemos una versión más reciente (poco probable aquí)\n+    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n+\n+    if not user_id or not isinstance(user_id, ObjectId):\n+         # Esto no debería pasar si get_current_user funciona bien, pero es una seguridad.\n+         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n+         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n+\n+    logger.info(f\"Solicitud de progreso para usuario: {user_email} (ID: {user_id})\")\n+\n+    # El array de ejercicios resueltos está directamente en el documento del usuario\n+    solved_exercises = current_db_user.get(\"ejercicios\", []) # Acceder directamente al array del documento proporcionado por el Depends\n+\n+    # Lógica de Cálculo (sin cambios)...\n+    progress_counts: Dict[str, int] = {\"basico\": 0, \"intermedio\": 0, \"avanzado\": 0}\n+    progress_sums: Dict[str, float] = {\"basico\": 0.0, \"intermedio\": 0.0, \"avanzado\": 0.0}\n+    total_solved_count = 0; total_grade_sum = 0.0\n+    for exercise in solved_exercises:\n+        if isinstance(exercise, dict) and exercise.get(\"problem_difficulty\") in progress_counts and isinstance(exercise.get(\"llm_grade\"), (int, float)):\n+            difficulty = exercise[\"problem_difficulty\"]; grade = exercise[\"llm_grade\"]\n+            total_solved_count += 1; total_grade_sum += grade\n+            progress_counts[difficulty] += 1; progress_sums[difficulty] += grade\n+        else: logger.warning(f\"Ejercicio formato inválido user_id {user_id}: {exercise}\")\n+    progress_by_difficulty: Dict[str, DifficultyProgress] = {}\n+    for dl in [\"basico\", \"intermedio\", \"avanzado\"]:\n+        count = progress_counts[dl]; grade_sum = progress_sums[dl]\n+        avg_grade = round(grade_sum / count, 2) if count > 0 else 0.0\n+        progress_by_difficulty[dl] = DifficultyProgress(solved_count=count, average_grade=avg_grade)\n+    overall_avg = round(total_grade_sum / total_solved_count, 2) if total_solved_count > 0 else 0.0\n+    logger.info(f\"Progreso calculado para {user_email}: Total={total_solved_count}, Avg={overall_avg}\")\n+    return UserProgressResponse(total_solved=total_solved_count, progress_by_difficulty=progress_by_difficulty, overall_average_grade=overall_avg, message=\"Tu progreso ha sido cargado.\")\n+\n+\n+# --- Endpoint para Obtener Problema ---\n+@router.get(\n+    \"/problem\",\n+    response_model=Union[ProblemResponse, NoProblemResponse],\n+    summary=\"Obtiene un problema de lógica no resuelto\"\n+)\n+async def get_logic_problem(\n+    current_db_user: Annotated[dict, Depends(get_current_user)],\n+    difficulty: Annotated[str | None, Query(description=\"Filtrar por dificultad\")] = None\n+):\n+    if mongo_client is None: raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio DB no disponible.\")\n+    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n+    if not user_id or not isinstance(user_id, ObjectId): raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"ID usuario inválido.\")\n+    if difficulty is not None and difficulty not in [\"basico\", \"intermedio\", \"avanzado\"]: raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Dificultad inválida.\")\n+    logger.info(f\"Buscando problema user_id: {user_id}, dificultad: {difficulty or 'cualquiera'}\")\n+\n+    try:\n+        # Asegúrate de que get_random_unsolved_problem es síncrono o usa async db driver (Motor)\n+        # Si es síncrono (PyMongo), usa asyncio.to_thread\n+        problem_dict = await asyncio.to_thread(mongo_client.get_random_unsolved_problem, user_id, difficulty=difficulty)\n+\n+    except Exception as db_error:\n+        logger.error(f\"Error DB consulta problemas user {user_id}: {db_error}\", exc_info=True)\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error DB consulta problemas.\")\n+\n+    if problem_dict:\n+        logger.info(f\"Problema encontrado {user_email}: ID={problem_dict.get('_id')}\")\n+        try:\n+             # Crear instancia Pydantic explícitamente para validación y serialización\n+             validated_problem = ProblemResponse(id=str(problem_dict[\"_id\"]), text=problem_dict[\"text\"], difficulty=problem_dict[\"difficulty\"], topics=problem_dict.get(\"topics\", []))\n+             return validated_problem\n+        except Exception as e:\n+             logger.error(f\"Error procesando datos problema {problem_dict.get('_id')} para {user_email}: {e}\", exc_info=True)\n+             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error procesando datos problema.\")\n+    else:\n+        logger.info(f\"No se encontraron problemas {user_email}, dificultad: {difficulty or 'cualquiera'}\")\n+        message = f\"¡Felicidades! Has resuelto todos los problemas de nivel '{difficulty}'.\" if difficulty else \"¡Felicidades! Has resuelto todos los problemas.\"\n+        return NoProblemResponse(message=message)\n+\n+\n+# --- Endpoint POST /tts \n+@router.post(\"/tts\")\n+async def text_to_speech(\n+    # --- CAMBIO AQUÍ ---\n+    # Ahora FastAPI espera un cuerpo JSON que coincida con el modelo TTSTextRequest\n+    request_data: TTSTextRequest, # <-- Usamos el modelo Pydantic para el cuerpo\n+    # --- FIN CAMBIO ---\n+    current_user: Annotated[dict, Depends(get_current_user)] # Proteger el endpoint\n+):\n+    if not tts_client:\n+        logger.error(\"Intento de usar TTS, pero cliente no inicializado.\")\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Servicio de voz no disponible en el servidor.\")\n+\n+    # Obtener el texto del objeto recibido del frontend\n+    text = request_data.text # <-- Acceder al texto desde el objeto request_data\n+\n+    if not text: # Esta verificación aún es útil si el modelo permitiera texto vacío, pero el modelo BaseModel no lo permite por defecto\n+        logger.warning(f\"Solicitud /tts con texto vacío de usuario {current_user.get('email', 'N/A')}\")\n+        # FastAPI ya manejaría esto con 422 si el modelo requiriera texto no vacío, pero la dejamos por claridad.\n+        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"No se proporcionó texto para convertir a voz.\")\n+\n+    user_email = current_user.get(\"email\", \"N/A\")\n+    logger.info(f\"Generando voz para usuario {user_email}: '{text[:50]}...'\")\n+\n+    try:\n+        # ... (resto del código para llamar a synthesize_speech con el 'text' obtenido) ...\n+        synthesis_input = texttospeech.SynthesisInput(text=text)\n+        voice = texttospeech.VoiceSelectionParams(language_code=\"es-MX\", ssml_gender=texttospeech.SsmlVoiceGender.FEMALE) # Configurar voz estándar\n+        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3) # Configurar audio MP3\n+\n+        response = tts_client.synthesize_speech(\n+            input=synthesis_input,\n+            voice=voice,\n+            audio_config=audio_config\n+        )\n+\n+        logger.info(f\"Voz generada exitosamente para {user_email} ({len(response.audio_content)} bytes).\")\n+        return Response(content=response.audio_content, media_type=\"audio/mpeg\")\n+\n+    except Exception as e:\n+        logger.error(f\"Error durante la síntesis de voz con Google Cloud TTS para {user_email}: {str(e)}\", exc_info=True)\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Error al generar voz en el servidor: {str(e)}\")\n+\n+\n+# --- Endpoint para Enviar Respuesta (CONEXIÓN CON LLM Y SAVE RESULT) ---\n+# Este endpoint recibe el texto de la respuesta, la evalúa y la guarda.\n+# REQUIERE que tengas implementada la función get_gemini_feedback en utils/gemini_utils.py\n+# REQUIERE que add_solved_exercise en mongodb_client.py funcione correctamente.\n+@router.post(\n+    \"/submit_answer\",\n+    # Asumiendo que models/logic.py tiene un modelo FeedbackResponse\n+    # con al menos 'analysis' (str) y 'grade' (int o float).\n+    # Ejemplo: class FeedbackResponse(BaseModel): analysis: str; grade: int\n+    response_model=FeedbackResponse,\n+    summary=\"Recibe respuesta, evalúa con IA y guarda el resultado\",\n+)\n+async def submit_user_answer(\n+    # current_user es el documento del usuario logeado, ya obtenido por Depends\n+    current_db_user: Annotated[dict, Depends(get_current_user)],\n+    problem_id: Annotated[str, Form(...)], # Recibe el ID del problema (como string) del frontend (Form data)\n+    user_answer: Annotated[str, Form(...)] # Recibe el texto de la respuesta (como string) del frontend (Form data)\n+):\n+    if mongo_client is None:\n+         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n+\n+    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n+    if not user_id or not isinstance(user_id, ObjectId):\n+         # Esto no debería pasar con un Depends válido, pero es una seguridad\n+         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n+         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n+\n+    # 1. Validar y convertir el ID del problema recibido\n+    try:\n+        # problem_id llega como string del frontend (Form data)\n+        problem_id_obj = ObjectId(problem_id) # Convertir el string ID a ObjectId\n+    except Exception:\n+        # Si la conversión falla, el ID recibido no es válido\n+        logger.warning(f\"ID de problema inválido recibido de {user_email}: '{problem_id}'\")\n+        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"ID de problema inválido.\")\n+\n+    logger.info(f\"Usuario '{user_email}' (ID: {user_id}) envió respuesta para problema '{problem_id_obj}'.\")\n+    logger.debug(f\"Respuesta recibida: '{user_answer}'\")\n+\n+    # 2. Obtener el problema original de la DB (necesario para el prompt del LLM)\n+    # Asumiendo que tienes un método get_problem_by_id(problem_id_obj) en mongo_client\n+    try:\n+        # Si get_problem_by_id es síncrono (PyMongo), usa asyncio.to_thread\n+        # Si es async (Motor), quita await asyncio.to_thread\n+        problem_data = await asyncio.to_thread(mongo_client.get_problem_by_id, problem_id_obj)\n+        # Si no tienes get_problem_by_id, puedes intentar obtenerlo de la misma agregación que en get_random_unsolved_problem,\n+        # pero get_problem_by_id es más limpio. Implementa get_problem_by_id en mongo_client si no existe.\n+    except Exception as db_error:\n+        logger.error(f\"Error DB al obtener problema {problem_id_obj} para {user_email}: {db_error}\", exc_info=True)\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al validar el problema.\")\n+\n+    if not problem_data:\n+        logger.warning(f\"Problema {problem_id_obj} no encontrado en DB para respuesta de {user_email}.\")\n+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"El problema especificado no fue encontrado.\")\n+\n+    # 3. --- PREPARAR PROMPT PARA LLM ---\n+    # Aquí es donde construirías el prompt para el LLM, incluyendo:\n+    # - Contexto general del proyecto (aplicación educativa, para usuarios ciegos, etc.)\n+    # - Progreso del usuario (opcional, pero útil para contexto del LLM)\n+    # - El problema original (problem_data['text'])\n+    # - La respuesta del usuario (user_answer)\n+    # - Instrucciones claras para el LLM (analizar lógica, no código, calificar 1-5, formato JSON).\n+\n+    # Para obtener el progreso del usuario *actualizado* para el prompt,\n+    # podrías volver a calcularlo o obtener el documento completo de usuario.\n+    # El current_db_user ya trae el array 'ejercicios'.\n+    # Puedes reutilizar la lógica de cálculo de progreso de get_user_progress aquí.\n+\n+    user_solved_exercises = current_db_user.get(\"ejercicios\", []) # Array de ejercicios resueltos\n+    # Calcula el progreso actual (total, por dificultad, promedios) a partir de user_solved_exercises\n+\n+    # --- Simulación de cálculo de progreso para el prompt ---\n+    # NOTA: Reemplaza esto con la lógica real de cálculo de progreso si la necesitas en el prompt.\n+    total_solved_count = len(user_solved_exercises)\n+    # Aquí iría la lógica para calcular promedios y conteos por dificultad si los incluyes en el prompt.\n+    # --- Fin Simulación ---\n+\n+\n+    # --- Construir el prompt ---\n+    # Este prompt es CRUCIAL para guiar al LLM. Adapta el texto según el modelo LLM que uses.\n+    llm_prompt_parts = [\n+        \"SYSTEM: You are a programming logic tutor, friendly and helpful, specialized in assisting blind users learning to program. Your feedback should focus on the logical steps, problem-solving approach, correctness, and efficiency, not specific code syntax. Provide a clear analysis and assign a grade.\",\n+        \"CONTEXT: This is an educational web application for blind individuals. Interaction is primarily through voice. Your response will be read aloud by a screen reader.\",\n+        f\"USER_PROGRESS_SUMMARY: This user has solved {total_solved_count} exercises so far.\", # Puedes añadir más detalles aquí si los calculaste\n+        f\"PROGRAMMING_LOGIC_PROBLEM: {problem_data['text']}\", # El enunciado original del problema\n+        f\"USER_SUBMITTED_SOLUTION_LOGIC: {user_answer}\", # La respuesta transcrita del usuario\n+        \"INSTRUCTIONS: Based on the PROGRAMMING_LOGIC_PROBLEM and the USER_SUBMITTED_SOLUTION_LOGIC:\",\n+        \"- Analyze the user's proposed logic and thought process. Is it a valid approach to solve the problem?\",\n+        \"- Comment on its correctness, clarity, and potential efficiency. Discuss edge cases if relevant to the problem.\",\n+        \"- Do NOT provide code snippets or specific code syntax in your analysis.\",\n+        \"- Provide detailed feedback (aim for 50-200 words, keep it concise but informative for voice).\",\n+        \"- Assign a grade for the solution's logic on a scale of 0 to 10, where 0 is completely incorrect/no attempt, and 10 is excellent.\",\n+        \"- Respond ONLY in JSON format with the keys 'analysis' (string) and 'grade' (integer 0-10). Ensure the JSON is valid.\",\n+        \"EXAMPLE_JSON_RESPONSE: {\\\"analysis\\\": \\\"Your approach is logical and correct...\\\", \\\"grade\\\": 8}\"\n+    ]\n+    llm_prompt = \"\\n\".join(llm_prompt_parts)\n+\n+    # 4. --- LLAMADA AL LLM ---\n+    llm_analysis = \"Análisis no disponible (servicio de IA no configurado o falló).\"\n+    llm_grade = 0 # Grado por defecto si falla el LLM\n+\n+    if GEMINI_AVAILABLE:\n+        logger.info(f\"Llamando a Gemini para evaluar respuesta del problema {problem_id_obj} para user {user_email}...\")\n+        try:\n+            # La función get_gemini_feedback debe estar implementada en utils/gemini_utils.py\n+            # y ser ASYNC (def async) para usar await aquí.\n+            # Si es SÍNCRONA, usa: feedback_result = await asyncio.to_thread(get_gemini_feedback, ...)\n+            feedback_result = await get_gemini_feedback(problem_data['text'], user_answer, user_progress_summary=llm_prompt_parts[2]) # Pasar el prompt completo o solo la parte del progreso si la función lo acepta\n+\n+\n+            if feedback_result and isinstance(feedback_result, dict): # Verificar que sea un diccionario\n+                llm_analysis = feedback_result.get(\"analysis\", \"Error al extraer análisis del resultado de IA.\")\n+                try:\n+                     # Intentar convertir la calificación a entero, manejando posibles errores\n+                     llm_grade = int(feedback_result.get(\"grade\", 0))\n+                     # Asegurar que la calificación esté en el rango esperado (ej. 0-10)\n+                     llm_grade = max(0, min(10, llm_grade))\n+                except (ValueError, TypeError):\n+                     logger.error(f\"Nota inválida recibida de Gemini para {user_email} ({problem_id_obj}): '{feedback_result.get('grade')}'. Usando 0.\")\n+                     llm_grade = 0\n+                logger.info(f\"Evaluación de Gemini recibida para {user_email}: Calificación={llm_grade}\")\n+            else:\n+                logger.error(f\"La llamada a Gemini no devolvió un diccionario o falló para {user_email} ({problem_id_obj}). Resultado: {feedback_result}\")\n+                llm_analysis = \"La evaluación automática falló. Intenta de nuevo más tarde.\" # Mensaje amigable si el LLM falla\n+                llm_grade = 0 # Calificación por defecto si falla el LLM\n+        except Exception as llm_error:\n+            # Capturar errores durante la llamada o procesamiento de la respuesta de Gemini\n+            logger.error(f\"Error inesperado durante la llamada o procesamiento de Gemini para {user_email} ({problem_id_obj}): {llm_error}\", exc_info=True)\n+            llm_analysis = \"Error interno al procesar la evaluación automática. Intenta de nuevo.\" # Mensaje amigable si el LLM falla\n+            llm_grade = 0 # Calificación por defecto si falla el LLM\n+    else:\n+        # Lógica placeholder si Gemini no está disponible (definida arriba en el try/except de importación)\n+        # get_gemini_feedback ya es la función placeholder si la importación falla\n+        logger.warning(\"Usando evaluación placeholder porque Gemini no está disponible.\")\n+        # Llamamos al placeholder para generar un resultado simulado\n+        simulated_feedback = await get_gemini_feedback(problem_data['text'], user_answer)\n+        llm_analysis = simulated_feedback[\"analysis\"]\n+        llm_grade = simulated_feedback[\"grade\"]\n+\n+\n+    # 5. --- GUARDAR RESULTADO EN DB ---\n+    # Preparamos los datos para guardar en el array 'ejercicios' del usuario\n+    submission_data = {\n+        \"problem_id\": problem_id_obj, # ID del problema (ObjectId)\n+        \"problem_difficulty\": problem_data.get(\"difficulty\", \"desconocida\"), # Dificultad del problema original\n+        \"user_answer\": user_answer, # La respuesta del usuario (texto)\n+        \"analysis_received\": llm_analysis, # El análisis del LLM\n+        \"llm_grade\": llm_grade, # La calificación del LLM (0-10)\n+        \"submission_timestamp\": datetime.utcnow() # Timestamp de la sumisión\n+    }\n+\n+    save_error = False\n+    try:\n+        # Llamar al método add_solved_exercise de MongoDBClient para guardar\n+        # Asumiendo que add_solved_exercise es síncrono (PyMongo), usar asyncio.to_thread\n+        # Si es async (Motor), quitar await asyncio.to_thread\n+        update_result = await asyncio.to_thread(mongo_client.add_solved_exercise, user_id, submission_data)\n+\n+        # Verificar el resultado de la operación de guardado (opcional pero recomendado)\n+        # add_solved_exercise debería devolver UpdateResult si usa update_one\n+        if update_result is None:\n+            save_error = True\n+            logger.error(f\"La función add_solved_exercise devolvió None para user {user_id}. No se pudo guardar.\")\n+        elif hasattr(update_result, 'matched_count') and hasattr(update_result, 'modified_count'):\n+             if update_result.matched_count == 0:\n+                  save_error = True\n+                  logger.error(f\"No se encontró el usuario {user_id} para añadir el ejercicio resuelto (update_one matched_count=0).\")\n+             elif update_result.modified_count == 0:\n+                  # Esto puede pasar si el documento ya estaba en el array por alguna razón\n+                  logger.warning(f\"No se modificó el usuario {user_id} al añadir ejercicio (modified_count=0).\")\n+             else:\n+                  logger.info(f\"Ejercicio resuelto añadido correctamente al historial del usuario {user_id}\")\n+        else:\n+             # Si devolvió algo inesperado\n+             save_error = True\n+             logger.error(f\"Valor de retorno inesperado de add_solved_exercise para user {user_id}: {type(update_result)}\")\n+\n+\n+    except Exception as e:\n+        # Capturar errores durante la operación de guardado\n+        logger.error(f\"Error al intentar guardar el ejercicio resuelto para user {user_id} ({problem_id_obj}): {e}\", exc_info=True)\n+        save_error = True\n+        # No lanzamos excepción aquí para que el frontend reciba el feedback del LLM aunque no se haya guardado.\n+        # Puedes decidir lanzar una excepción si el guardado es crítico.\n+\n+\n+    logger.info(f\"Evaluación final para {user_email} (problema {problem_id_obj}): Calificación={llm_grade} (Guardado: {'No' if save_error else 'Sí'})\")\n+\n+    # 6. Devolver el feedback al frontend\n+    # Retornar FeedbackResponse(analysis=..., grade=...)\n+    return FeedbackResponse(analysis=llm_analysis, grade=llm_grade)\n+\n+# Asegúrate de que tu modelo FeedbackResponse esté definido en models/logic.py\n+# Ejemplo:\n+# from pydantic import BaseModel\n+# class FeedbackResponse(BaseModel):\n+#     analysis: str\n+#     grade: int # O float si tu LLM devuelve float\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746310107337,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n     mongo_client = None # Set a None si falla para verificar en endpoints\n \n # Instancia del cliente Google Cloud Text-to-Speech (asumiendo que ya la tienes e inicializaste)\n # Debe estar definida globalmente en este archivo si la usas en /tts\n-try: tts_client = texttospeech.TextToSpeechClient() \n+try: tts_client = texttospeech.TextToSpeechClient(credentials=\"/home/alessandro_hp/Documentos/Cursor/DAW_PROYECTO/daw_backend/scripts/daw-proyecto-458721-accdda2dde3a.json\") \n except Exception: tts_client = None\n # Asegúrate de que el endpoint /tts está definido si lo usas.\n \n \n@@ -405,416 +405,5 @@\n # Ejemplo:\n # from pydantic import BaseModel\n # class FeedbackResponse(BaseModel):\n #     analysis: str\n-#     grade: int # O float si tu LLM devuelve float\n-# routers/logic.py\n-\n-from fastapi import APIRouter, Depends, HTTPException, status, Query, Form # Importa Form si esperas datos de formulario\n-from fastapi.responses import Response\n-from bson import ObjectId\n-from typing import Optional, Dict, List, Union, Annotated # Importa Annotated\n-from datetime import datetime # Para el timestamp\n-import logging\n-import asyncio # Necesario para asyncio.to_thread para llamadas síncronas a DB\n-\n-# Importa cliente Google Cloud Text-to-Speech si lo usas (ya debe estar)\n-from google.cloud import texttospeech\n-\n-# Importa tu cliente de MongoDB\n-from mongodb_client import MongoDBClient\n-\n-# Importa tu dependencia de autenticación\n-from utils.auth_utils import get_current_user\n-\n-# Importa los modelos/schemas Pydantic\n-# Necesitas el modelo FeedbackResponse para la respuesta\n-from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse, TTSTextRequest # Asegúrate de que FeedbackResponse esté en models.logic\n-# Si no tienes FeedbackResponse, defínelo en models/logic.py:\n-# class FeedbackResponse(BaseModel):\n-#    analysis: str\n-#    grade: int # O float, según lo que devuelva tu LLM\n-\n-import logging\n-\n-logger = logging.getLogger(__name__)\n-logging.basicConfig(level=logging.INFO)\n-\n-# --- Configuración para el LLM (Gemini) ---\n-# Necesitas una función que llame a la API de Gemini.\n-# Supondremos que tienes un archivo como utils/gemini_utils.py\n-# con una función get_gemini_feedback(problem_text: str, user_answer: str) -> Dict[str, Any] (o None si falla).\n-# Esta función debería llamar a la API de Gemini con un prompt adecuado.\n-try:\n-    # ASEGÚRATE de que la ruta de importación sea correcta para tu proyecto\n-    # y que el archivo utils/gemini_utils.py exista y tenga la función get_gemini_feedback\n-    from utils.gemini_utils import get_gemini_feedback\n-    GEMINI_AVAILABLE = True\n-    logger.info(\"Módulo gemini_utils importado correctamente.\")\n-except ImportError:\n-    logger.warning(\"Módulo gemini_utils no encontrado o get_gemini_feedback no definido. La evaluación usará placeholders.\")\n-    GEMINI_AVAILABLE = False\n-    # Definir una función placeholder async si no existe la real, para evitar errores\n-    async def get_gemini_feedback(problem_text: str, user_answer: str):\n-        logger.warning(\"Usando placeholder get_gemini_feedback.\")\n-        # Simulación de respuesta de Gemini (debe coincidir con el formato esperado)\n-        simulated_analysis = f\"Análisis simulado para '{user_answer[:50]}...'. Parece una respuesta con longitud {len(user_answer)}. (Evaluación Simulada)\"\n-        simulated_grade = max(0, min(10, len(user_answer) // 5)) # Simulación simple de nota 0-10\n-        # Simular algo de latencia\n-        await asyncio.sleep(1)\n-        return {\"analysis\": simulated_analysis, \"grade\": simulated_grade}\n-\n-\n-logger = logging.getLogger(__name__)\n-\n-router = APIRouter(\n-    prefix=\"/logic\", # Prefijo /logic para este router\n-    tags=[\"Logic Problems\"],\n-    # dependencies=[Depends(get_current_user)] # Opcional: Proteger todo el router\n-)\n-\n-# Instancia del Cliente MongoDB (asumiendo que ya la tienes)\n-try:\n-    mongo_client = MongoDBClient()\n-    logger.info(\"MongoDBClient instanciado en routers/logic.py\")\n-except Exception as e:\n-    logger.error(f\"Error al instanciar MongoDBClient en routers/logic.py: {e}\")\n-    mongo_client = None # Set a None si falla para verificar en endpoints\n-\n-# Instancia del cliente Google Cloud Text-to-Speech (asumiendo que ya la tienes e inicializaste)\n-# Debe estar definida globalmente en este archivo si la usas en /tts\n-try: tts_client = texttospeech.TextToSpeechClient() \n-except Exception: tts_client = None\n-# Asegúrate de que el endpoint /tts está definido si lo usas.\n-\n-\n-# --- Endpoint de Progreso ---\n-@router.get(\n-    \"/progress\",\n-    response_model=UserProgressResponse,\n-    summary=\"Obtiene el progreso del usuario autenticado\"\n-)\n-async def get_user_progress(\n-    # current_user ya es el diccionario del usuario de la DB\n-    current_db_user: Annotated[dict, Depends(get_current_user)]\n-):\n-    if mongo_client is None:\n-         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n-\n-    # Ya tenemos el documento del usuario gracias a Depends(get_current_user)\n-    # No necesitamos obtenerlo de nuevo por ID a menos que necesitemos una versión más reciente (poco probable aquí)\n-    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n-\n-    if not user_id or not isinstance(user_id, ObjectId):\n-         # Esto no debería pasar si get_current_user funciona bien, pero es una seguridad.\n-         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n-         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n-\n-    logger.info(f\"Solicitud de progreso para usuario: {user_email} (ID: {user_id})\")\n-\n-    # El array de ejercicios resueltos está directamente en el documento del usuario\n-    solved_exercises = current_db_user.get(\"ejercicios\", []) # Acceder directamente al array del documento proporcionado por el Depends\n-\n-    # Lógica de Cálculo (sin cambios)...\n-    progress_counts: Dict[str, int] = {\"basico\": 0, \"intermedio\": 0, \"avanzado\": 0}\n-    progress_sums: Dict[str, float] = {\"basico\": 0.0, \"intermedio\": 0.0, \"avanzado\": 0.0}\n-    total_solved_count = 0; total_grade_sum = 0.0\n-    for exercise in solved_exercises:\n-        if isinstance(exercise, dict) and exercise.get(\"problem_difficulty\") in progress_counts and isinstance(exercise.get(\"llm_grade\"), (int, float)):\n-            difficulty = exercise[\"problem_difficulty\"]; grade = exercise[\"llm_grade\"]\n-            total_solved_count += 1; total_grade_sum += grade\n-            progress_counts[difficulty] += 1; progress_sums[difficulty] += grade\n-        else: logger.warning(f\"Ejercicio formato inválido user_id {user_id}: {exercise}\")\n-    progress_by_difficulty: Dict[str, DifficultyProgress] = {}\n-    for dl in [\"basico\", \"intermedio\", \"avanzado\"]:\n-        count = progress_counts[dl]; grade_sum = progress_sums[dl]\n-        avg_grade = round(grade_sum / count, 2) if count > 0 else 0.0\n-        progress_by_difficulty[dl] = DifficultyProgress(solved_count=count, average_grade=avg_grade)\n-    overall_avg = round(total_grade_sum / total_solved_count, 2) if total_solved_count > 0 else 0.0\n-    logger.info(f\"Progreso calculado para {user_email}: Total={total_solved_count}, Avg={overall_avg}\")\n-    return UserProgressResponse(total_solved=total_solved_count, progress_by_difficulty=progress_by_difficulty, overall_average_grade=overall_avg, message=\"Tu progreso ha sido cargado.\")\n-\n-\n-# --- Endpoint para Obtener Problema ---\n-@router.get(\n-    \"/problem\",\n-    response_model=Union[ProblemResponse, NoProblemResponse],\n-    summary=\"Obtiene un problema de lógica no resuelto\"\n-)\n-async def get_logic_problem(\n-    current_db_user: Annotated[dict, Depends(get_current_user)],\n-    difficulty: Annotated[str | None, Query(description=\"Filtrar por dificultad\")] = None\n-):\n-    if mongo_client is None: raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio DB no disponible.\")\n-    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n-    if not user_id or not isinstance(user_id, ObjectId): raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"ID usuario inválido.\")\n-    if difficulty is not None and difficulty not in [\"basico\", \"intermedio\", \"avanzado\"]: raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Dificultad inválida.\")\n-    logger.info(f\"Buscando problema user_id: {user_id}, dificultad: {difficulty or 'cualquiera'}\")\n-\n-    try:\n-        # Asegúrate de que get_random_unsolved_problem es síncrono o usa async db driver (Motor)\n-        # Si es síncrono (PyMongo), usa asyncio.to_thread\n-        problem_dict = await asyncio.to_thread(mongo_client.get_random_unsolved_problem, user_id, difficulty=difficulty)\n-\n-    except Exception as db_error:\n-        logger.error(f\"Error DB consulta problemas user {user_id}: {db_error}\", exc_info=True)\n-        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error DB consulta problemas.\")\n-\n-    if problem_dict:\n-        logger.info(f\"Problema encontrado {user_email}: ID={problem_dict.get('_id')}\")\n-        try:\n-             # Crear instancia Pydantic explícitamente para validación y serialización\n-             validated_problem = ProblemResponse(id=str(problem_dict[\"_id\"]), text=problem_dict[\"text\"], difficulty=problem_dict[\"difficulty\"], topics=problem_dict.get(\"topics\", []))\n-             return validated_problem\n-        except Exception as e:\n-             logger.error(f\"Error procesando datos problema {problem_dict.get('_id')} para {user_email}: {e}\", exc_info=True)\n-             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error procesando datos problema.\")\n-    else:\n-        logger.info(f\"No se encontraron problemas {user_email}, dificultad: {difficulty or 'cualquiera'}\")\n-        message = f\"¡Felicidades! Has resuelto todos los problemas de nivel '{difficulty}'.\" if difficulty else \"¡Felicidades! Has resuelto todos los problemas.\"\n-        return NoProblemResponse(message=message)\n-\n-\n-# --- Endpoint POST /tts (si usas Google Cloud TTS) ---\n-# ASEGÚRATE de que el cliente tts_client esté inicializado globalmente arriba\n-# ASEGÚRATE de tener instalada la librería google-cloud-texttospeech\n-@router.post(\"/tts\")\n-async def text_to_speech(\n-    # --- CAMBIO AQUÍ ---\n-    # Ahora FastAPI espera un cuerpo JSON que coincida con el modelo TTSTextRequest\n-    request_data: TTSTextRequest, # <-- Usamos el modelo Pydantic para el cuerpo\n-    # --- FIN CAMBIO ---\n-    current_user: Annotated[dict, Depends(get_current_user)] # Proteger el endpoint\n-):\n-    if not tts_client:\n-        logger.error(\"Intento de usar TTS, pero cliente no inicializado.\")\n-        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Servicio de voz no disponible en el servidor.\")\n-\n-    # Obtener el texto del objeto recibido del frontend\n-    text = request_data.text # <-- Acceder al texto desde el objeto request_data\n-\n-    if not text: # Esta verificación aún es útil si el modelo permitiera texto vacío, pero el modelo BaseModel no lo permite por defecto\n-        logger.warning(f\"Solicitud /tts con texto vacío de usuario {current_user.get('email', 'N/A')}\")\n-        # FastAPI ya manejaría esto con 422 si el modelo requiriera texto no vacío, pero la dejamos por claridad.\n-        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"No se proporcionó texto para convertir a voz.\")\n-\n-    user_email = current_user.get(\"email\", \"N/A\")\n-    logger.info(f\"Generando voz para usuario {user_email}: '{text[:50]}...'\")\n-\n-    try:\n-        # ... (resto del código para llamar a synthesize_speech con el 'text' obtenido) ...\n-        synthesis_input = texttospeech.SynthesisInput(text=text)\n-        voice = texttospeech.VoiceSelectionParams(language_code=\"es-MX\", ssml_gender=texttospeech.SsmlVoiceGender.FEMALE) # Configurar voz estándar\n-        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3) # Configurar audio MP3\n-\n-        response = tts_client.synthesize_speech(\n-            input=synthesis_input,\n-            voice=voice,\n-            audio_config=audio_config\n-        )\n-\n-        logger.info(f\"Voz generada exitosamente para {user_email} ({len(response.audio_content)} bytes).\")\n-        return Response(content=response.audio_content, media_type=\"audio/mpeg\")\n-\n-    except Exception as e:\n-        logger.error(f\"Error durante la síntesis de voz con Google Cloud TTS para {user_email}: {str(e)}\", exc_info=True)\n-        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Error al generar voz en el servidor: {str(e)}\")\n-\n-\n-# --- Endpoint para Enviar Respuesta (CONEXIÓN CON LLM Y SAVE RESULT) ---\n-# Este endpoint recibe el texto de la respuesta, la evalúa y la guarda.\n-# REQUIERE que tengas implementada la función get_gemini_feedback en utils/gemini_utils.py\n-# REQUIERE que add_solved_exercise en mongodb_client.py funcione correctamente.\n-@router.post(\n-    \"/submit_answer\",\n-    # Asumiendo que models/logic.py tiene un modelo FeedbackResponse\n-    # con al menos 'analysis' (str) y 'grade' (int o float).\n-    # Ejemplo: class FeedbackResponse(BaseModel): analysis: str; grade: int\n-    response_model=FeedbackResponse,\n-    summary=\"Recibe respuesta, evalúa con IA y guarda el resultado\",\n-)\n-async def submit_user_answer(\n-    # current_user es el documento del usuario logeado, ya obtenido por Depends\n-    current_db_user: Annotated[dict, Depends(get_current_user)],\n-    problem_id: Annotated[str, Form(...)], # Recibe el ID del problema (como string) del frontend (Form data)\n-    user_answer: Annotated[str, Form(...)] # Recibe el texto de la respuesta (como string) del frontend (Form data)\n-):\n-    if mongo_client is None:\n-         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n-\n-    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n-    if not user_id or not isinstance(user_id, ObjectId):\n-         # Esto no debería pasar con un Depends válido, pero es una seguridad\n-         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n-         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n-\n-    # 1. Validar y convertir el ID del problema recibido\n-    try:\n-        # problem_id llega como string del frontend (Form data)\n-        problem_id_obj = ObjectId(problem_id) # Convertir el string ID a ObjectId\n-    except Exception:\n-        # Si la conversión falla, el ID recibido no es válido\n-        logger.warning(f\"ID de problema inválido recibido de {user_email}: '{problem_id}'\")\n-        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"ID de problema inválido.\")\n-\n-    logger.info(f\"Usuario '{user_email}' (ID: {user_id}) envió respuesta para problema '{problem_id_obj}'.\")\n-    logger.debug(f\"Respuesta recibida: '{user_answer}'\")\n-\n-    # 2. Obtener el problema original de la DB (necesario para el prompt del LLM)\n-    # Asumiendo que tienes un método get_problem_by_id(problem_id_obj) en mongo_client\n-    try:\n-        # Si get_problem_by_id es síncrono (PyMongo), usa asyncio.to_thread\n-        # Si es async (Motor), quita await asyncio.to_thread\n-        problem_data = await asyncio.to_thread(mongo_client.get_problem_by_id, problem_id_obj)\n-        # Si no tienes get_problem_by_id, puedes intentar obtenerlo de la misma agregación que en get_random_unsolved_problem,\n-        # pero get_problem_by_id es más limpio. Implementa get_problem_by_id en mongo_client si no existe.\n-    except Exception as db_error:\n-        logger.error(f\"Error DB al obtener problema {problem_id_obj} para {user_email}: {db_error}\", exc_info=True)\n-        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al validar el problema.\")\n-\n-    if not problem_data:\n-        logger.warning(f\"Problema {problem_id_obj} no encontrado en DB para respuesta de {user_email}.\")\n-        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"El problema especificado no fue encontrado.\")\n-\n-    # 3. --- PREPARAR PROMPT PARA LLM ---\n-    # Aquí es donde construirías el prompt para el LLM, incluyendo:\n-    # - Contexto general del proyecto (aplicación educativa, para usuarios ciegos, etc.)\n-    # - Progreso del usuario (opcional, pero útil para contexto del LLM)\n-    # - El problema original (problem_data['text'])\n-    # - La respuesta del usuario (user_answer)\n-    # - Instrucciones claras para el LLM (analizar lógica, no código, calificar 1-5, formato JSON).\n-\n-    # Para obtener el progreso del usuario *actualizado* para el prompt,\n-    # podrías volver a calcularlo o obtener el documento completo de usuario.\n-    # El current_db_user ya trae el array 'ejercicios'.\n-    # Puedes reutilizar la lógica de cálculo de progreso de get_user_progress aquí.\n-\n-    user_solved_exercises = current_db_user.get(\"ejercicios\", []) # Array de ejercicios resueltos\n-    # Calcula el progreso actual (total, por dificultad, promedios) a partir de user_solved_exercises\n-\n-    # --- Simulación de cálculo de progreso para el prompt ---\n-    # NOTA: Reemplaza esto con la lógica real de cálculo de progreso si la necesitas en el prompt.\n-    total_solved_count = len(user_solved_exercises)\n-    # Aquí iría la lógica para calcular promedios y conteos por dificultad si los incluyes en el prompt.\n-    # --- Fin Simulación ---\n-\n-\n-    # --- Construir el prompt ---\n-    # Este prompt es CRUCIAL para guiar al LLM. Adapta el texto según el modelo LLM que uses.\n-    llm_prompt_parts = [\n-        \"SYSTEM: You are a programming logic tutor, friendly and helpful, specialized in assisting blind users learning to program. Your feedback should focus on the logical steps, problem-solving approach, correctness, and efficiency, not specific code syntax. Provide a clear analysis and assign a grade.\",\n-        \"CONTEXT: This is an educational web application for blind individuals. Interaction is primarily through voice. Your response will be read aloud by a screen reader.\",\n-        f\"USER_PROGRESS_SUMMARY: This user has solved {total_solved_count} exercises so far.\", # Puedes añadir más detalles aquí si los calculaste\n-        f\"PROGRAMMING_LOGIC_PROBLEM: {problem_data['text']}\", # El enunciado original del problema\n-        f\"USER_SUBMITTED_SOLUTION_LOGIC: {user_answer}\", # La respuesta transcrita del usuario\n-        \"INSTRUCTIONS: Based on the PROGRAMMING_LOGIC_PROBLEM and the USER_SUBMITTED_SOLUTION_LOGIC:\",\n-        \"- Analyze the user's proposed logic and thought process. Is it a valid approach to solve the problem?\",\n-        \"- Comment on its correctness, clarity, and potential efficiency. Discuss edge cases if relevant to the problem.\",\n-        \"- Do NOT provide code snippets or specific code syntax in your analysis.\",\n-        \"- Provide detailed feedback (aim for 50-200 words, keep it concise but informative for voice).\",\n-        \"- Assign a grade for the solution's logic on a scale of 0 to 10, where 0 is completely incorrect/no attempt, and 10 is excellent.\",\n-        \"- Respond ONLY in JSON format with the keys 'analysis' (string) and 'grade' (integer 0-10). Ensure the JSON is valid.\",\n-        \"EXAMPLE_JSON_RESPONSE: {\\\"analysis\\\": \\\"Your approach is logical and correct...\\\", \\\"grade\\\": 8}\"\n-    ]\n-    llm_prompt = \"\\n\".join(llm_prompt_parts)\n-\n-    # 4. --- LLAMADA AL LLM ---\n-    llm_analysis = \"Análisis no disponible (servicio de IA no configurado o falló).\"\n-    llm_grade = 0 # Grado por defecto si falla el LLM\n-\n-    if GEMINI_AVAILABLE:\n-        logger.info(f\"Llamando a Gemini para evaluar respuesta del problema {problem_id_obj} para user {user_email}...\")\n-        try:\n-            # La función get_gemini_feedback debe estar implementada en utils/gemini_utils.py\n-            # y ser ASYNC (def async) para usar await aquí.\n-            # Si es SÍNCRONA, usa: feedback_result = await asyncio.to_thread(get_gemini_feedback, ...)\n-            feedback_result = await get_gemini_feedback(problem_data['text'], user_answer, user_progress_summary=llm_prompt_parts[2]) # Pasar el prompt completo o solo la parte del progreso si la función lo acepta\n-\n-\n-            if feedback_result and isinstance(feedback_result, dict): # Verificar que sea un diccionario\n-                llm_analysis = feedback_result.get(\"analysis\", \"Error al extraer análisis del resultado de IA.\")\n-                try:\n-                     # Intentar convertir la calificación a entero, manejando posibles errores\n-                     llm_grade = int(feedback_result.get(\"grade\", 0))\n-                     # Asegurar que la calificación esté en el rango esperado (ej. 0-10)\n-                     llm_grade = max(0, min(10, llm_grade))\n-                except (ValueError, TypeError):\n-                     logger.error(f\"Nota inválida recibida de Gemini para {user_email} ({problem_id_obj}): '{feedback_result.get('grade')}'. Usando 0.\")\n-                     llm_grade = 0\n-                logger.info(f\"Evaluación de Gemini recibida para {user_email}: Calificación={llm_grade}\")\n-            else:\n-                logger.error(f\"La llamada a Gemini no devolvió un diccionario o falló para {user_email} ({problem_id_obj}). Resultado: {feedback_result}\")\n-                llm_analysis = \"La evaluación automática falló. Intenta de nuevo más tarde.\" # Mensaje amigable si el LLM falla\n-                llm_grade = 0 # Calificación por defecto si falla el LLM\n-        except Exception as llm_error:\n-            # Capturar errores durante la llamada o procesamiento de la respuesta de Gemini\n-            logger.error(f\"Error inesperado durante la llamada o procesamiento de Gemini para {user_email} ({problem_id_obj}): {llm_error}\", exc_info=True)\n-            llm_analysis = \"Error interno al procesar la evaluación automática. Intenta de nuevo.\" # Mensaje amigable si el LLM falla\n-            llm_grade = 0 # Calificación por defecto si falla el LLM\n-    else:\n-        # Lógica placeholder si Gemini no está disponible (definida arriba en el try/except de importación)\n-        # get_gemini_feedback ya es la función placeholder si la importación falla\n-        logger.warning(\"Usando evaluación placeholder porque Gemini no está disponible.\")\n-        # Llamamos al placeholder para generar un resultado simulado\n-        simulated_feedback = await get_gemini_feedback(problem_data['text'], user_answer)\n-        llm_analysis = simulated_feedback[\"analysis\"]\n-        llm_grade = simulated_feedback[\"grade\"]\n-\n-\n-    # 5. --- GUARDAR RESULTADO EN DB ---\n-    # Preparamos los datos para guardar en el array 'ejercicios' del usuario\n-    submission_data = {\n-        \"problem_id\": problem_id_obj, # ID del problema (ObjectId)\n-        \"problem_difficulty\": problem_data.get(\"difficulty\", \"desconocida\"), # Dificultad del problema original\n-        \"user_answer\": user_answer, # La respuesta del usuario (texto)\n-        \"analysis_received\": llm_analysis, # El análisis del LLM\n-        \"llm_grade\": llm_grade, # La calificación del LLM (0-10)\n-        \"submission_timestamp\": datetime.utcnow() # Timestamp de la sumisión\n-    }\n-\n-    save_error = False\n-    try:\n-        # Llamar al método add_solved_exercise de MongoDBClient para guardar\n-        # Asumiendo que add_solved_exercise es síncrono (PyMongo), usar asyncio.to_thread\n-        # Si es async (Motor), quitar await asyncio.to_thread\n-        update_result = await asyncio.to_thread(mongo_client.add_solved_exercise, user_id, submission_data)\n-\n-        # Verificar el resultado de la operación de guardado (opcional pero recomendado)\n-        # add_solved_exercise debería devolver UpdateResult si usa update_one\n-        if update_result is None:\n-            save_error = True\n-            logger.error(f\"La función add_solved_exercise devolvió None para user {user_id}. No se pudo guardar.\")\n-        elif hasattr(update_result, 'matched_count') and hasattr(update_result, 'modified_count'):\n-             if update_result.matched_count == 0:\n-                  save_error = True\n-                  logger.error(f\"No se encontró el usuario {user_id} para añadir el ejercicio resuelto (update_one matched_count=0).\")\n-             elif update_result.modified_count == 0:\n-                  # Esto puede pasar si el documento ya estaba en el array por alguna razón\n-                  logger.warning(f\"No se modificó el usuario {user_id} al añadir ejercicio (modified_count=0).\")\n-             else:\n-                  logger.info(f\"Ejercicio resuelto añadido correctamente al historial del usuario {user_id}\")\n-        else:\n-             # Si devolvió algo inesperado\n-             save_error = True\n-             logger.error(f\"Valor de retorno inesperado de add_solved_exercise para user {user_id}: {type(update_result)}\")\n-\n-\n-    except Exception as e:\n-        # Capturar errores durante la operación de guardado\n-        logger.error(f\"Error al intentar guardar el ejercicio resuelto para user {user_id} ({problem_id_obj}): {e}\", exc_info=True)\n-        save_error = True\n-        # No lanzamos excepción aquí para que el frontend reciba el feedback del LLM aunque no se haya guardado.\n-        # Puedes decidir lanzar una excepción si el guardado es crítico.\n-\n-\n-    logger.info(f\"Evaluación final para {user_email} (problema {problem_id_obj}): Calificación={llm_grade} (Guardado: {'No' if save_error else 'Sí'})\")\n-\n-    # 6. Devolver el feedback al frontend\n-    # Retornar FeedbackResponse(analysis=..., grade=...)\n-    return FeedbackResponse(analysis=llm_analysis, grade=llm_grade)\n-\n-# Asegúrate de que tu modelo FeedbackResponse esté definido en models/logic.py\n-# Ejemplo:\n-# from pydantic import BaseModel\n-# class FeedbackResponse(BaseModel):\n-#     analysis: str\n #     grade: int # O float si tu LLM devuelve float\n\\ No newline at end of file\n"
                },
                {
                    "date": 1746310296571,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,8 +61,9 @@\n     prefix=\"/logic\", # Prefijo /logic para este router\n     tags=[\"Logic Problems\"],\n     # dependencies=[Depends(get_current_user)] # Opcional: Proteger todo el router\n )\n+SERVICE_ACCOUNT_KEY_PATH = \"/home/alessandro_hp/Documentos/Cursor/DAW_PROYECTO/daw_backend/scripts/daw-proyecto-458721-accdda2dde3a.json\" # <-- Tu ruta exacta\n \n # Instancia del Cliente MongoDB (asumiendo que ya la tienes)\n try:\n     mongo_client = MongoDBClient()\n@@ -72,9 +73,9 @@\n     mongo_client = None # Set a None si falla para verificar en endpoints\n \n # Instancia del cliente Google Cloud Text-to-Speech (asumiendo que ya la tienes e inicializaste)\n # Debe estar definida globalmente en este archivo si la usas en /tts\n-try: tts_client = texttospeech.TextToSpeechClient(credentials=\"/home/alessandro_hp/Documentos/Cursor/DAW_PROYECTO/daw_backend/scripts/daw-proyecto-458721-accdda2dde3a.json\") \n+try: tts_client = texttospeech.TextToSpeechClient(credentials=SERVICE_ACCOUNT_KEY_PATH) \n except Exception: tts_client = None\n # Asegúrate de que el endpoint /tts está definido si lo usas.\n \n \n"
                },
                {
                    "date": 1746310362158,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,8 +23,9 @@\n # Si no tienes FeedbackResponse, defínelo en models/logic.py:\n # class FeedbackResponse(BaseModel):\n #    analysis: str\n #    grade: int # O float, según lo que devuelva tu LLM\n+from google.oauth2 import service_account # Asegúrate de que esto esté importado\n \n import logging\n \n logger = logging.getLogger(__name__)\n@@ -73,10 +74,13 @@\n     mongo_client = None # Set a None si falla para verificar en endpoints\n \n # Instancia del cliente Google Cloud Text-to-Speech (asumiendo que ya la tienes e inicializaste)\n # Debe estar definida globalmente en este archivo si la usas en /tts\n-try: tts_client = texttospeech.TextToSpeechClient(credentials=SERVICE_ACCOUNT_KEY_PATH) \n-except Exception: tts_client = None\n+try: \n+    credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_KEY_PATH)\n+    tts_client = texttospeech.TextToSpeechClient(credentials=SERVICE_ACCOUNT_KEY_PATH) \n+except Exception: \n+    tts_client = None\n # Asegúrate de que el endpoint /tts está definido si lo usas.\n \n \n # --- Endpoint de Progreso ---\n"
                },
                {
                    "date": 1746310556400,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,9 +62,8 @@\n     prefix=\"/logic\", # Prefijo /logic para este router\n     tags=[\"Logic Problems\"],\n     # dependencies=[Depends(get_current_user)] # Opcional: Proteger todo el router\n )\n-SERVICE_ACCOUNT_KEY_PATH = \"/home/alessandro_hp/Documentos/Cursor/DAW_PROYECTO/daw_backend/scripts/daw-proyecto-458721-accdda2dde3a.json\" # <-- Tu ruta exacta\n \n # Instancia del Cliente MongoDB (asumiendo que ya la tienes)\n try:\n     mongo_client = MongoDBClient()\n@@ -73,17 +72,46 @@\n     logger.error(f\"Error al instanciar MongoDBClient en routers/logic.py: {e}\")\n     mongo_client = None # Set a None si falla para verificar en endpoints\n \n # Instancia del cliente Google Cloud Text-to-Speech (asumiendo que ya la tienes e inicializaste)\n-# Debe estar definida globalmente en este archivo si la usas en /tts\n-try: \n+SERVICE_ACCOUNT_KEY_PATH = \"/home/alessandro_hp/Documentos/Cursor/DAW_PROYECTO/daw_backend/scripts/daw-proyecto-458721-accdda2dde3a.json\" # <-- Tu ruta exacta\n+\n+# Instancia del cliente Google Cloud Text-to-Speech (inicializar al inicio del módulo)\n+tts_client = None # Inicializar a None\n+# Aseguramos que la variable credentials también se inicialice a None aquí\n+credentials = None\n+try:\n+    # --- Cargar credenciales desde el archivo ---\n+    # Esto requiere que el archivo sea válido y la librería google-auth esté instalada.\n     credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_KEY_PATH)\n-    tts_client = texttospeech.TextToSpeechClient(credentials=SERVICE_ACCOUNT_KEY_PATH) \n-except Exception: \n+\n+    # --- AÑADIR ESTE LOG DESPUÉS DE CARGAR CREDENCIALES ---\n+    # Verifica si la carga devolvió el objeto esperado\n+    logger.info(f\"Credenciales cargadas desde archivo type: {type(credentials)}, value: {credentials}\")\n+    # ----------------------------------------------------\n+\n+    # --- Inicializar el cliente Google Cloud TTS usando las credenciales ---\n+    # ¡¡CORRECCIÓN!! Pasar la variable 'credentials' (el objeto), NO la ruta string.\n+    tts_client = texttospeech.TextToSpeechClient(credentials=credentials) # <-- ¡¡PASAR LA VARIABLE credentials!!\n+\n+    logger.info(f\"Cliente Google Cloud Text-to-Speech inicializado usando archivo explícito: {SERVICE_ACCOUNT_KEY_PATH}\")\n+\n+# Capturar errores específicos de archivo no encontrado primero\n+except FileNotFoundError:\n+    logger.error(f\"Error: Archivo de clave de cuenta de servicio NO ENCONTRADO en la ruta: {SERVICE_ACCOUNT_KEY_PATH}\", exc_info=True)\n     tts_client = None\n-# Asegúrate de que el endpoint /tts está definido si lo usas.\n+    credentials = None\n+except Exception as e:\n+    # Capturar cualquier otro error durante la inicialización (archivo inválido, permisos, red, etc.)\n+    logger.error(f\"Error al inicializar cliente Google Cloud TTS con archivo {SERVICE_ACCOUNT_KEY_PATH}: {str(e)}\", exc_info=True)\n+    tts_client = None\n+    credentials = None\n \n+# --- AÑADIR ESTE LOG DESPUÉS DEL BLOQUE TRY/EXCEPT (PARA VER ESTADO FINAL) ---\n+logger.info(f\"Estado final de tts_client después de la inicialización del módulo: {type(tts_client)}\")\n+# ---------------------------------------------------\n \n+\n # --- Endpoint de Progreso ---\n @router.get(\n     \"/progress\",\n     response_model=UserProgressResponse,\n"
                },
                {
                    "date": 1746310617639,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,442 @@\n+# routers/logic.py\n+\n+from fastapi import APIRouter, Depends, HTTPException, status, Query, Form # Importa Form si esperas datos de formulario\n+from fastapi.responses import Response\n+from bson import ObjectId\n+from typing import Optional, Dict, List, Union, Annotated # Importa Annotated\n+from datetime import datetime # Para el timestamp\n+import logging\n+import asyncio # Necesario para asyncio.to_thread para llamadas síncronas a DB\n+\n+# Importa cliente Google Cloud Text-to-Speech si lo usas (ya debe estar)\n+from google.cloud import texttospeech\n+\n+# Importa tu cliente de MongoDB\n+from mongodb_client import MongoDBClient\n+\n+# Importa tu dependencia de autenticación\n+from utils.auth_utils import get_current_user\n+\n+# Importa los modelos/schemas Pydantic\n+# Necesitas el modelo FeedbackResponse para la respuesta\n+from models.logic import UserProgressResponse, DifficultyProgress, ProblemResponse, NoProblemResponse, FeedbackResponse, TTSTextRequest # Asegúrate de que FeedbackResponse esté en models.logic\n+# Si no tienes FeedbackResponse, defínelo en models/logic.py:\n+# class FeedbackResponse(BaseModel):\n+#    analysis: str\n+#    grade: int # O float, según lo que devuelva tu LLM\n+from google.oauth2 import service_account # Asegúrate de que esto esté importado\n+\n+import logging\n+\n+logger = logging.getLogger(__name__)\n+logging.basicConfig(level=logging.INFO)\n+\n+# --- Configuración para el LLM (Gemini) ---\n+# Necesitas una función que llame a la API de Gemini.\n+# Supondremos que tienes un archivo como utils/gemini_utils.py\n+# con una función get_gemini_feedback(problem_text: str, user_answer: str) -> Dict[str, Any] (o None si falla).\n+# Esta función debería llamar a la API de Gemini con un prompt adecuado.\n+try:\n+    # ASEGÚRATE de que la ruta de importación sea correcta para tu proyecto\n+    # y que el archivo utils/gemini_utils.py exista y tenga la función get_gemini_feedback\n+    from utils.gemini_utils import get_gemini_feedback\n+    GEMINI_AVAILABLE = True\n+    logger.info(\"Módulo gemini_utils importado correctamente.\")\n+except ImportError:\n+    logger.warning(\"Módulo gemini_utils no encontrado o get_gemini_feedback no definido. La evaluación usará placeholders.\")\n+    GEMINI_AVAILABLE = False\n+    # Definir una función placeholder async si no existe la real, para evitar errores\n+    async def get_gemini_feedback(problem_text: str, user_answer: str):\n+        logger.warning(\"Usando placeholder get_gemini_feedback.\")\n+        # Simulación de respuesta de Gemini (debe coincidir con el formato esperado)\n+        simulated_analysis = f\"Análisis simulado para '{user_answer[:50]}...'. Parece una respuesta con longitud {len(user_answer)}. (Evaluación Simulada)\"\n+        simulated_grade = max(0, min(10, len(user_answer) // 5)) # Simulación simple de nota 0-10\n+        # Simular algo de latencia\n+        await asyncio.sleep(1)\n+        return {\"analysis\": simulated_analysis, \"grade\": simulated_grade}\n+\n+\n+logger = logging.getLogger(__name__)\n+\n+router = APIRouter(\n+    prefix=\"/logic\", # Prefijo /logic para este router\n+    tags=[\"Logic Problems\"],\n+    # dependencies=[Depends(get_current_user)] # Opcional: Proteger todo el router\n+)\n+\n+# Instancia del Cliente MongoDB (asumiendo que ya la tienes)\n+try:\n+    mongo_client = MongoDBClient()\n+    logger.info(\"MongoDBClient instanciado en routers/logic.py\")\n+except Exception as e:\n+    logger.error(f\"Error al instanciar MongoDBClient en routers/logic.py: {e}\")\n+    mongo_client = None # Set a None si falla para verificar en endpoints\n+\n+# Instancia del cliente Google Cloud Text-to-Speech (asumiendo que ya la tienes e inicializaste)\n+SERVICE_ACCOUNT_KEY_PATH = \"/home/alessandro_hp/Documentos/Cursor/DAW_PROYECTO/daw_backend/scripts/daw-proyecto-458721-accdda2dde3a.json\" # <-- Tu ruta exacta\n+\n+# Instancia del cliente Google Cloud Text-to-Speech (inicializar al inicio del módulo)\n+tts_client = None # Inicializar a None\n+# Aseguramos que la variable credentials también se inicialice a None aquí\n+credentials = None\n+try:\n+    # --- Cargar credenciales desde el archivo ---\n+    # Esto requiere que el archivo sea válido y la librería google-auth esté instalada.\n+    credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_KEY_PATH)\n+\n+    # --- AÑADIR ESTE LOG DESPUÉS DE CARGAR CREDENCIALES ---\n+    # Verifica si la carga devolvió el objeto esperado\n+    logger.info(f\"Credenciales cargadas desde archivo type: {type(credentials)}, value: {credentials}\")\n+    # ----------------------------------------------------\n+\n+    # --- Inicializar el cliente Google Cloud TTS usando las credenciales ---\n+    # ¡¡CORRECCIÓN!! Pasar la variable 'credentials' (el objeto), NO la ruta string.\n+    tts_client = texttospeech.TextToSpeechClient(credentials=credentials) # <-- ¡¡PASAR LA VARIABLE credentials!!\n+\n+    logger.info(f\"Cliente Google Cloud Text-to-Speech inicializado usando archivo explícito: {SERVICE_ACCOUNT_KEY_PATH}\")\n+\n+# Capturar errores específicos de archivo no encontrado primero\n+except FileNotFoundError:\n+    logger.error(f\"Error: Archivo de clave de cuenta de servicio NO ENCONTRADO en la ruta: {SERVICE_ACCOUNT_KEY_PATH}\", exc_info=True)\n+    tts_client = None\n+    credentials = None\n+except Exception as e:\n+    # Capturar cualquier otro error durante la inicialización (archivo inválido, permisos, red, etc.)\n+    logger.error(f\"Error al inicializar cliente Google Cloud TTS con archivo {SERVICE_ACCOUNT_KEY_PATH}: {str(e)}\", exc_info=True)\n+    tts_client = None\n+    credentials = None\n+\n+# --- AÑADIR ESTE LOG DESPUÉS DEL BLOQUE TRY/EXCEPT (PARA VER ESTADO FINAL) ---\n+logger.info(f\"Estado final de tts_client después de la inicialización del módulo: {type(tts_client)}\")\n+# ---------------------------------------------------\n+\n+\n+# --- Endpoint de Progreso ---\n+@router.get(\n+    \"/progress\",\n+    response_model=UserProgressResponse,\n+    summary=\"Obtiene el progreso del usuario autenticado\"\n+)\n+async def get_user_progress(\n+    # current_user ya es el diccionario del usuario de la DB\n+    current_db_user: Annotated[dict, Depends(get_current_user)]\n+):\n+    if mongo_client is None:\n+         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n+\n+    # Ya tenemos el documento del usuario gracias a Depends(get_current_user)\n+    # No necesitamos obtenerlo de nuevo por ID a menos que necesitemos una versión más reciente (poco probable aquí)\n+    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n+\n+    if not user_id or not isinstance(user_id, ObjectId):\n+         # Esto no debería pasar si get_current_user funciona bien, pero es una seguridad.\n+         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n+         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n+\n+    logger.info(f\"Solicitud de progreso para usuario: {user_email} (ID: {user_id})\")\n+\n+    # El array de ejercicios resueltos está directamente en el documento del usuario\n+    solved_exercises = current_db_user.get(\"ejercicios\", []) # Acceder directamente al array del documento proporcionado por el Depends\n+\n+    # Lógica de Cálculo (sin cambios)...\n+    progress_counts: Dict[str, int] = {\"basico\": 0, \"intermedio\": 0, \"avanzado\": 0}\n+    progress_sums: Dict[str, float] = {\"basico\": 0.0, \"intermedio\": 0.0, \"avanzado\": 0.0}\n+    total_solved_count = 0; total_grade_sum = 0.0\n+    for exercise in solved_exercises:\n+        if isinstance(exercise, dict) and exercise.get(\"problem_difficulty\") in progress_counts and isinstance(exercise.get(\"llm_grade\"), (int, float)):\n+            difficulty = exercise[\"problem_difficulty\"]; grade = exercise[\"llm_grade\"]\n+            total_solved_count += 1; total_grade_sum += grade\n+            progress_counts[difficulty] += 1; progress_sums[difficulty] += grade\n+        else: logger.warning(f\"Ejercicio formato inválido user_id {user_id}: {exercise}\")\n+    progress_by_difficulty: Dict[str, DifficultyProgress] = {}\n+    for dl in [\"basico\", \"intermedio\", \"avanzado\"]:\n+        count = progress_counts[dl]; grade_sum = progress_sums[dl]\n+        avg_grade = round(grade_sum / count, 2) if count > 0 else 0.0\n+        progress_by_difficulty[dl] = DifficultyProgress(solved_count=count, average_grade=avg_grade)\n+    overall_avg = round(total_grade_sum / total_solved_count, 2) if total_solved_count > 0 else 0.0\n+    logger.info(f\"Progreso calculado para {user_email}: Total={total_solved_count}, Avg={overall_avg}\")\n+    return UserProgressResponse(total_solved=total_solved_count, progress_by_difficulty=progress_by_difficulty, overall_average_grade=overall_avg, message=\"Tu progreso ha sido cargado.\")\n+\n+\n+# --- Endpoint para Obtener Problema ---\n+@router.get(\n+    \"/problem\",\n+    response_model=Union[ProblemResponse, NoProblemResponse],\n+    summary=\"Obtiene un problema de lógica no resuelto\"\n+)\n+async def get_logic_problem(\n+    current_db_user: Annotated[dict, Depends(get_current_user)],\n+    difficulty: Annotated[str | None, Query(description=\"Filtrar por dificultad\")] = None\n+):\n+    if mongo_client is None: raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio DB no disponible.\")\n+    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n+    if not user_id or not isinstance(user_id, ObjectId): raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"ID usuario inválido.\")\n+    if difficulty is not None and difficulty not in [\"basico\", \"intermedio\", \"avanzado\"]: raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"Dificultad inválida.\")\n+    logger.info(f\"Buscando problema user_id: {user_id}, dificultad: {difficulty or 'cualquiera'}\")\n+\n+    try:\n+        # Asegúrate de que get_random_unsolved_problem es síncrono o usa async db driver (Motor)\n+        # Si es síncrono (PyMongo), usa asyncio.to_thread\n+        problem_dict = await asyncio.to_thread(mongo_client.get_random_unsolved_problem, user_id, difficulty=difficulty)\n+\n+    except Exception as db_error:\n+        logger.error(f\"Error DB consulta problemas user {user_id}: {db_error}\", exc_info=True)\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error DB consulta problemas.\")\n+\n+    if problem_dict:\n+        logger.info(f\"Problema encontrado {user_email}: ID={problem_dict.get('_id')}\")\n+        try:\n+             # Crear instancia Pydantic explícitamente para validación y serialización\n+             validated_problem = ProblemResponse(id=str(problem_dict[\"_id\"]), text=problem_dict[\"text\"], difficulty=problem_dict[\"difficulty\"], topics=problem_dict.get(\"topics\", []))\n+             return validated_problem\n+        except Exception as e:\n+             logger.error(f\"Error procesando datos problema {problem_dict.get('_id')} para {user_email}: {e}\", exc_info=True)\n+             raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error procesando datos problema.\")\n+    else:\n+        logger.info(f\"No se encontraron problemas {user_email}, dificultad: {difficulty or 'cualquiera'}\")\n+        message = f\"¡Felicidades! Has resuelto todos los problemas de nivel '{difficulty}'.\" if difficulty else \"¡Felicidades! Has resuelto todos los problemas.\"\n+        return NoProblemResponse(message=message)\n+\n+\n+# --- Endpoint POST /tts \n+@router.post(\"/tts\")\n+async def text_to_speech(\n+    # --- CAMBIO AQUÍ ---\n+    # Ahora FastAPI espera un cuerpo JSON que coincida con el modelo TTSTextRequest\n+    request_data: TTSTextRequest, # <-- Usamos el modelo Pydantic para el cuerpo\n+    # --- FIN CAMBIO ---\n+    current_user: Annotated[dict, Depends(get_current_user)] # Proteger el endpoint\n+):\n+    if not tts_client:\n+        logger.error(\"Intento de usar TTS, pero cliente no inicializado.\")\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Servicio de voz no disponible en el servidor.\")\n+\n+    # Obtener el texto del objeto recibido del frontend\n+    text = request_data.text # <-- Acceder al texto desde el objeto request_data\n+\n+    if not text: # Esta verificación aún es útil si el modelo permitiera texto vacío, pero el modelo BaseModel no lo permite por defecto\n+        logger.warning(f\"Solicitud /tts con texto vacío de usuario {current_user.get('email', 'N/A')}\")\n+        # FastAPI ya manejaría esto con 422 si el modelo requiriera texto no vacío, pero la dejamos por claridad.\n+        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"No se proporcionó texto para convertir a voz.\")\n+\n+    user_email = current_user.get(\"email\", \"N/A\")\n+    logger.info(f\"Generando voz para usuario {user_email}: '{text[:50]}...'\")\n+\n+    try:\n+        # ... (resto del código para llamar a synthesize_speech con el 'text' obtenido) ...\n+        synthesis_input = texttospeech.SynthesisInput(text=text)\n+        voice = texttospeech.VoiceSelectionParams(language_code=\"es-MX\", ssml_gender=texttospeech.SsmlVoiceGender.FEMALE) # Configurar voz estándar\n+        audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3) # Configurar audio MP3\n+\n+        response = tts_client.synthesize_speech(\n+            input=synthesis_input,\n+            voice=voice,\n+            audio_config=audio_config\n+        )\n+\n+        logger.info(f\"Voz generada exitosamente para {user_email} ({len(response.audio_content)} bytes).\")\n+        return Response(content=response.audio_content, media_type=\"audio/mpeg\")\n+\n+    except Exception as e:\n+        logger.error(f\"Error durante la síntesis de voz con Google Cloud TTS para {user_email}: {str(e)}\", exc_info=True)\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=f\"Error al generar voz en el servidor: {str(e)}\")\n+\n+\n+# --- Endpoint para Enviar Respuesta (CONEXIÓN CON LLM Y SAVE RESULT) ---\n+# Este endpoint recibe el texto de la respuesta, la evalúa y la guarda.\n+# REQUIERE que tengas implementada la función get_gemini_feedback en utils/gemini_utils.py\n+# REQUIERE que add_solved_exercise en mongodb_client.py funcione correctamente.\n+@router.post(\n+    \"/submit_answer\",\n+    # Asumiendo que models/logic.py tiene un modelo FeedbackResponse\n+    # con al menos 'analysis' (str) y 'grade' (int o float).\n+    # Ejemplo: class FeedbackResponse(BaseModel): analysis: str; grade: int\n+    response_model=FeedbackResponse,\n+    summary=\"Recibe respuesta, evalúa con IA y guarda el resultado\",\n+)\n+async def submit_user_answer(\n+    # current_user es el documento del usuario logeado, ya obtenido por Depends\n+    current_db_user: Annotated[dict, Depends(get_current_user)],\n+    problem_id: Annotated[str, Form(...)], # Recibe el ID del problema (como string) del frontend (Form data)\n+    user_answer: Annotated[str, Form(...)] # Recibe el texto de la respuesta (como string) del frontend (Form data)\n+):\n+    if mongo_client is None:\n+         raise HTTPException(status_code=status.HTTP_503_SERVICE_UNAVAILABLE, detail=\"Servicio de base de datos no disponible.\")\n+\n+    user_id = current_db_user.get(\"_id\"); user_email = current_db_user.get(\"email\", \"N/A\")\n+    if not user_id or not isinstance(user_id, ObjectId):\n+         # Esto no debería pasar con un Depends válido, pero es una seguridad\n+         logger.error(f\"Dependencia get_current_user no devolvió un _id ObjectId válido para {user_email}\")\n+         raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error interno al obtener datos de usuario.\")\n+\n+    # 1. Validar y convertir el ID del problema recibido\n+    try:\n+        # problem_id llega como string del frontend (Form data)\n+        problem_id_obj = ObjectId(problem_id) # Convertir el string ID a ObjectId\n+    except Exception:\n+        # Si la conversión falla, el ID recibido no es válido\n+        logger.warning(f\"ID de problema inválido recibido de {user_email}: '{problem_id}'\")\n+        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=\"ID de problema inválido.\")\n+\n+    logger.info(f\"Usuario '{user_email}' (ID: {user_id}) envió respuesta para problema '{problem_id_obj}'.\")\n+    logger.debug(f\"Respuesta recibida: '{user_answer}'\")\n+\n+    # 2. Obtener el problema original de la DB (necesario para el prompt del LLM)\n+    # Asumiendo que tienes un método get_problem_by_id(problem_id_obj) en mongo_client\n+    try:\n+        # Si get_problem_by_id es síncrono (PyMongo), usa asyncio.to_thread\n+        # Si es async (Motor), quita await asyncio.to_thread\n+        problem_data = await asyncio.to_thread(mongo_client.get_problem_by_id, problem_id_obj)\n+        # Si no tienes get_problem_by_id, puedes intentar obtenerlo de la misma agregación que en get_random_unsolved_problem,\n+        # pero get_problem_by_id es más limpio. Implementa get_problem_by_id en mongo_client si no existe.\n+    except Exception as db_error:\n+        logger.error(f\"Error DB al obtener problema {problem_id_obj} para {user_email}: {db_error}\", exc_info=True)\n+        raise HTTPException(status_code=status.HTTP_500_INTERNAL_SERVER_ERROR, detail=\"Error al validar el problema.\")\n+\n+    if not problem_data:\n+        logger.warning(f\"Problema {problem_id_obj} no encontrado en DB para respuesta de {user_email}.\")\n+        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=\"El problema especificado no fue encontrado.\")\n+\n+    # 3. --- PREPARAR PROMPT PARA LLM ---\n+    # Aquí es donde construirías el prompt para el LLM, incluyendo:\n+    # - Contexto general del proyecto (aplicación educativa, para usuarios ciegos, etc.)\n+    # - Progreso del usuario (opcional, pero útil para contexto del LLM)\n+    # - El problema original (problem_data['text'])\n+    # - La respuesta del usuario (user_answer)\n+    # - Instrucciones claras para el LLM (analizar lógica, no código, calificar 1-5, formato JSON).\n+\n+    # Para obtener el progreso del usuario *actualizado* para el prompt,\n+    # podrías volver a calcularlo o obtener el documento completo de usuario.\n+    # El current_db_user ya trae el array 'ejercicios'.\n+    # Puedes reutilizar la lógica de cálculo de progreso de get_user_progress aquí.\n+\n+    user_solved_exercises = current_db_user.get(\"ejercicios\", []) # Array de ejercicios resueltos\n+    # Calcula el progreso actual (total, por dificultad, promedios) a partir de user_solved_exercises\n+\n+    # --- Simulación de cálculo de progreso para el prompt ---\n+    # NOTA: Reemplaza esto con la lógica real de cálculo de progreso si la necesitas en el prompt.\n+    total_solved_count = len(user_solved_exercises)\n+    # Aquí iría la lógica para calcular promedios y conteos por dificultad si los incluyes en el prompt.\n+    # --- Fin Simulación ---\n+\n+\n+    # --- Construir el prompt ---\n+    # Este prompt es CRUCIAL para guiar al LLM. Adapta el texto según el modelo LLM que uses.\n+    llm_prompt_parts = [\n+        \"SYSTEM: You are a programming logic tutor, friendly and helpful, specialized in assisting blind users learning to program. Your feedback should focus on the logical steps, problem-solving approach, correctness, and efficiency, not specific code syntax. Provide a clear analysis and assign a grade.\",\n+        \"CONTEXT: This is an educational web application for blind individuals. Interaction is primarily through voice. Your response will be read aloud by a screen reader.\",\n+        f\"USER_PROGRESS_SUMMARY: This user has solved {total_solved_count} exercises so far.\", # Puedes añadir más detalles aquí si los calculaste\n+        f\"PROGRAMMING_LOGIC_PROBLEM: {problem_data['text']}\", # El enunciado original del problema\n+        f\"USER_SUBMITTED_SOLUTION_LOGIC: {user_answer}\", # La respuesta transcrita del usuario\n+        \"INSTRUCTIONS: Based on the PROGRAMMING_LOGIC_PROBLEM and the USER_SUBMITTED_SOLUTION_LOGIC:\",\n+        \"- Analyze the user's proposed logic and thought process. Is it a valid approach to solve the problem?\",\n+        \"- Comment on its correctness, clarity, and potential efficiency. Discuss edge cases if relevant to the problem.\",\n+        \"- Do NOT provide code snippets or specific code syntax in your analysis.\",\n+        \"- Provide detailed feedback (aim for 50-200 words, keep it concise but informative for voice).\",\n+        \"- Assign a grade for the solution's logic on a scale of 0 to 10, where 0 is completely incorrect/no attempt, and 10 is excellent.\",\n+        \"- Respond ONLY in JSON format with the keys 'analysis' (string) and 'grade' (integer 0-10). Ensure the JSON is valid.\",\n+        \"EXAMPLE_JSON_RESPONSE: {\\\"analysis\\\": \\\"Your approach is logical and correct...\\\", \\\"grade\\\": 8}\"\n+    ]\n+    llm_prompt = \"\\n\".join(llm_prompt_parts)\n+\n+    # 4. --- LLAMADA AL LLM ---\n+    llm_analysis = \"Análisis no disponible (servicio de IA no configurado o falló).\"\n+    llm_grade = 0 # Grado por defecto si falla el LLM\n+\n+    if GEMINI_AVAILABLE:\n+        logger.info(f\"Llamando a Gemini para evaluar respuesta del problema {problem_id_obj} para user {user_email}...\")\n+        try:\n+            # La función get_gemini_feedback debe estar implementada en utils/gemini_utils.py\n+            # y ser ASYNC (def async) para usar await aquí.\n+            # Si es SÍNCRONA, usa: feedback_result = await asyncio.to_thread(get_gemini_feedback, ...)\n+            feedback_result = await get_gemini_feedback(problem_data['text'], user_answer, user_progress_summary=llm_prompt_parts[2]) # Pasar el prompt completo o solo la parte del progreso si la función lo acepta\n+\n+\n+            if feedback_result and isinstance(feedback_result, dict): # Verificar que sea un diccionario\n+                llm_analysis = feedback_result.get(\"analysis\", \"Error al extraer análisis del resultado de IA.\")\n+                try:\n+                     # Intentar convertir la calificación a entero, manejando posibles errores\n+                     llm_grade = int(feedback_result.get(\"grade\", 0))\n+                     # Asegurar que la calificación esté en el rango esperado (ej. 0-10)\n+                     llm_grade = max(0, min(10, llm_grade))\n+                except (ValueError, TypeError):\n+                     logger.error(f\"Nota inválida recibida de Gemini para {user_email} ({problem_id_obj}): '{feedback_result.get('grade')}'. Usando 0.\")\n+                     llm_grade = 0\n+                logger.info(f\"Evaluación de Gemini recibida para {user_email}: Calificación={llm_grade}\")\n+            else:\n+                logger.error(f\"La llamada a Gemini no devolvió un diccionario o falló para {user_email} ({problem_id_obj}). Resultado: {feedback_result}\")\n+                llm_analysis = \"La evaluación automática falló. Intenta de nuevo más tarde.\" # Mensaje amigable si el LLM falla\n+                llm_grade = 0 # Calificación por defecto si falla el LLM\n+        except Exception as llm_error:\n+            # Capturar errores durante la llamada o procesamiento de la respuesta de Gemini\n+            logger.error(f\"Error inesperado durante la llamada o procesamiento de Gemini para {user_email} ({problem_id_obj}): {llm_error}\", exc_info=True)\n+            llm_analysis = \"Error interno al procesar la evaluación automática. Intenta de nuevo.\" # Mensaje amigable si el LLM falla\n+            llm_grade = 0 # Calificación por defecto si falla el LLM\n+    else:\n+        # Lógica placeholder si Gemini no está disponible (definida arriba en el try/except de importación)\n+        # get_gemini_feedback ya es la función placeholder si la importación falla\n+        logger.warning(\"Usando evaluación placeholder porque Gemini no está disponible.\")\n+        # Llamamos al placeholder para generar un resultado simulado\n+        simulated_feedback = await get_gemini_feedback(problem_data['text'], user_answer)\n+        llm_analysis = simulated_feedback[\"analysis\"]\n+        llm_grade = simulated_feedback[\"grade\"]\n+\n+\n+    # 5. --- GUARDAR RESULTADO EN DB ---\n+    # Preparamos los datos para guardar en el array 'ejercicios' del usuario\n+    submission_data = {\n+        \"problem_id\": problem_id_obj, # ID del problema (ObjectId)\n+        \"problem_difficulty\": problem_data.get(\"difficulty\", \"desconocida\"), # Dificultad del problema original\n+        \"user_answer\": user_answer, # La respuesta del usuario (texto)\n+        \"analysis_received\": llm_analysis, # El análisis del LLM\n+        \"llm_grade\": llm_grade, # La calificación del LLM (0-10)\n+        \"submission_timestamp\": datetime.utcnow() # Timestamp de la sumisión\n+    }\n+\n+    save_error = False\n+    try:\n+        # Llamar al método add_solved_exercise de MongoDBClient para guardar\n+        # Asumiendo que add_solved_exercise es síncrono (PyMongo), usar asyncio.to_thread\n+        # Si es async (Motor), quitar await asyncio.to_thread\n+        update_result = await asyncio.to_thread(mongo_client.add_solved_exercise, user_id, submission_data)\n+\n+        # Verificar el resultado de la operación de guardado (opcional pero recomendado)\n+        # add_solved_exercise debería devolver UpdateResult si usa update_one\n+        if update_result is None:\n+            save_error = True\n+            logger.error(f\"La función add_solved_exercise devolvió None para user {user_id}. No se pudo guardar.\")\n+        elif hasattr(update_result, 'matched_count') and hasattr(update_result, 'modified_count'):\n+             if update_result.matched_count == 0:\n+                  save_error = True\n+                  logger.error(f\"No se encontró el usuario {user_id} para añadir el ejercicio resuelto (update_one matched_count=0).\")\n+             elif update_result.modified_count == 0:\n+                  # Esto puede pasar si el documento ya estaba en el array por alguna razón\n+                  logger.warning(f\"No se modificó el usuario {user_id} al añadir ejercicio (modified_count=0).\")\n+             else:\n+                  logger.info(f\"Ejercicio resuelto añadido correctamente al historial del usuario {user_id}\")\n+        else:\n+             # Si devolvió algo inesperado\n+             save_error = True\n+             logger.error(f\"Valor de retorno inesperado de add_solved_exercise para user {user_id}: {type(update_result)}\")\n+\n+\n+    except Exception as e:\n+        # Capturar errores durante la operación de guardado\n+        logger.error(f\"Error al intentar guardar el ejercicio resuelto para user {user_id} ({problem_id_obj}): {e}\", exc_info=True)\n+        save_error = True\n+        # No lanzamos excepción aquí para que el frontend reciba el feedback del LLM aunque no se haya guardado.\n+        # Puedes decidir lanzar una excepción si el guardado es crítico.\n+\n+\n+    logger.info(f\"Evaluación final para {user_email} (problema {problem_id_obj}): Calificación={llm_grade} (Guardado: {'No' if save_error else 'Sí'})\")\n+\n+    # 6. Devolver el feedback al frontend\n+    # Retornar FeedbackResponse(analysis=..., grade=...)\n+    return FeedbackResponse(analysis=llm_analysis, grade=llm_grade)\n+\n+# Asegúrate de que tu modelo FeedbackResponse esté definido en models/logic.py\n+# Ejemplo:\n+# from pydantic import BaseModel\n+# class FeedbackResponse(BaseModel):\n+#     analysis: str\n+#     grade: int # O float si tu LLM devuelve float\n\\ No newline at end of file\n"
                }
            ],
            "date": 1746139863306,
            "name": "Commit-0",
            "content": "# routers/logic.py\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom bson import ObjectId # Necesario para trabajar con ObjectIds\nfrom typing import Optional, Dict, List # Importar tipos necesarios\nfrom datetime import datetime # Necesario para timestamps si no lo generas en el cliente\n\n# Importa tu cliente de MongoDB (asegúrate que la ruta de importación sea correcta)\nfrom mongodb_client import MongoDBClient\n\n# Importa tu dependencia para obtener el usuario actual\nfrom utils.auth_utils import get_current_user # Asegúrate que la ruta es correcta\n\n# Importa el modelo de respuesta de progreso que acabamos de crear\nfrom models.logic import UserProgressResponse, DifficultyProgress # Asegúrate que la ruta es correcta\n\nimport logging # Para logging\nlogger = logging.getLogger(__name__) # Obtener logger para este módulo\n\nrouter = APIRouter(\n    prefix=\"/logic\", # Prefijo para todas las rutas en este router (ej. /api/logic/...)\n    tags=[\"Logic Problems\"], # Tags para la documentación de Swagger/OpenAPI\n    # Aquí podrías añadir la dependencia de autenticación a todo el router si quieres que todas sus rutas estén protegidas por defecto\n    # dependencies=[Depends(get_current_user)]\n)\n\n# Instancia del cliente de MongoDB\nmongo_client = MongoDBClient()\n\n# Endpoint para obtener el progreso del usuario en los ejercicios de lógica\n@router.get(\"/progress\", response_model=UserProgressResponse)\nasync def get_user_progress(\n    # Usa la dependencia para obtener el usuario autenticado.\n    # get_current_user debe devolver el documento completo del usuario o al menos su ID y email.\n    # Según tu código, get_current_user devuelve el diccionario completo del usuario.\n    current_user: dict = Depends(get_current_user)\n):\n    \"\"\"\n    Obtiene el progreso del usuario en los ejercicios de lógica resueltos.\n    Retorna conteos por dificultad y promedios de calificación.\n    Esta ruta requiere autenticación (Bearer Token).\n    \"\"\"\n    user_id = current_user.get(\"_id\") # Obtiene el ObjectId del usuario del documento retornado por get_current_user\n    user_email = current_user.get(\"email\") # Obtiene el email para logging\n\n    if not user_id:\n         logger.error(f\"Usuario autenticado sin _id en el token/objeto retornado: {user_email}\")\n         # Esto no debería pasar si get_current_user funciona correctamente, pero es una buena validación\n         raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"No se pudo identificar al usuario\")\n\n\n    logger.info(f\"Solicitud de progreso para usuario: {user_email} (ID: {user_id})\")\n\n    # El array de ejercicios resueltos está directamente en el documento del usuario\n    # Si por alguna razón el usuario no tiene el campo 'ejercicios', accedemos de forma segura con .get()\n    solved_exercises = current_user.get(\"ejercicios\", [])\n\n    # Inicializar contadores y sumas para el cálculo del progreso\n    progress_counts: Dict[str, int] = {\"basico\": 0, \"intermedio\": 0, \"avanzado\": 0}\n    progress_sums: Dict[str, float] = {\"basico\": 0.0, \"intermedio\": 0.0, \"avanzado\": 0.0}\n    total_solved_count = 0\n    total_grade_sum = 0.0\n\n    # Iterar sobre los ejercicios resueltos para calcular las estadísticas\n    for exercise in solved_exercises:\n        # Verificar que el ejercicio tenga la estructura esperada\n        if isinstance(exercise, dict) and \"problem_difficulty\" in exercise and \"llm_grade\" in exercise:\n            difficulty = exercise[\"problem_difficulty\"]\n            grade = exercise[\"llm_grade\"]\n\n            # Verificar que la dificultad sea una de las esperadas y el grade sea numérico\n            if difficulty in progress_counts and isinstance(grade, (int, float)):\n                total_solved_count += 1\n                total_grade_sum += grade\n\n                progress_counts[difficulty] += 1\n                progress_sums[difficulty] += grade\n            else:\n                 logger.warning(f\"Ejercicio con formato inesperado encontrado para user_id {user_id}: {exercise}\")\n\n\n    # Calcular promedios por dificultad\n    progress_by_difficulty: Dict[str, DifficultyProgress] = {}\n    for difficulty in progress_counts:\n        solved_count = progress_counts[difficulty]\n        grade_sum = progress_sums[difficulty]\n        # Calcular promedio solo si hay ejercicios resueltos en esa dificultad para evitar división por cero\n        average_grade = grade_sum / solved_count if solved_count > 0 else 0.0\n        # Opcional: Redondear el promedio para la respuesta\n        average_grade = round(average_grade, 2)\n\n        progress_by_difficulty[difficulty] = DifficultyProgress(\n            solved_count=solved_count,\n            average_grade=average_grade\n        )\n\n    # Calcular promedio general\n    overall_average_grade = total_grade_sum / total_solved_count if total_solved_count > 0 else 0.0\n    overall_average_grade = round(overall_average_grade, 2) # Opcional: Redondear\n\n    logger.info(f\"Progreso calculado para {user_email}: {total_solved_count} total, {progress_by_difficulty}, {overall_average_grade} avg\")\n\n    # Crear y retornar la respuesta usando el modelo Pydantic\n    return UserProgressResponse(\n        total_solved=total_solved_count,\n        progress_by_difficulty=progress_by_difficulty,\n        overall_average_grade=overall_average_grade,\n        message=\"Tu progreso ha sido cargado.\"\n    )\n\n# --- Otros endpoints de lógica (como /problem y /submit_answer) irán aquí ---\n# Los implementaremos en los siguientes pasos."
        }
    ]
}